{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Sentimental Analysis\n",
    "\n",
    "Goal: Scrape data from a website like bloomberg (all the bolded words), separate the news into categories, then assign a sentimental value\n",
    "\n",
    "spaCY was used to do preprocessing\n",
    "\n",
    "The following library are to be explored:\n",
    "1. VADER\n",
    "2. TextBlob\n",
    "3. Flair\n",
    "4. Models - RoBERTA (HuggingFace), DistilliBERT (HuggingFace)\n",
    "5. LLM\n",
    "6. Self Built (self-sourced Dataset)\n",
    "\n",
    "Plan:\n",
    "1. Compare between models 1-5\n",
    "2. Using the best model available to assign values to the data\n",
    "3. train own model using dataset\n",
    "4. Compare and conclude"
   ],
   "id": "2193c22260401624"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Exploring the Py libraries",
   "id": "f0bd2e9beb7fc1ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nest_asyncio import apply\n",
    "from textblob.en import sentiment\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ],
   "id": "49b31de351000735",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# setup\n",
    "\n",
    "sentence = \"Trump to Leave G-7 Tonight Due to Middle East Crisis\"\n",
    "\n",
    "# Preprocessing\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialize NLTK tools\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Preprocess text\n",
    "def preprocess(text):\n",
    "    if not isinstance(text, str) or text is None:\n",
    "        return \"\"\n",
    "    tokens = word_tokenize(text.lower())  # Tokenize and lowercase\n",
    "    cleaned_tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalpha() and token not in stop_words]\n",
    "    test_sentence = \" \".join(cleaned_tokens)\n",
    "    return test_sentence\n",
    "\n",
    "test_sentence = preprocess(sentence)"
   ],
   "id": "9fac6435f5ff0170",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. VADER",
   "id": "7a7d37fc0c0f14fc"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Prebuilt Vader sentiment package\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "scores = analyzer.polarity_scores(test_sentence)\n",
    "print(scores)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. TextBlob",
   "id": "119bdd34da09b06a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Prebuilt Textblob sentiment package\n",
    "\n",
    "from textblob import TextBlob\n",
    "text = TextBlob(test_sentence)\n",
    "score = text.sentiment\n",
    "print(score)"
   ],
   "id": "91d3e6559d45db91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. Flair\n",
    "\n",
    "Is optimized for sequence labeling but also has prebuild sentiment classification"
   ],
   "id": "5c513bc60f546da9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Prebuilt Flair sentiment package/Model\n",
    "\n",
    "from flair.data import Sentence\n",
    "from flair.nn import Classifier\n",
    "\n",
    "sentence = Sentence(test_sentence)\n",
    "tagger = Classifier.load('sentiment')\n",
    "tagger.predict(sentence)\n",
    "print(sentence)"
   ],
   "id": "3a17b17ba7907748",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4. HuggingFace Transformers",
   "id": "17218a63e9f9044c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T10:20:37.013101Z",
     "start_time": "2025-06-17T10:20:35.935568Z"
    }
   },
   "cell_type": "code",
   "source": "from transformers import pipeline, set_seed",
   "id": "87c16e128c2783db",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torch' from 'C:\\Users\\Jay Tai\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\__init__.py' has no attribute 'fx' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[54]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtransformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m pipeline, set_seed\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\__init__.py:27\u001B[39m\n\u001B[32m     24\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtyping\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m TYPE_CHECKING\n\u001B[32m     26\u001B[39m \u001B[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m27\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m dependency_versions_check\n\u001B[32m     28\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     29\u001B[39m     OptionalDependencyNotAvailable,\n\u001B[32m     30\u001B[39m     _LazyModule,\n\u001B[32m   (...)\u001B[39m\u001B[32m     49\u001B[39m     logging,\n\u001B[32m     50\u001B[39m )\n\u001B[32m     51\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mimport_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m define_import_structure\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\dependency_versions_check.py:16\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     12\u001B[39m \u001B[38;5;66;03m# See the License for the specific language governing permissions and\u001B[39;00m\n\u001B[32m     13\u001B[39m \u001B[38;5;66;03m# limitations under the License.\u001B[39;00m\n\u001B[32m     15\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdependency_versions_table\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m deps\n\u001B[32m---> \u001B[39m\u001B[32m16\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mversions\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m require_version, require_version_core\n\u001B[32m     19\u001B[39m \u001B[38;5;66;03m# define which module versions we always want to check at run time\u001B[39;00m\n\u001B[32m     20\u001B[39m \u001B[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001B[39;00m\n\u001B[32m     21\u001B[39m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[32m     22\u001B[39m \u001B[38;5;66;03m# order specific notes:\u001B[39;00m\n\u001B[32m     23\u001B[39m \u001B[38;5;66;03m# - tqdm must be checked before tokenizers\u001B[39;00m\n\u001B[32m     25\u001B[39m pkgs_to_check_at_runtime = [\n\u001B[32m     26\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mpython\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     27\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mtqdm\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     37\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mpyyaml\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     38\u001B[39m ]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\utils\\__init__.py:24\u001B[39m\n\u001B[32m     21\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpackaging\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m version\n\u001B[32m     23\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m __version__\n\u001B[32m---> \u001B[39m\u001B[32m24\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01margs_doc\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     25\u001B[39m     ClassAttrs,\n\u001B[32m     26\u001B[39m     ClassDocstring,\n\u001B[32m     27\u001B[39m     ImageProcessorArgs,\n\u001B[32m     28\u001B[39m     ModelArgs,\n\u001B[32m     29\u001B[39m     auto_class_docstring,\n\u001B[32m     30\u001B[39m     auto_docstring,\n\u001B[32m     31\u001B[39m     parse_docstring,\n\u001B[32m     32\u001B[39m     set_min_indent,\n\u001B[32m     33\u001B[39m     source_args_doc,\n\u001B[32m     34\u001B[39m )\n\u001B[32m     35\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbackbone_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m BackboneConfigMixin, BackboneMixin\n\u001B[32m     36\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mchat_template_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m DocstringParsingException, TypeHintParsingException, get_json_schema\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\utils\\args_doc.py:30\u001B[39m\n\u001B[32m     22\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mregex\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mre\u001B[39;00m\n\u001B[32m     24\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdoc\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     25\u001B[39m     MODELS_TO_PIPELINE,\n\u001B[32m     26\u001B[39m     PIPELINE_TASKS_TO_SAMPLE_DOCSTRINGS,\n\u001B[32m     27\u001B[39m     PT_SAMPLE_DOCSTRINGS,\n\u001B[32m     28\u001B[39m     _prepare_output_docstrings,\n\u001B[32m     29\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m30\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mgeneric\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ModelOutput\n\u001B[32m     33\u001B[39m PATH_TO_TRANSFORMERS = Path(\u001B[33m\"\u001B[39m\u001B[33msrc\u001B[39m\u001B[33m\"\u001B[39m).resolve() / \u001B[33m\"\u001B[39m\u001B[33mtransformers\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     36\u001B[39m AUTODOC_FILES = [\n\u001B[32m     37\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mconfiguration_*.py\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     38\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mmodeling_*.py\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m     43\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mfeature_extractor_*.py\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     44\u001B[39m ]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\utils\\generic.py:46\u001B[39m\n\u001B[32m     34\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mimport_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     35\u001B[39m     get_torch_version,\n\u001B[32m     36\u001B[39m     is_flax_available,\n\u001B[32m   (...)\u001B[39m\u001B[32m     40\u001B[39m     is_torch_fx_proxy,\n\u001B[32m     41\u001B[39m )\n\u001B[32m     44\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_torch_available():\n\u001B[32m     45\u001B[39m     \u001B[38;5;66;03m# required for @can_return_tuple decorator to work with torchdynamo\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m46\u001B[39m     \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m  \u001B[38;5;66;03m# noqa: F401\u001B[39;00m\n\u001B[32m     49\u001B[39m \u001B[38;5;28;01mclass\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mcached_property\u001B[39;00m(\u001B[38;5;28mproperty\u001B[39m):\n\u001B[32m     50\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     51\u001B[39m \u001B[33;03m    Descriptor that mimics @property but caches output in member variable.\u001B[39;00m\n\u001B[32m     52\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m     55\u001B[39m \u001B[33;03m    Built-in in functools from Python 3.8.\u001B[39;00m\n\u001B[32m     56\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\__init__.py:2240\u001B[39m\n\u001B[32m   2236\u001B[39m sys.modules.setdefault(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.classes\u001B[39m\u001B[33m\"\u001B[39m, classes)\n\u001B[32m   2238\u001B[39m \u001B[38;5;66;03m# quantization depends on torch.fx and torch.ops\u001B[39;00m\n\u001B[32m   2239\u001B[39m \u001B[38;5;66;03m# Import quantization\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2240\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m quantization \u001B[38;5;28;01mas\u001B[39;00m quantization  \u001B[38;5;66;03m# usort: skip\u001B[39;00m\n\u001B[32m   2242\u001B[39m \u001B[38;5;66;03m# Import the quasi random sampler\u001B[39;00m\n\u001B[32m   2243\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m quasirandom \u001B[38;5;28;01mas\u001B[39;00m quasirandom  \u001B[38;5;66;03m# usort: skip\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\quantization\\__init__.py:6\u001B[39m\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfuser_method_mappings\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *  \u001B[38;5;66;03m# noqa: F403\u001B[39;00m\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mobserver\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *  \u001B[38;5;66;03m# noqa: F403\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mqconfig\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *  \u001B[38;5;66;03m# noqa: F403\u001B[39;00m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mquant_type\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *  \u001B[38;5;66;03m# noqa: F403\u001B[39;00m\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mquantization_mappings\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *  \u001B[38;5;66;03m# noqa: F403\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\quantization\\qconfig.py:9\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# flake8: noqa: F401\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[33mr\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[33;03mThis file is in the process of migration to `torch/ao/quantization`, and\u001B[39;00m\n\u001B[32m      4\u001B[39m \u001B[33;03mis kept here for compatibility while the migration process is ongoing.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m      7\u001B[39m \u001B[33;03mhere.\u001B[39;00m\n\u001B[32m      8\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mao\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mquantization\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mqconfig\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     10\u001B[39m     _add_module_to_qconfig_obs_ctr,\n\u001B[32m     11\u001B[39m     _assert_valid_qconfig,\n\u001B[32m     12\u001B[39m     default_activation_only_qconfig,\n\u001B[32m     13\u001B[39m     default_debug_qconfig,\n\u001B[32m     14\u001B[39m     default_dynamic_qconfig,\n\u001B[32m     15\u001B[39m     default_per_channel_qconfig,\n\u001B[32m     16\u001B[39m     default_qat_qconfig,\n\u001B[32m     17\u001B[39m     default_qat_qconfig_v2,\n\u001B[32m     18\u001B[39m     default_qconfig,\n\u001B[32m     19\u001B[39m     default_weight_only_qconfig,\n\u001B[32m     20\u001B[39m     float16_dynamic_qconfig,\n\u001B[32m     21\u001B[39m     float16_static_qconfig,\n\u001B[32m     22\u001B[39m     float_qparams_weight_only_qconfig,\n\u001B[32m     23\u001B[39m     get_default_qat_qconfig,\n\u001B[32m     24\u001B[39m     get_default_qconfig,\n\u001B[32m     25\u001B[39m     per_channel_dynamic_qconfig,\n\u001B[32m     26\u001B[39m     QConfig,\n\u001B[32m     27\u001B[39m     qconfig_equals,\n\u001B[32m     28\u001B[39m     QConfigAny,\n\u001B[32m     29\u001B[39m     QConfigDynamic,\n\u001B[32m     30\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\ao\\quantization\\__init__.py:12\u001B[39m\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfuser_method_mappings\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *  \u001B[38;5;66;03m# noqa: F403\u001B[39;00m\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mobserver\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *  \u001B[38;5;66;03m# noqa: F403\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m12\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpt2e\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_numeric_debugger\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (  \u001B[38;5;66;03m# noqa: F401\u001B[39;00m\n\u001B[32m     13\u001B[39m     compare_results,\n\u001B[32m     14\u001B[39m     CUSTOM_KEY,\n\u001B[32m     15\u001B[39m     extract_results_from_loggers,\n\u001B[32m     16\u001B[39m     generate_numeric_debug_handle,\n\u001B[32m     17\u001B[39m     NUMERIC_DEBUG_HANDLE_KEY,\n\u001B[32m     18\u001B[39m     prepare_for_propagation_comparison,\n\u001B[32m     19\u001B[39m )\n\u001B[32m     20\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpt2e\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mexport_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     21\u001B[39m     _allow_exported_model_train_eval \u001B[38;5;28;01mas\u001B[39;00m allow_exported_model_train_eval,\n\u001B[32m     22\u001B[39m     _move_exported_model_to_eval \u001B[38;5;28;01mas\u001B[39;00m move_exported_model_to_eval,\n\u001B[32m     23\u001B[39m     _move_exported_model_to_train \u001B[38;5;28;01mas\u001B[39;00m move_exported_model_to_train,\n\u001B[32m     24\u001B[39m )\n\u001B[32m     25\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mqconfig\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *  \u001B[38;5;66;03m# noqa: F403\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\ao\\quantization\\pt2e\\_numeric_debugger.py:9\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mao\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mns\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfx\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m compute_sqnr\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mao\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mquantization\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpt2e\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mgraph_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m bfs_trace_with_node_process\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mexport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ExportedProgram\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfx\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m GraphModule, Node\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\ao\\quantization\\pt2e\\graph_utils.py:9\u001B[39m\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtyping\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Any, Callable, Optional, Union\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mexport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ExportedProgram\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfx\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Node\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfx\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpasses\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msource_matcher_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     12\u001B[39m     check_subgraphs_connected,\n\u001B[32m     13\u001B[39m     get_source_partitions,\n\u001B[32m     14\u001B[39m     SourcePartition,\n\u001B[32m     15\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\export\\__init__.py:60\u001B[39m\n\u001B[32m     57\u001B[39m \u001B[38;5;66;03m# To make sure export specific custom ops are loaded\u001B[39;00m\n\u001B[32m     58\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mexport\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcustom_ops\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m60\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdecomp_utils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m CustomDecompTable\n\u001B[32m     61\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdynamic_shapes\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Constraint, Dim, dims, ShapesCollection\n\u001B[32m     62\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mexported_program\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     63\u001B[39m     default_decompositions,\n\u001B[32m     64\u001B[39m     ExportedProgram,\n\u001B[32m     65\u001B[39m     ModuleCallEntry,\n\u001B[32m     66\u001B[39m     ModuleCallSignature,\n\u001B[32m     67\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\export\\decomp_utils.py:5\u001B[39m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtyping\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Callable\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_export\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m      6\u001B[39m     _collect_all_valid_cia_ops,\n\u001B[32m      7\u001B[39m     _collect_all_valid_cia_ops_for_aten_namespace,\n\u001B[32m      8\u001B[39m     _get_decomp_for_cia,\n\u001B[32m      9\u001B[39m     _is_aten_op,\n\u001B[32m     10\u001B[39m )\n\u001B[32m     13\u001B[39m __all__ = [\u001B[33m\"\u001B[39m\u001B[33mCustomDecompTable\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m     16\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     17\u001B[39m \u001B[33;03mCore ATen ops with Composite Implicit Autograd dispatch that should be excluded from decomposition\u001B[39;00m\n\u001B[32m     18\u001B[39m \u001B[33;03mby default. The decomposition logic should eventually exclude all core-tagged CIA ops, but until all\u001B[39;00m\n\u001B[32m     19\u001B[39m \u001B[33;03mbackends are ready, this list allows opt-in one at a time.\u001B[39;00m\n\u001B[32m     20\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_export\\__init__.py:49\u001B[39m\n\u001B[32m     46\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfx\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mgraph\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _PyTreeCodeGen, _PyTreeInfo\n\u001B[32m     48\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mwrappers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _wrap_submodules\n\u001B[32m---> \u001B[39m\u001B[32m49\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _materialize_cpp_cia_ops\n\u001B[32m     51\u001B[39m log = logging.getLogger(\u001B[34m__name__\u001B[39m)\n\u001B[32m     53\u001B[39m \u001B[38;5;129m@dataclasses\u001B[39m.dataclass\n\u001B[32m     54\u001B[39m \u001B[38;5;28;01mclass\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mExportDynamoConfig\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\_export\\utils.py:93\u001B[39m\n\u001B[32m     88\u001B[39m         constant_attrs.add(value, name)\n\u001B[32m     89\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m constant_attrs\n\u001B[32m     92\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_register_constants_as_buffers\u001B[39m(\n\u001B[32m---> \u001B[39m\u001B[32m93\u001B[39m     mod: \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfx\u001B[49m.GraphModule, state_dict, non_persistent_buffers\n\u001B[32m     94\u001B[39m ):\n\u001B[32m     95\u001B[39m     \u001B[38;5;66;03m# TODO some annoying circular dependency issue\u001B[39;00m\n\u001B[32m     96\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mexport\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01munflatten\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _assign_attr, _AttrKind\n\u001B[32m     98\u001B[39m     temp_registered_constants = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[31mAttributeError\u001B[39m: partially initialized module 'torch' from 'C:\\Users\\Jay Tai\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\__init__.py' has no attribute 'fx' (most likely due to a circular import)"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### - RoBERTa",
   "id": "cb40705550143cc0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "classifier = pipeline('sentiment-analysis', model='cardiffnlp/twitter-roberta-base-sentiment')\n",
    "result = classifier(test_sentence)\n",
    "print(result)"
   ],
   "id": "abcf26e6644caaef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### - DistilBERT",
   "id": "4acdd1f0a2de7930"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T10:20:32.304210Z",
     "start_time": "2025-06-17T10:20:32.206064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classifier = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')\n",
    "result = classifier(test_sentence)\n",
    "print(result)"
   ],
   "id": "68f02a1362c85665",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[53]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m classifier = \u001B[43mpipeline\u001B[49m(\u001B[33m'\u001B[39m\u001B[33msentiment-analysis\u001B[39m\u001B[33m'\u001B[39m, model=\u001B[33m'\u001B[39m\u001B[33mdistilbert-base-uncased-finetuned-sst-2-english\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m      2\u001B[39m result = classifier(test_sentence)\n\u001B[32m      3\u001B[39m \u001B[38;5;28mprint\u001B[39m(result)\n",
      "\u001B[31mNameError\u001B[39m: name 'pipeline' is not defined"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### - Google Flan t5 base LLM model (Open source via HuggingFace)",
   "id": "b1be917b6a3da9b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "classifier = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")\n",
    "prompt = f\"Classify the sentiment of '{test_sentence}' as positive, negative, or neutral, and give a sentimental score of -1 to 1.\"\n",
    "result = classifier(prompt)\n",
    "print(result)"
   ],
   "id": "d8fe64f25bbd57c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5. OpenRouter to send api request to LLM",
   "id": "ad5d025246605ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# LLM Qwen\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=\"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\",\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  extra_body={},\n",
    "  model=\"deepseek/deepseek-r1-0528-qwen3-8b:free\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": f\"Conduct Sentimental Analysis on the following statement(s) and give me a polarity and score. {test_sentence}\"\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ],
   "id": "c7a8d51013f358ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 6. Building own model from data taken from Kraggle\n",
    "\n",
    "cnbc: (3080, 3) -- reserved for testing and backtesting\n",
    "\n",
    "guardian: (17800, 2)\n",
    "+\n",
    "retuers: (32770, 3)\n",
    "\n",
    "I pass the data into an ai to generate a list of sentimental values to be assigned (lazy to self assign)\n",
    "\n",
    "train-split 80-20 and trained"
   ],
   "id": "ded858992243b6d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "cnbc = pd.read_csv(\"data/cnbc_headlines.csv\") # used as a testing data across the board\n",
    "guardian = pd.read_csv(\"data/guardian_headlines.csv\")\n",
    "reuters = pd.read_csv(\"data/reuters_headlines.csv\")"
   ],
   "id": "1bf7f406b267cde8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# preparing training and testing data\n",
    "\n",
    "import random\n",
    "random.seed(999)\n",
    "data = list(map(preprocess, (list(guardian['Headlines']) + list(reuters['Headlines']) + list(cnbc['Headlines']))))\n",
    "random.shuffle(data)\n",
    "t = int(len(data)*.8)\n",
    "train_set = data[:t]\n",
    "test_set = data[t:]"
   ],
   "id": "ec2b33bf8fc924eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(train_set), len(test_set)",
   "id": "dcc4ad0fc36126b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# We create a preliminary model using NLTK library trained on our dataset\n",
    "\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "\n",
    "a = SentimentAnalyzer()\n"
   ],
   "id": "c6e9c4a3ea2e0712",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "eb0f4f96ace7ff39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ec96c29ad9634bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "94cb891652d452bf",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
