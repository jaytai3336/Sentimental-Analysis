{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Sentiment Analysis of Financial News Using NLTK","metadata":{"id":"lC6R4QaV0Ci0"}},{"cell_type":"markdown","source":"We would predict the sentiment of Fiancial news using NLTK (Natural Language Toolkit).","metadata":{"id":"Iq7zwt8VJh1Z"}},{"cell_type":"markdown","source":"# About Dataset\nhttps://www.kaggle.com/datasets/notlucasp/financial-news-headlines/code \n\nThis dataset contains 3 csv file\n\ncnbc headline   (3080, 3)\n\ngaurdian headline   (17800, 2)\n\nreuters headline   (32770, 3)\n","metadata":{"id":"Y6-xhkpm0MqU"}},{"cell_type":"markdown","source":"# Columns Provided in the Dataset\n\ncnbc headline df\n1. time\n2. headlines\n3. Description\n\ngaurdian headline df\n1. time\n2. headline\n\nreuters headline df\n1. time\n2. headline\n3. description\n","metadata":{"id":"sZRF0xat134_"}},{"cell_type":"markdown","source":"# What is NLTK ?\n\nThe Natural Language Toolkit (NLTK) is a platform used for building Python programs that work with human language data for applying in statistical natural language processing (NLP).\n\nIt contains text processing libraries for tokenization, parsing, classification, stemming, tagging and semantic reasoning.\n\n\n\n# What is sentiment analysis ?\n\nSentiment analysis is the process of detecting positive or negative sentiment in text. Itâ€™s often used by businesses to detect sentiment in social data, gauge brand reputation, and understand customers.\n\n","metadata":{"id":"5Q1HBH6RfLoZ"}},{"cell_type":"code","source":"pip install nltk","metadata":{"execution":{"iopub.status.busy":"2023-08-26T15:28:43.530932Z","iopub.execute_input":"2023-08-26T15:28:43.531358Z","iopub.status.idle":"2023-08-26T15:28:52.735896Z","shell.execute_reply.started":"2023-08-26T15:28:43.531325Z","shell.execute_reply":"2023-08-26T15:28:52.734460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\n\n# Ignore all warnings (not recommended in most cases)\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-08-26T15:28:52.737901Z","iopub.execute_input":"2023-08-26T15:28:52.738257Z","iopub.status.idle":"2023-08-26T15:28:52.743863Z","shell.execute_reply.started":"2023-08-26T15:28:52.738229Z","shell.execute_reply":"2023-08-26T15:28:52.742542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import all the required libraries \nimport nltk\n#import stopwords and text processing libraries\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n# Download NLTK resources (only required once)\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('vader_lexicon')\n","metadata":{"id":"pE3JktaFgX_s","outputId":"0324e30c-7e6d-47f7-b1e5-2b64046ab02c","execution":{"iopub.status.busy":"2023-08-26T15:28:52.745833Z","iopub.execute_input":"2023-08-26T15:28:52.746384Z","iopub.status.idle":"2023-08-26T15:28:52.768901Z","shell.execute_reply.started":"2023-08-26T15:28:52.746350Z","shell.execute_reply":"2023-08-26T15:28:52.767414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import machine learning libraries\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix","metadata":{"id":"B1qtW2W7gX67","execution":{"iopub.status.busy":"2023-08-26T15:28:52.771492Z","iopub.execute_input":"2023-08-26T15:28:52.771801Z","iopub.status.idle":"2023-08-26T15:28:52.780404Z","shell.execute_reply.started":"2023-08-26T15:28:52.771774Z","shell.execute_reply":"2023-08-26T15:28:52.778470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Basic EDA on cnbc_headlines dataset","metadata":{"id":"ijgTOXVu4QvL"}},{"cell_type":"code","source":"# Read csv file of cnbc headlines using pandas\n# Path=  /kaggle/input/financial-news-headlines/cnbc_headlines.csv\n\nimport pandas as pd\n\n# Define the path to the CSV file\ncsv_path = \"/kaggle/input/financial-news-headlines/cnbc_headlines.csv\"\n\n# Read the CSV file using Pandas\ncnbc_df = pd.read_csv(csv_path)\n","metadata":{"id":"EkHTI2fsgX1x","execution":{"iopub.status.busy":"2023-08-26T15:28:52.781589Z","iopub.execute_input":"2023-08-26T15:28:52.782568Z","iopub.status.idle":"2023-08-26T15:28:52.808340Z","shell.execute_reply.started":"2023-08-26T15:28:52.782516Z","shell.execute_reply":"2023-08-26T15:28:52.806808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the first few rows of the DataFrame\ncnbc_df","metadata":{"id":"Pel3IRW1gX0_","outputId":"22789c43-1702-4ce5-cfc3-7284f5343c72","execution":{"iopub.status.busy":"2023-08-26T15:28:52.809886Z","iopub.execute_input":"2023-08-26T15:28:52.810384Z","iopub.status.idle":"2023-08-26T15:28:52.823904Z","shell.execute_reply.started":"2023-08-26T15:28:52.810352Z","shell.execute_reply":"2023-08-26T15:28:52.822547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the shape of cnbc headline dataset\ncnbc_df.shape","metadata":{"id":"7MY607w2gXxS","outputId":"95607ac5-e89c-4896-e5d1-4268a4d80e25","execution":{"iopub.status.busy":"2023-08-26T15:28:52.825974Z","iopub.execute_input":"2023-08-26T15:28:52.826455Z","iopub.status.idle":"2023-08-26T15:28:52.836567Z","shell.execute_reply.started":"2023-08-26T15:28:52.826417Z","shell.execute_reply":"2023-08-26T15:28:52.834965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check all the columns in the cnbc headline dataset\ncnbc_df.columns","metadata":{"id":"fGyvfk-ZgXwN","outputId":"35c626ac-2781-4549-d4c2-22a9ebf0b2eb","execution":{"iopub.status.busy":"2023-08-26T15:28:52.838270Z","iopub.execute_input":"2023-08-26T15:28:52.838680Z","iopub.status.idle":"2023-08-26T15:28:52.856309Z","shell.execute_reply.started":"2023-08-26T15:28:52.838648Z","shell.execute_reply":"2023-08-26T15:28:52.854749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check which columns are having categorical, numerical or boolean values\ncnbc_df.info()","metadata":{"id":"kFiwMd7BgXr4","outputId":"146f358f-19be-4ddc-dc15-3290beb69f5f","execution":{"iopub.status.busy":"2023-08-26T15:28:52.857448Z","iopub.execute_input":"2023-08-26T15:28:52.857778Z","iopub.status.idle":"2023-08-26T15:28:52.878405Z","shell.execute_reply.started":"2023-08-26T15:28:52.857751Z","shell.execute_reply":"2023-08-26T15:28:52.876899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for missing values in all the columnns of cnbc headline dataset\ncnbc_df.isnull().sum()","metadata":{"id":"oST2tsU9gXrE","outputId":"6f38baa8-1b58-4779-be42-039a2c4e17fc","execution":{"iopub.status.busy":"2023-08-26T15:28:52.883502Z","iopub.execute_input":"2023-08-26T15:28:52.883845Z","iopub.status.idle":"2023-08-26T15:28:52.897771Z","shell.execute_reply.started":"2023-08-26T15:28:52.883816Z","shell.execute_reply":"2023-08-26T15:28:52.897059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is 280 missing values in headlines, description and time","metadata":{"id":"YRLZs_Jg8T3r"}},{"cell_type":"code","source":"# Drop nan values in cnbc headline dataset\ncnbc_df = cnbc_df.dropna()","metadata":{"id":"PdlYoGUfgXnE","execution":{"iopub.status.busy":"2023-08-26T15:28:52.898729Z","iopub.execute_input":"2023-08-26T15:28:52.899019Z","iopub.status.idle":"2023-08-26T15:28:52.917013Z","shell.execute_reply.started":"2023-08-26T15:28:52.898970Z","shell.execute_reply":"2023-08-26T15:28:52.915684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnbc_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-26T15:28:52.918411Z","iopub.execute_input":"2023-08-26T15:28:52.919030Z","iopub.status.idle":"2023-08-26T15:28:52.936397Z","shell.execute_reply.started":"2023-08-26T15:28:52.918927Z","shell.execute_reply":"2023-08-26T15:28:52.934683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count the duplicate rows\ncnbc_df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2023-08-26T15:28:52.938429Z","iopub.execute_input":"2023-08-26T15:28:52.938852Z","iopub.status.idle":"2023-08-26T15:28:52.957235Z","shell.execute_reply.started":"2023-08-26T15:28:52.938815Z","shell.execute_reply":"2023-08-26T15:28:52.955551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop the duplicate rows in the dataset keep the first one\ncnbc_df = cnbc_df.drop_duplicates(keep='first')\n\ncnbc_df.head()","metadata":{"id":"cD2J5VmmgXid","outputId":"f2c61222-e741-4732-a2b4-3267b10f70df","execution":{"iopub.status.busy":"2023-08-26T15:28:52.958549Z","iopub.execute_input":"2023-08-26T15:28:52.958920Z","iopub.status.idle":"2023-08-26T15:28:52.976969Z","shell.execute_reply.started":"2023-08-26T15:28:52.958893Z","shell.execute_reply":"2023-08-26T15:28:52.976216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the shape of cnbc headline dataset\ncnbc_df.shape","metadata":{"id":"WD5tcCcagXhU","outputId":"2355a67f-5967-4d18-9d33-42f9e78cab9b","execution":{"iopub.status.busy":"2023-08-26T15:28:52.978000Z","iopub.execute_input":"2023-08-26T15:28:52.978315Z","iopub.status.idle":"2023-08-26T15:28:52.985008Z","shell.execute_reply.started":"2023-08-26T15:28:52.978287Z","shell.execute_reply":"2023-08-26T15:28:52.984170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Basic EDA on Gaurdian headlines dataset","metadata":{"id":"JZFVAsUf53Vv"}},{"cell_type":"code","source":"# Read csv file of gaurdian headlines using pandas\n# Path = /kaggle/input/financial-news-headlines/guardian_headlines.csv\n# Define the path to the CSV file\ncsv_path = \"/kaggle/input/financial-news-headlines/guardian_headlines.csv\"\n\n# Read the CSV file using Pandas\nguardian_df = pd.read_csv(csv_path)","metadata":{"id":"st0vypi5gXTz","execution":{"iopub.status.busy":"2023-08-26T15:28:52.986639Z","iopub.execute_input":"2023-08-26T15:28:52.986928Z","iopub.status.idle":"2023-08-26T15:28:53.057741Z","shell.execute_reply.started":"2023-08-26T15:28:52.986904Z","shell.execute_reply":"2023-08-26T15:28:53.056744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the first few rows of the DataFrame\nguardian_df.head()","metadata":{"id":"O15tPmH1gXS5","outputId":"565c251d-ef27-4758-8bcd-77f4d73b3ec3","execution":{"iopub.status.busy":"2023-08-26T15:28:53.061141Z","iopub.execute_input":"2023-08-26T15:28:53.061432Z","iopub.status.idle":"2023-08-26T15:28:53.071270Z","shell.execute_reply.started":"2023-08-26T15:28:53.061408Z","shell.execute_reply":"2023-08-26T15:28:53.069504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the shape of gaurdian headline dataset\nguardian_df.shape","metadata":{"id":"09OSuHhRgXNf","outputId":"a485e842-e80a-4ac1-c9a4-e6ca644c3c6c","execution":{"iopub.status.busy":"2023-08-26T15:28:53.072327Z","iopub.execute_input":"2023-08-26T15:28:53.072636Z","iopub.status.idle":"2023-08-26T15:28:53.088182Z","shell.execute_reply.started":"2023-08-26T15:28:53.072609Z","shell.execute_reply":"2023-08-26T15:28:53.086463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check columns of gaurdian headline\nguardian_df.columns","metadata":{"id":"7gKFN26whZnD","outputId":"eaf4eede-9485-47d5-b5cb-e451b3113f43","execution":{"iopub.status.busy":"2023-08-26T15:28:53.089380Z","iopub.execute_input":"2023-08-26T15:28:53.089668Z","iopub.status.idle":"2023-08-26T15:28:53.104691Z","shell.execute_reply.started":"2023-08-26T15:28:53.089643Z","shell.execute_reply":"2023-08-26T15:28:53.103120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check which columns are having categorical, numerical or boolean values\nguardian_df.info()","metadata":{"id":"5fplFio3hZmG","outputId":"203f8075-6c24-4cc0-9c97-64de380ef72d","execution":{"iopub.status.busy":"2023-08-26T15:28:53.106237Z","iopub.execute_input":"2023-08-26T15:28:53.106561Z","iopub.status.idle":"2023-08-26T15:28:53.132552Z","shell.execute_reply.started":"2023-08-26T15:28:53.106534Z","shell.execute_reply":"2023-08-26T15:28:53.130865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check null values in gaurdian headlines dataset\nguardian_df.isnull().sum()","metadata":{"id":"qaWAwEazhZh8","outputId":"db5b6254-3aac-4c68-dbfb-d9088d5f6975","execution":{"iopub.status.busy":"2023-08-26T15:28:53.134169Z","iopub.execute_input":"2023-08-26T15:28:53.134447Z","iopub.status.idle":"2023-08-26T15:28:53.147723Z","shell.execute_reply.started":"2023-08-26T15:28:53.134423Z","shell.execute_reply":"2023-08-26T15:28:53.146227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop duplicate rows in headlines and keep the first one\n# Drop duplicate rows and keep the first occurrence\nguardian_df = guardian_df.drop_duplicates(keep='first')\n\n# Display the first few rows of the DataFrame after dropping duplicates\nguardian_df.head()","metadata":{"id":"NBtOooYChZg9","outputId":"64d9aed6-ab1c-46f5-d86d-0d2fcbf757ee","execution":{"iopub.status.busy":"2023-08-26T15:28:53.149498Z","iopub.execute_input":"2023-08-26T15:28:53.149867Z","iopub.status.idle":"2023-08-26T15:28:53.175707Z","shell.execute_reply.started":"2023-08-26T15:28:53.149839Z","shell.execute_reply":"2023-08-26T15:28:53.173664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Basic EDA on reuters headlines","metadata":{"id":"3iwjVwnv6-v3"}},{"cell_type":"code","source":"# Read csv file of reuters headlines using using pandas\n# Path= /kaggle/input/financial-news-headlines/reuters_headlines.csv\n\n# Define the path to the CSV file\ncsv_path = \"/kaggle/input/financial-news-headlines/reuters_headlines.csv\"\n\n# Read the CSV file using Pandas\nreuters_df = pd.read_csv(csv_path)","metadata":{"id":"asNDch3WhZXh","execution":{"iopub.status.busy":"2023-08-26T15:28:53.177341Z","iopub.execute_input":"2023-08-26T15:28:53.177686Z","iopub.status.idle":"2023-08-26T15:28:53.461221Z","shell.execute_reply.started":"2023-08-26T15:28:53.177658Z","shell.execute_reply":"2023-08-26T15:28:53.460340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the first few rows of the DataFrame\nreuters_df.head()","metadata":{"id":"n-FuGab8hZS0","outputId":"61fbc9af-cc62-4f68-bf99-3d071af01425","execution":{"iopub.status.busy":"2023-08-26T15:28:53.462241Z","iopub.execute_input":"2023-08-26T15:28:53.462471Z","iopub.status.idle":"2023-08-26T15:28:53.473954Z","shell.execute_reply.started":"2023-08-26T15:28:53.462450Z","shell.execute_reply":"2023-08-26T15:28:53.472413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the shape of reuters headlines dataset\nreuters_df.shape","metadata":{"id":"aRIhdEPyhZR3","outputId":"a2592db9-0d2c-45e6-9f36-926a14eb5602","execution":{"iopub.status.busy":"2023-08-26T15:28:53.475248Z","iopub.execute_input":"2023-08-26T15:28:53.475577Z","iopub.status.idle":"2023-08-26T15:28:53.488223Z","shell.execute_reply.started":"2023-08-26T15:28:53.475549Z","shell.execute_reply":"2023-08-26T15:28:53.486583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#check the columns of reuters headline dataset\nreuters_df.columns","metadata":{"id":"zn6OnjCwhZN8","outputId":"7965f9fb-0c75-4356-9ad0-4d8fe1727c3d","execution":{"iopub.status.busy":"2023-08-26T15:28:53.490872Z","iopub.execute_input":"2023-08-26T15:28:53.491505Z","iopub.status.idle":"2023-08-26T15:28:53.503384Z","shell.execute_reply.started":"2023-08-26T15:28:53.491386Z","shell.execute_reply":"2023-08-26T15:28:53.502222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check which columns are having categorical, numerical or boolean values\nreuters_df.info()","metadata":{"id":"go-UtVDjhZM1","outputId":"f423cfcf-3bdf-471c-fb4d-1424787d9c79","execution":{"iopub.status.busy":"2023-08-26T15:28:53.506478Z","iopub.execute_input":"2023-08-26T15:28:53.506911Z","iopub.status.idle":"2023-08-26T15:28:53.538404Z","shell.execute_reply.started":"2023-08-26T15:28:53.506877Z","shell.execute_reply":"2023-08-26T15:28:53.536661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for missing values in all the columnns of reuters headlines dataset\nreuters_df.isnull().sum()","metadata":{"id":"7d7HOHV7hZJM","outputId":"b60f3758-a698-45ad-ec28-c22e424997f3","execution":{"iopub.status.busy":"2023-08-26T15:28:53.543387Z","iopub.execute_input":"2023-08-26T15:28:53.543715Z","iopub.status.idle":"2023-08-26T15:28:53.569071Z","shell.execute_reply.started":"2023-08-26T15:28:53.543688Z","shell.execute_reply":"2023-08-26T15:28:53.567463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropp the duplicate rows in reuters headlines dataset and keep the first one\nreuters_df = reuters_df.drop_duplicates(keep='first')\nreuters_df","metadata":{"id":"Zvbdb747hZHz","outputId":"d9926a4c-1074-4c12-e41e-7607561c38fd","execution":{"iopub.status.busy":"2023-08-26T15:28:53.571045Z","iopub.execute_input":"2023-08-26T15:28:53.571386Z","iopub.status.idle":"2023-08-26T15:28:53.624756Z","shell.execute_reply.started":"2023-08-26T15:28:53.571357Z","shell.execute_reply":"2023-08-26T15:28:53.623282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making some functions that we will need  ahead","metadata":{"id":"2uvArOVne6jB"}},{"cell_type":"markdown","source":"### Preprocessing ","metadata":{"id":"94zINn2npv1V"}},{"cell_type":"markdown","source":"1. **Lowercase** - It is necessary to convert the text to lower case as it is case sensitive.\n\n2. **Remove punctuations** -  The punctuations present in the text do not add value to the data. The punctuation, when attached to any word, will create a problem in differentiating with other words. so we have to get rid of them.\n\n3. **Remove stopwords** -  Stopwords include: I, he, she, and, but, was were, being, have, etc, which do not add meaning to the data. So these words must be removed which helps to reduce the features from our data. These are removed after tokenizing the text.\n\n4. **Stemming** -  A technique that takes the word to its root form. It just removes suffixes from the words. The stemmed word might not be part of the dictionary, i.e it will not necessarily give meaning.\n\n5. **lemmatizing** -  Takes the word to its root form called Lemma. It helps to bring words to their dictionary form. It is applied to nouns by default. It is more accurate as it uses more informed analysis to create groups of words with similar meanings based on the context, so it is complex and takes more time. This is used where we need to retain the contextual information.\n","metadata":{"id":"nV7crjnBpyX9"}},{"cell_type":"code","source":"# Create a function for preprocessing \n\ndef preprocess_text(text, stemming=False, lemmatizing=False):\n    # Convert text to lowercase\n    text = text.lower()\n    \n    # Remove punctuation\n    text = ''.join([char for char in text if char.isalnum() or char.isspace()])\n    \n    # Remove stopwords\n    stop_words = set(stopwords.words('english'))\n    words = [word for word in text.split() if word not in stop_words]\n    \n    # Apply stemming if specified\n    if stemming:\n        stemmer = PorterStemmer()\n        words = [stemmer.stem(word) for word in words]\n    \n    # Apply lemmatizing if specified\n    if lemmatizing:\n        lemmatizer = WordNetLemmatizer()\n        words = [lemmatizer.lemmatize(word) for word in words]\n    \n    # Join the preprocessed words back into a sentence\n    processed_text = ' '.join(words)\n    \n    return processed_text  ","metadata":{"id":"djtZVA_IhY9b","execution":{"iopub.status.busy":"2023-08-26T15:28:53.625758Z","iopub.execute_input":"2023-08-26T15:28:53.626113Z","iopub.status.idle":"2023-08-26T15:28:53.634366Z","shell.execute_reply.started":"2023-08-26T15:28:53.626081Z","shell.execute_reply":"2023-08-26T15:28:53.632703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets begin Sentiment Analysis","metadata":{"id":"pjlDZ7Peu7t1"}},{"cell_type":"code","source":"# Import sentiment intensity analyzer\n\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nnltk.download('vader_lexicon')\n\n\n# Create a SentimentIntensityAnalyzer object\nsia = SentimentIntensityAnalyzer()","metadata":{"id":"HUxqpmosB6vy","outputId":"77151daa-a298-4a80-eaa6-f5dc11a340f1","execution":{"iopub.status.busy":"2023-08-26T15:28:53.635855Z","iopub.execute_input":"2023-08-26T15:28:53.636193Z","iopub.status.idle":"2023-08-26T15:28:53.668716Z","shell.execute_reply.started":"2023-08-26T15:28:53.636165Z","shell.execute_reply":"2023-08-26T15:28:53.666930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fuction to  decide sentiment as positive, negative and neutral\ndef get_sentiment_label(text):\n    sia = SentimentIntensityAnalyzer()\n    sentiment_scores = sia.polarity_scores(text)\n    \n    # Decide sentiment label based on compound score\n    compound_score = sentiment_scores['compound']\n    if compound_score >= 0.05:\n        return 'Positive'\n    elif compound_score <= -0.05:\n        return 'Negative'\n    else:\n        return 'Neutral'\n\n# Example usage\nheadline = \"Stock Market Soars Amid Positive Earnings Reports\"\nsentiment_label = get_sentiment_label(headline)\nprint(\"Sentiment Label:\", sentiment_label)\n","metadata":{"id":"GscOEWSjGfa2","execution":{"iopub.status.busy":"2023-08-26T15:28:53.669730Z","iopub.execute_input":"2023-08-26T15:28:53.670080Z","iopub.status.idle":"2023-08-26T15:28:53.685649Z","shell.execute_reply.started":"2023-08-26T15:28:53.670049Z","shell.execute_reply":"2023-08-26T15:28:53.684048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now working with description on datasets","metadata":{"id":"RVa-zf7xfRjc"}},{"cell_type":"code","source":"# Concatenate cnbc headlines dataset and reuters headline dataset\ncombined_df = pd.concat([cnbc_df, reuters_df], ignore_index=True)","metadata":{"id":"NFS1pS0Zws6Z","execution":{"iopub.status.busy":"2023-08-26T15:28:53.686970Z","iopub.execute_input":"2023-08-26T15:28:53.687311Z","iopub.status.idle":"2023-08-26T15:28:53.698104Z","shell.execute_reply.started":"2023-08-26T15:28:53.687281Z","shell.execute_reply":"2023-08-26T15:28:53.697036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the shape of this new dataset\ncombined_df.shape","metadata":{"id":"eDgz1y9Cwzfm","outputId":"f5a8a761-7f1b-4997-dee9-f4cb89f98268","execution":{"iopub.status.busy":"2023-08-26T15:28:53.699829Z","iopub.execute_input":"2023-08-26T15:28:53.700193Z","iopub.status.idle":"2023-08-26T15:28:53.713742Z","shell.execute_reply.started":"2023-08-26T15:28:53.700162Z","shell.execute_reply":"2023-08-26T15:28:53.712692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a copy of new dataset \ncombined_df_copy = combined_df.copy()","metadata":{"id":"u0v43468m4d0","execution":{"iopub.status.busy":"2023-08-26T15:28:53.714767Z","iopub.execute_input":"2023-08-26T15:28:53.715895Z","iopub.status.idle":"2023-08-26T15:28:53.728841Z","shell.execute_reply.started":"2023-08-26T15:28:53.715827Z","shell.execute_reply":"2023-08-26T15:28:53.727917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_df_copy","metadata":{"execution":{"iopub.status.busy":"2023-08-26T15:28:53.730017Z","iopub.execute_input":"2023-08-26T15:28:53.731470Z","iopub.status.idle":"2023-08-26T15:28:53.748236Z","shell.execute_reply.started":"2023-08-26T15:28:53.731423Z","shell.execute_reply":"2023-08-26T15:28:53.746962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply preprocessing function to the 'Description' of new dataset (combined_df_copy)\ncombined_df_copy['Description'] = combined_df_copy['Description'].apply(preprocess_text)\n\n# Display the first few rows of the DataFrame after preprocessing\ncombined_df_copy.head()\n","metadata":{"id":"KMejFN4HhY44","outputId":"59c6d813-245a-41f4-e2d9-b30f6921e669","execution":{"iopub.status.busy":"2023-08-26T15:28:53.749605Z","iopub.execute_input":"2023-08-26T15:28:53.750097Z","iopub.status.idle":"2023-08-26T15:28:58.577492Z","shell.execute_reply.started":"2023-08-26T15:28:53.750072Z","shell.execute_reply":"2023-08-26T15:28:58.575717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Calculate Polarity Score\n\nPolarity score is a metric used in sentiment analysis to quantify the sentiment or emotion expressed in a piece of text. It indicates whether the text expresses a positive, negative, or neutral sentiment. Polarity scores are typically numerical values that range from -1 to 1:\n\n    A polarity score of 1 indicates a highly positive sentiment.\n    A polarity score of -1 indicates a highly negative sentiment.\n    A polarity score close to 0 indicates a neutral sentiment.\n\nPolarity scores are often calculated using various natural language processing techniques, including lexicon-based methods, machine learning models, and rule-based systems. In the context of sentiment analysis, polarity scores are used to determine the sentiment of a text and categorize it as positive, negative, or neutral based on the calculated score.\n\nIn NLTK's SentimentIntensityAnalyzer, the **polarity_scores()** function computes a polarity score for a given text, providing values for positive, negative, neutral, and compound sentiments. The compound sentiment score is often used to make overall sentiment predictions, as it combines all three sentiment components into a single value.","metadata":{}},{"cell_type":"code","source":"# Analyze polarity score of values in description and  add new column ''ds_score'' in dataset\ndef get_sentiment_score(text):\n    sia = SentimentIntensityAnalyzer()\n    sentiment_scores = sia.polarity_scores(text)\n    return sentiment_scores['compound']\n\ncombined_df_copy['ds_score'] = combined_df_copy['Description'].apply(get_sentiment_score)\n\ncombined_df_copy.head()","metadata":{"id":"l97AoQKkhYzb","outputId":"984cc92c-5215-44d0-881e-a6947d580b96","execution":{"iopub.status.busy":"2023-08-26T15:28:58.579112Z","iopub.execute_input":"2023-08-26T15:28:58.579404Z","iopub.status.idle":"2023-08-26T15:32:35.629013Z","shell.execute_reply.started":"2023-08-26T15:28:58.579379Z","shell.execute_reply":"2023-08-26T15:32:35.627615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply the function  which decides sentiment to  polarity score column\n\n# Create a function to decide sentiment label based on polarity score\ndef decide_sentiment_label(score):\n    if score >= 0.05:\n        return 'Positive'\n    elif score <= -0.05:\n        return 'Negative'\n    else:\n        return 'Neutral'\n\n# Apply the decide_sentiment_label function to the 'ds_score' column\ncombined_df_copy['sentiment_label'] = combined_df_copy['ds_score'].apply(decide_sentiment_label)\n\n","metadata":{"id":"c9Aq-sQ7hYu_","outputId":"6f50dd1a-ba4c-4708-82ea-ed7a75459a89","execution":{"iopub.status.busy":"2023-08-26T15:32:35.630123Z","iopub.execute_input":"2023-08-26T15:32:35.630459Z","iopub.status.idle":"2023-08-26T15:32:35.647666Z","shell.execute_reply.started":"2023-08-26T15:32:35.630431Z","shell.execute_reply":"2023-08-26T15:32:35.646066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Display the first few rows of the DataFrame with the new sentiment label column\ncombined_df_copy.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-26T15:32:35.649071Z","iopub.execute_input":"2023-08-26T15:32:35.649415Z","iopub.status.idle":"2023-08-26T15:32:35.669935Z","shell.execute_reply.started":"2023-08-26T15:32:35.649387Z","shell.execute_reply":"2023-08-26T15:32:35.668389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculating the sum of each unique sentiment label\nsentiment_label_counts = combined_df_copy['sentiment_label'].value_counts()\n\nprint(sentiment_label_counts)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T15:32:35.671505Z","iopub.execute_input":"2023-08-26T15:32:35.671858Z","iopub.status.idle":"2023-08-26T15:32:35.687681Z","shell.execute_reply.started":"2023-08-26T15:32:35.671828Z","shell.execute_reply":"2023-08-26T15:32:35.686748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Make Count plot for Sentiment Label\n\nplt.figure(figsize=(5, 3))\nsns.countplot(data=combined_df_copy, x='sentiment_label')\nplt.title('Sentiment Label Count')\nplt.xlabel('Sentiment Label')\nplt.ylabel('Count')\nplt.show()","metadata":{"id":"BMaNV0ayeBoI","outputId":"34766863-6362-45a5-c27d-a7baf76e6223","execution":{"iopub.status.busy":"2023-08-26T15:32:35.688723Z","iopub.execute_input":"2023-08-26T15:32:35.689464Z","iopub.status.idle":"2023-08-26T15:32:36.240350Z","shell.execute_reply.started":"2023-08-26T15:32:35.689430Z","shell.execute_reply":"2023-08-26T15:32:36.239085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the description \n\nthere are approx\n\n16000 positive statment\n\n12000 negative statment\n\n6000 neutral statment","metadata":{"id":"r5q_doOjIQu-"}},{"cell_type":"code","source":"# Pie chart on description score column\n\n# Calculate the counts of each sentiment label\nsentiment_counts = combined_df_copy['sentiment_label'].value_counts()\n\n# Create a pie chart for the sentiment labels\nplt.figure(figsize=(5, 3))\nplt.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=140)\nplt.title('Sentiment Label Distribution')\nplt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\nplt.show()","metadata":{"id":"ptvoU5apeN4N","outputId":"32e707ce-18f6-4fdc-a06d-f20e8322d5b3","execution":{"iopub.status.busy":"2023-08-26T15:32:36.242259Z","iopub.execute_input":"2023-08-26T15:32:36.242679Z","iopub.status.idle":"2023-08-26T15:32:36.358629Z","shell.execute_reply.started":"2023-08-26T15:32:36.242645Z","shell.execute_reply":"2023-08-26T15:32:36.357695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelling on Description ","metadata":{"id":"wgt0f3fKfakl"}},{"cell_type":"code","source":"# Split the dataset  into test and train \n# 90% train , 10% test and random state 212\n\nfrom sklearn.model_selection import train_test_split\n\n# Define the features and target variable\nX = combined_df_copy['Description']  # Features\ny = combined_df_copy['sentiment_label']  # Target variable\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=212)\n\n# Print the shape of the training and testing sets\nprint(\"X_train shape:\", X_train.shape)\nprint(\"X_test shape:\", X_test.shape)\nprint(\"y_train shape:\", y_train.shape)\nprint(\"y_test shape:\", y_test.shape)\n","metadata":{"id":"pOd6wPeUhYd2","execution":{"iopub.status.busy":"2023-08-26T15:35:41.257475Z","iopub.execute_input":"2023-08-26T15:35:41.257821Z","iopub.status.idle":"2023-08-26T15:35:41.274352Z","shell.execute_reply.started":"2023-08-26T15:35:41.257792Z","shell.execute_reply":"2023-08-26T15:35:41.272669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## (1) LINEAR SUPPORT VECTOR MACHINE\n","metadata":{"id":"hVuDdLFJkFSb"}},{"cell_type":"code","source":"%%time\n# pipeline creation\n# 1. tfidVectorization\n# 2. linearSVC model\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n\n# Create a pipeline with TfidfVectorizer and LinearSVC\npipeline = Pipeline([\n    ('tfidf', TfidfVectorizer()),\n    ('model', LinearSVC())\n])\n\n# Fit the pipeline to the training data\npipeline.fit(X_train, y_train)\n\n# Predict on the test dataset\ny_pred = pipeline.predict(X_test)\n\n# Calculate accuracy score\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"accuracy score: {:.2f}%\".format(accuracy * 100))\n\n# Print confusion matrix\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n\n# Print classification report\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","metadata":{"id":"exk6nRwomgAt","outputId":"5de5fd8f-a60c-4317-9c81-2baf81621a40","execution":{"iopub.status.busy":"2023-08-26T15:37:40.393021Z","iopub.execute_input":"2023-08-26T15:37:40.393371Z","iopub.status.idle":"2023-08-26T15:37:41.969507Z","shell.execute_reply.started":"2023-08-26T15:37:40.393344Z","shell.execute_reply":"2023-08-26T15:37:41.968606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## (2) LOGISTIC REGRESSION\n","metadata":{"id":"6Qq4dK32kBpM"}},{"cell_type":"code","source":"%%time\n# pipeline creation \n# 1. CountVectorization\n# 2. TfidTransformer\n# 3. Logistic Regression\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n\n# Create a pipeline with CountVectorizer, TfidfTransformer, and Logistic Regression\npipeline = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('model', LogisticRegression())\n])\n\n# Fit the pipeline to the training data\npipeline.fit(X_train, y_train)\n\n# Predict on the test dataset\ny_pred = pipeline.predict(X_test)\n\n# Calculate accuracy score\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"accuracy score: {:.2f}%\".format(accuracy * 100))\n\n# Print confusion matrix\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n\n# Print classification report\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","metadata":{"id":"0w0yNn2_mf_s","outputId":"17175fb5-83c7-4204-f358-42007a8f2168","execution":{"iopub.status.busy":"2023-08-26T15:41:09.296934Z","iopub.execute_input":"2023-08-26T15:41:09.297305Z","iopub.status.idle":"2023-08-26T15:41:14.125324Z","shell.execute_reply.started":"2023-08-26T15:41:09.297278Z","shell.execute_reply":"2023-08-26T15:41:14.123869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## (3) MULTINOMIAL NAIVE BAYES\n","metadata":{"id":"XbFrK_pXj-HC"}},{"cell_type":"code","source":"%%time\n# pipeline creation \n# 1. CountVectorizer\n# 2. TfidTransformer\n# 3. MultinomialNB\n \nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n\n# Create a pipeline with CountVectorizer, TfidfTransformer, and Multinomial Naive Bayes\npipeline = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('model', MultinomialNB())\n])\n\n# Fit the pipeline to the training data\npipeline.fit(X_train, y_train)\n\n# Predict on the test dataset\ny_pred = pipeline.predict(X_test)\n\n# Calculate accuracy score\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"accuracy score: {:.2f}%\".format(accuracy * 100))\n\n# Print confusion matrix\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n\n# Print classification report\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","metadata":{"id":"ag3ceKiEmfxR","outputId":"2d14e551-23eb-4ced-d133-e5fd561f7c72","execution":{"iopub.status.busy":"2023-08-26T15:42:13.899971Z","iopub.execute_input":"2023-08-26T15:42:13.900384Z","iopub.status.idle":"2023-08-26T15:42:14.777871Z","shell.execute_reply.started":"2023-08-26T15:42:13.900356Z","shell.execute_reply":"2023-08-26T15:42:14.776956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## (4) BERNOULLI NAIVE BAYES\n","metadata":{"id":"-79YSosbj7HP"}},{"cell_type":"code","source":"%%time\n# pipeline creation \n# 1. CountVectorizer\n# 2. TfidTransformer\n# 3. BernoulliNB\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n\n# Create a pipeline with CountVectorizer, TfidfTransformer, and Bernoulli Naive Bayes\npipeline = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('model', BernoulliNB())\n])\n\n# Fit the pipeline to the training data\npipeline.fit(X_train, y_train)\n\n# Predict on the test dataset\ny_pred = pipeline.predict(X_test)\n\n# Calculate accuracy score\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"accuracy score: {:.2f}%\".format(accuracy * 100))\n\n# Print confusion matrix\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n\n# Print classification report\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","metadata":{"id":"N-ftjtoEmfsP","outputId":"fc46a6c1-da3e-46e4-a2f1-37e562cf708c","execution":{"iopub.status.busy":"2023-08-26T15:43:36.587566Z","iopub.execute_input":"2023-08-26T15:43:36.587923Z","iopub.status.idle":"2023-08-26T15:43:37.492432Z","shell.execute_reply.started":"2023-08-26T15:43:36.587895Z","shell.execute_reply":"2023-08-26T15:43:37.490813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## (5) GRADIENT BOOSTING CLASSIFICATION MODEL\n","metadata":{"id":"DDcEnl9uj3yl"}},{"cell_type":"code","source":"%%time\n# pipeline creation \n# 1. CountVectorizer\n# 2. TfidTransformer\n# 3. GradientBoostingClassifier\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n\n# Create a pipeline with CountVectorizer, TfidfTransformer, and Gradient Boosting Classifier\npipeline = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('model', GradientBoostingClassifier())\n])\n\n# Fit the pipeline to the training data\npipeline.fit(X_train, y_train)\n\n# Predict on the test dataset\ny_pred = pipeline.predict(X_test)\n\n# Calculate accuracy score\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"accuracy score: {:.2f}%\".format(accuracy * 100))\n\n# Print confusion matrix\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n\n# Print classification report\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))","metadata":{"id":"vTT-HmujmfrR","outputId":"8987cfa9-952f-4c27-cd42-452a26a479bb","execution":{"iopub.status.busy":"2023-08-26T15:44:23.275119Z","iopub.execute_input":"2023-08-26T15:44:23.275551Z","iopub.status.idle":"2023-08-26T15:46:03.039626Z","shell.execute_reply.started":"2023-08-26T15:44:23.275521Z","shell.execute_reply":"2023-08-26T15:46:03.038045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## (6) XGBOOST CLASSIFICATION MODEL\n","metadata":{"id":"hwMk-HFAjzP-"}},{"cell_type":"code","source":"%%time\n# pipeline creation \n# 1. CountVectorizer\n# 2. TfidTransformer\n# 3. XGBClassifier\n\nfrom sklearn.preprocessing import LabelEncoder\n\n\n# Create a label encoder\nlabel_encoder = LabelEncoder()\n\n# Fit the label encoder on the sentiment labels and transform them to numerical values\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\n# Create a pipeline with CountVectorizer, TfidfTransformer, and XGBoost Classifier\npipeline = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('model', XGBClassifier())\n])\n\n# Fit the pipeline to the training data\npipeline.fit(X_train, y_train_encoded)\n\n# Predict on the test dataset\ny_pred_encoded = pipeline.predict(X_test)\n\n# Calculate accuracy score\naccuracy = accuracy_score(y_test_encoded, y_pred_encoded)\nprint(\"accuracy score: {:.2f}%\".format(accuracy * 100))\n\n# Print confusion matrix\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test_encoded, y_pred_encoded))\n\n# Print classification report\nprint(\"Classification Report:\\n\", classification_report(y_test_encoded, y_pred_encoded, target_names=label_encoder.classes_))\n","metadata":{"id":"1M8E7hmnmfn1","outputId":"739370a5-ba74-4119-8f09-591adaed55f7","execution":{"iopub.status.busy":"2023-08-26T15:48:17.844919Z","iopub.execute_input":"2023-08-26T15:48:17.845281Z","iopub.status.idle":"2023-08-26T15:48:48.845226Z","shell.execute_reply.started":"2023-08-26T15:48:17.845252Z","shell.execute_reply":"2023-08-26T15:48:48.843739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## (7) DECISION TREE CLASSIFICATION MODEL\n","metadata":{"id":"8RvWy4tSjwDV"}},{"cell_type":"code","source":"%%time\n# pipeline creation \n# 1. CountVectorizer\n# 2. TfidTransformer\n# 3. Decision tree classifier\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# Assuming you have already split the data into X_train, X_test, y_train, y_test\n# If not, please refer to the previous code snippets\n\n# Create a pipeline with CountVectorizer, TfidfTransformer, and Decision Tree Classifier\npipeline = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('model', DecisionTreeClassifier())\n])\n\n# Fit the pipeline to the training data\npipeline.fit(X_train, y_train)\n\n# Predict on the test dataset\ny_pred = pipeline.predict(X_test)\n\n# Calculate accuracy score\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"accuracy score: {:.2f}%\".format(accuracy * 100))\n\n# Print confusion matrix\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n\n# Print classification report\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n","metadata":{"id":"63xamISqmfmd","outputId":"f4c8b146-0b8b-49a0-bd3a-b40f67372709","execution":{"iopub.status.busy":"2023-08-26T16:01:20.364356Z","iopub.execute_input":"2023-08-26T16:01:20.364884Z","iopub.status.idle":"2023-08-26T16:01:42.276176Z","shell.execute_reply.started":"2023-08-26T16:01:20.364845Z","shell.execute_reply":"2023-08-26T16:01:42.275057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## (8) K- NEAREST NEIGHBOUR CLASSIFIER MODEL\n","metadata":{"id":"LenIHULAjsrv"}},{"cell_type":"code","source":"%%time\n# pipeline creation \n# 1. CountVectorizer\n# 2. TfidTransformer\n# 3. KNN classifier\n\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n\n# Create a pipeline with CountVectorizer, TfidfTransformer, and K-Nearest Neighbors Classifier\npipeline = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('model', KNeighborsClassifier())\n])\n\n# Fit the pipeline to the training data\npipeline.fit(X_train, y_train)\n\n# Predict on the test dataset\ny_pred = pipeline.predict(X_test)\n\n# Calculate accuracy score\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"accuracy score: {:.2f}%\".format(accuracy * 100))\n\n# Print confusion matrix\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n\n# Print classification report\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))","metadata":{"id":"UtU2_7-MzQ6N","outputId":"ed7a03b4-1efd-432f-e1d2-aa0e4f2375e8","execution":{"iopub.status.busy":"2023-08-26T16:02:47.107571Z","iopub.execute_input":"2023-08-26T16:02:47.108007Z","iopub.status.idle":"2023-08-26T16:03:10.584741Z","shell.execute_reply.started":"2023-08-26T16:02:47.107955Z","shell.execute_reply":"2023-08-26T16:03:10.583436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Comparing all models metrics","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.svm import LinearSVC\nfrom sklearn.naive_bayes import MultinomialNB, BernoulliNB\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Create a helper function to compare metrics\ndef compare_models(models, X_train, X_test, y_train, y_test):\n    # Initialize an empty DataFrame to store metrics\n    metrics_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Confusion Matrix', 'Classification Report'])\n    \n    # Create a label encoder to convert sentiment labels to numerical values\n    label_encoder = LabelEncoder()\n    y_train_encoded = label_encoder.fit_transform(y_train)\n    y_test_encoded = label_encoder.transform(y_test)\n    \n    for model_name, model in models.items():\n        # Create a pipeline with CountVectorizer, TfidfTransformer, and the current model\n        pipeline = Pipeline([\n            ('vect', CountVectorizer()),\n            ('tfidf', TfidfTransformer()),\n            ('model', model)\n        ])\n        \n        # Fit the pipeline to the training data\n        pipeline.fit(X_train, y_train_encoded)\n        \n        # Predict on the test dataset\n        y_pred_encoded = pipeline.predict(X_test)\n        \n        # Calculate accuracy score\n        accuracy = accuracy_score(y_test_encoded, y_pred_encoded)\n        \n        # Calculate confusion matrix\n        conf_matrix = confusion_matrix(y_test_encoded, y_pred_encoded)\n        \n        # Calculate classification report\n        class_report = classification_report(y_test_encoded, y_pred_encoded, output_dict=True, target_names=label_encoder.classes_)\n        \n        # Append metrics to the DataFrame\n        metrics_df = metrics_df.append({\n            'Model': model_name,\n            'Accuracy': accuracy,\n            'Confusion Matrix': conf_matrix,\n            'Classification Report': class_report\n        }, ignore_index=True)\n    \n    return metrics_df\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-26T16:13:59.771295Z","iopub.execute_input":"2023-08-26T16:13:59.771654Z","iopub.status.idle":"2023-08-26T16:13:59.782229Z","shell.execute_reply.started":"2023-08-26T16:13:59.771625Z","shell.execute_reply":"2023-08-26T16:13:59.780594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the models you want to compare\nmodels = {\n    'LinearSVC': LinearSVC(),\n    'MultinomialNB': MultinomialNB(),\n    'BernoulliNB': BernoulliNB(),\n    'GradientBoostingClassifier': GradientBoostingClassifier(),\n    'XGBClassifier': XGBClassifier(),\n    'DecisionTreeClassifier': DecisionTreeClassifier(),\n    'KNeighborsClassifier': KNeighborsClassifier()\n}\n\n# Call the helper function to compare metrics\nmetrics_comparison = compare_models(models, X_train, X_test, y_train, y_test)\n\n# Display the metrics comparison DataFrame\nprint(metrics_comparison)\n","metadata":{"id":"4A6ZI1hQwkhO","outputId":"bd76815b-6c62-4ff0-c201-5ef627257d9e","execution":{"iopub.status.busy":"2023-08-26T16:14:07.969132Z","iopub.execute_input":"2023-08-26T16:14:07.969492Z","iopub.status.idle":"2023-08-26T16:16:59.189941Z","shell.execute_reply.started":"2023-08-26T16:14:07.969464Z","shell.execute_reply":"2023-08-26T16:16:59.188154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics_comparison","metadata":{"execution":{"iopub.status.busy":"2023-08-26T16:18:47.308028Z","iopub.execute_input":"2023-08-26T16:18:47.308409Z","iopub.status.idle":"2023-08-26T16:18:47.340699Z","shell.execute_reply.started":"2023-08-26T16:18:47.308380Z","shell.execute_reply":"2023-08-26T16:18:47.339930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Working with Test Dataset","metadata":{"id":"YxNC09uekdZH"}},{"cell_type":"code","source":"# Perform the prediction on the test dataset\nfrom sklearn.svm import LinearSVC\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n\n# Create a pipeline with CountVectorizer, TfidfTransformer, and LinearSVC\nbest_model_pipeline = Pipeline([\n    ('vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('model', LinearSVC())\n])\n\n# Fit the pipeline to the training data\nbest_model_pipeline.fit(X_train, y_train_encoded)\n\n# Predict on the test dataset\ny_pred_encoded = best_model_pipeline.predict(X_test)\n\n# Inverse transform numerical predictions back to original sentiment labels\ny_pred = label_encoder.inverse_transform(y_pred_encoded)\n\n# Print the predicted sentiment labels\nprint(\"Predicted Sentiment Labels:\\n\", y_pred)","metadata":{"id":"P_XD4m1Fkh3i","outputId":"bfaa4a5b-f52a-4064-8e5c-66b939deab41","execution":{"iopub.status.busy":"2023-08-26T16:19:54.785886Z","iopub.execute_input":"2023-08-26T16:19:54.786262Z","iopub.status.idle":"2023-08-26T16:19:56.243600Z","shell.execute_reply.started":"2023-08-26T16:19:54.786234Z","shell.execute_reply":"2023-08-26T16:19:56.242996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Creating a dataframe of predicted results \n\n# Create a dictionary to store the predicted results\npredicted_results = {\n    'Headline': X_test,  # Assuming X_test contains the original headlines\n    'Predicted Sentiment': y_pred,\n    'Actual Sentiment': y_test\n}\n\n# Convert the dictionary to a DataFrame\npredicted_results_df = pd.DataFrame(predicted_results)\n\n# Print the DataFrame containing predicted results\npredicted_results_df","metadata":{"id":"U4cHKaw6khr_","execution":{"iopub.status.busy":"2023-08-26T16:21:40.247338Z","iopub.execute_input":"2023-08-26T16:21:40.247722Z","iopub.status.idle":"2023-08-26T16:21:40.267819Z","shell.execute_reply.started":"2023-08-26T16:21:40.247693Z","shell.execute_reply":"2023-08-26T16:21:40.265766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Finding Test Accuracy!","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# Calculate accuracy score\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)\n\n# Calculate confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\\n\", conf_matrix)\n\n# Calculate classification report\nclass_report = classification_report(y_test, y_pred, target_names=label_encoder.classes_)\nprint(\"Classification Report:\\n\", class_report)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-26T16:23:34.648589Z","iopub.execute_input":"2023-08-26T16:23:34.649041Z","iopub.status.idle":"2023-08-26T16:23:34.754858Z","shell.execute_reply.started":"2023-08-26T16:23:34.649005Z","shell.execute_reply":"2023-08-26T16:23:34.753594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Awesome! We have 84% Test Accuracy!**","metadata":{}},{"cell_type":"markdown","source":"# Now working with headlines + description","metadata":{"id":"LcDOjy2MfkG2"}},{"cell_type":"markdown","source":"Performing sentiment analysis on both headlines and descriptions can provide a more comprehensive understanding of the sentiment expressed in financial news articles.\n\nHere are a few reasons why analyzing both headlines and descriptions could be valuable:\n\n1.    Richer Context: Headlines provide a concise summary of the article's main theme, while descriptions offer more detailed information. By analyzing both, you can capture the sentiment of the main idea as well as the supporting context.\n\n2.    Nuanced Sentiment: Headlines often focus on attracting attention, which can sometimes result in sensationalism. Descriptions, on the other hand, may contain more nuanced and balanced sentiment.\n\n3.    Detection of Changes: Sentiment can change from the headline to the description, reflecting shifts in the article's tone or focus. Analyzing both can help detect these changes.\n\n4.    Performance Improvement: Combining multiple sources of information (headlines and descriptions) can potentially lead to better sentiment analysis results, as one source might compensate for limitations in the other.\n\n5.    Informed Decision-Making: In financial contexts, understanding sentiment is crucial for making informed decisions. By analyzing both headlines and descriptions, you can gain deeper insights into market perceptions and trends.\n\n6.    Research and Strategy: Researchers and investors may benefit from a more thorough sentiment analysis that considers both headlines and descriptions to guide their research and investment strategies.\n\n7.    Robustness: If sentiment analysis on one source (e.g., headlines) is less accurate due to inherent biases or limitations, using another source (e.g., descriptions) can enhance the robustness of the analysis.","metadata":{}},{"cell_type":"code","source":"\n# Merge the 'Headlines' and 'Description' columns and create a new column 'Info'\ncombined_df_copy['Info'] = combined_df_copy['Headlines'] + ' ' + combined_df_copy['Description']\n\n# Print the updated DataFrame\ncombined_df_copy","metadata":{"id":"HOSweU4mzTgq","outputId":"ad66fc23-e9f7-473c-d7bb-5520937d7698","execution":{"iopub.status.busy":"2023-08-26T16:27:09.093000Z","iopub.execute_input":"2023-08-26T16:27:09.094102Z","iopub.status.idle":"2023-08-26T16:27:09.131857Z","shell.execute_reply.started":"2023-08-26T16:27:09.094063Z","shell.execute_reply":"2023-08-26T16:27:09.130305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_df_copy.columns","metadata":{"execution":{"iopub.status.busy":"2023-08-26T16:27:41.381367Z","iopub.execute_input":"2023-08-26T16:27:41.381809Z","iopub.status.idle":"2023-08-26T16:27:41.390852Z","shell.execute_reply.started":"2023-08-26T16:27:41.381777Z","shell.execute_reply":"2023-08-26T16:27:41.390024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Keep only the 'Info' and 'Time' columns and drop the remaining columns\ncombined_df_copy = combined_df_copy[['Info', 'Time']]\n\n# Print the updated DataFrame\ncombined_df_copy.head()","metadata":{"id":"_ZTFzLcGzTb3","outputId":"afd1bcb2-1616-46f3-9099-e3c48f246d50","execution":{"iopub.status.busy":"2023-08-26T16:31:59.244047Z","iopub.execute_input":"2023-08-26T16:31:59.244517Z","iopub.status.idle":"2023-08-26T16:31:59.264416Z","shell.execute_reply.started":"2023-08-26T16:31:59.244485Z","shell.execute_reply":"2023-08-26T16:31:59.263195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" # Apply the preprocessing function to the 'Info' column\ncombined_df_copy['Info'] = combined_df_copy['Info'].apply(preprocess_text)\n\n# Print the updated DataFrame\ncombined_df_copy","metadata":{"id":"iMOW0ljOzTaN","outputId":"751af887-0be3-45e1-d2cf-8e503b6a9783","execution":{"iopub.status.busy":"2023-08-26T16:33:14.858661Z","iopub.execute_input":"2023-08-26T16:33:14.859014Z","iopub.status.idle":"2023-08-26T16:33:20.075660Z","shell.execute_reply.started":"2023-08-26T16:33:14.858960Z","shell.execute_reply":"2023-08-26T16:33:20.074138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analyze polarity score of values in info and  add new column 'info_score' of it in dataset\n\n# Create a SentimentIntensityAnalyzer object\nsia = SentimentIntensityAnalyzer()\n\n# Function to calculate polarity scores\ndef get_polarity_score(text):\n    return sia.polarity_scores(text)['compound']\n","metadata":{"id":"Bww_M5RQzTXm","outputId":"0c392b14-3bc2-4766-f51b-b14e3716638e","execution":{"iopub.status.busy":"2023-08-26T16:38:11.528418Z","iopub.execute_input":"2023-08-26T16:38:11.528788Z","iopub.status.idle":"2023-08-26T16:38:11.540123Z","shell.execute_reply.started":"2023-08-26T16:38:11.528761Z","shell.execute_reply":"2023-08-26T16:38:11.539346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply the polarity score function to the 'Info' column\ncombined_df_copy['info_score'] = combined_df_copy['Info'].apply(get_polarity_score)\n\n# Print the updated DataFrame\ncombined_df_copy","metadata":{"id":"duwvemaLzTWh","outputId":"f771aff0-a319-4c10-ce87-0f1088063d82","execution":{"iopub.status.busy":"2023-08-26T16:38:25.317834Z","iopub.execute_input":"2023-08-26T16:38:25.318268Z","iopub.status.idle":"2023-08-26T16:38:38.763301Z","shell.execute_reply.started":"2023-08-26T16:38:25.318234Z","shell.execute_reply":"2023-08-26T16:38:38.761522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to map polarity scores to sentiment labels\ndef map_to_sentiment(score):\n    if score > 0.05:\n        return 'Positive'\n    elif score < -0.05:\n        return 'Negative'\n    else:\n        return 'Neutral'\n\n# Apply the mapping function to the 'info_score' column\ncombined_df_copy['info_score'] = combined_df_copy['info_score'].apply(map_to_sentiment)\n\n# Print the updated DataFrame\ncombined_df_copy","metadata":{"execution":{"iopub.status.busy":"2023-08-26T16:40:02.084684Z","iopub.execute_input":"2023-08-26T16:40:02.085354Z","iopub.status.idle":"2023-08-26T16:40:02.116514Z","shell.execute_reply.started":"2023-08-26T16:40:02.085313Z","shell.execute_reply":"2023-08-26T16:40:02.114344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform count plot on info_score column\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Create a count plot for the 'info_score' column\nplt.figure(figsize=(4, 3))\nsns.countplot(data=combined_df_copy, x='info_score')\nplt.title('Count Plot of Info Scores')\nplt.xlabel('Sentiment')\nplt.ylabel('Count')\nplt.show()","metadata":{"id":"ohPDx_0glaeM","outputId":"74fba960-52d3-4a2c-e952-8e5498b7fb61","execution":{"iopub.status.busy":"2023-08-26T16:40:45.590384Z","iopub.execute_input":"2023-08-26T16:40:45.590833Z","iopub.status.idle":"2023-08-26T16:40:45.788837Z","shell.execute_reply.started":"2023-08-26T16:40:45.590799Z","shell.execute_reply":"2023-08-26T16:40:45.787053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the sum of each type of 'info_score'\nscore_counts = combined_df_copy['info_score'].value_counts()\n\n# Print the count of each type of 'info_score'\nprint(score_counts)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-26T16:42:20.893081Z","iopub.execute_input":"2023-08-26T16:42:20.893447Z","iopub.status.idle":"2023-08-26T16:42:20.902245Z","shell.execute_reply.started":"2023-08-26T16:42:20.893417Z","shell.execute_reply":"2023-08-26T16:42:20.900837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform pie chart on info_score column\nimport matplotlib.pyplot as plt\n\n# Calculate the count of each type of 'info_score'\nscore_counts = combined_df_copy['info_score'].value_counts()\n\n# Create a pie chart\nplt.figure(figsize=(4, 3))\nplt.pie(score_counts, labels=score_counts.index, autopct='%1.1f%%', startangle=140)\nplt.title('Pie Chart of Info Scores')\nplt.show()","metadata":{"id":"BNaH0yfFll7Z","outputId":"25db852a-077a-486a-d810-b8d97fab4adc","execution":{"iopub.status.busy":"2023-08-26T16:43:44.038619Z","iopub.execute_input":"2023-08-26T16:43:44.039020Z","iopub.status.idle":"2023-08-26T16:43:44.128868Z","shell.execute_reply.started":"2023-08-26T16:43:44.038970Z","shell.execute_reply":"2023-08-26T16:43:44.128132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the dataset\n\ninfo contains\n\n48.4 % positive statments\n\n39.8% negtive statements\n\n11.3% neutral statments","metadata":{"id":"e0JsgArfmgi-"}},{"cell_type":"markdown","source":"# Model Building on headlines + description","metadata":{"id":"FDaguQJMfrML"}},{"cell_type":"code","source":"# Split the dataset  into test and train \n# 90% train , 10% test and random state 212\n\nfrom sklearn.model_selection import train_test_split\n\n# Split the dataset into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(\n    combined_df_copy['Info'],  # Features (Info column)\n    combined_df_copy['info_score'],  # Target (info_score column)\n    test_size=0.1,  # 10% test size\n    random_state=212\n)\n\n# Print the shapes of the train and test sets\nprint(\"Train set shape:\", X_train.shape)\nprint(\"Test set shape:\", X_test.shape)","metadata":{"id":"U-sjg3NEzTRd","execution":{"iopub.status.busy":"2023-08-26T16:45:10.667124Z","iopub.execute_input":"2023-08-26T16:45:10.667465Z","iopub.status.idle":"2023-08-26T16:45:10.684138Z","shell.execute_reply.started":"2023-08-26T16:45:10.667438Z","shell.execute_reply":"2023-08-26T16:45:10.682461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# (1) LINEAR SUPPORT VECTOR MACHINE\n","metadata":{"id":"h469Z39Zjjvn"}},{"cell_type":"code","source":"\n%%time\n# pipeline creation\n# 1. tfidVectorization\n# 2. linearSVC model\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# Create a pipeline with TF-IDF vectorization and LinearSVC\npipeline = Pipeline([\n    ('tfidf', TfidfVectorizer()),\n    ('model', LinearSVC())\n])\n\n# Fit the pipeline to the training data\npipeline.fit(X_train, y_train)\n\n# Predict on the test dataset\ny_pred = pipeline.predict(X_test)\n\n# Calculate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)\n\n# Calculate confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix:\\n\", conf_matrix)\n\n# Print classification report\nclass_report = classification_report(y_test, y_pred)\nprint(\"Classification Report:\\n\", class_report)\n","metadata":{"id":"atnWirUQzTQI","outputId":"bc1c5870-4985-4879-80f1-dc8928f98b4a","execution":{"iopub.status.busy":"2023-08-26T16:54:40.044738Z","iopub.execute_input":"2023-08-26T16:54:40.045148Z","iopub.status.idle":"2023-08-26T16:54:41.989571Z","shell.execute_reply.started":"2023-08-26T16:54:40.045118Z","shell.execute_reply":"2023-08-26T16:54:41.988779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# (2) LOGISTIC REGRESSION\n","metadata":{"id":"ucmhtCoTjf7H"}},{"cell_type":"code","source":"%%time\n# pipeline creation \n# 1. CountVectorization\n# 2. TfidTransformer\n# 3. Logistic Regression\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# Create a pipeline with CountVectorizer, TfidfTransformer, and Logistic Regression\npipeline_lr = Pipeline([\n    ('count_vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('model', LogisticRegression())\n])\n\n# Fit the pipeline to the training data\npipeline_lr.fit(X_train, y_train)\n\n# Predict on the test dataset\ny_pred_lr = pipeline_lr.predict(X_test)\n\n# Calculate accuracy\naccuracy_lr = accuracy_score(y_test, y_pred_lr)\nprint(\"Accuracy:\", accuracy_lr)\n\n# Calculate confusion matrix\nconf_matrix_lr = confusion_matrix(y_test, y_pred_lr)\nprint(\"Confusion Matrix:\\n\", conf_matrix_lr)\n\n# Print classification report\nclass_report_lr = classification_report(y_test, y_pred_lr)\nprint(\"Classification Report:\\n\", class_report_lr)\n","metadata":{"id":"UXsbyfc22sXR","outputId":"8c47b13d-6bf9-4cf6-cbc6-4f6712f72db7","execution":{"iopub.status.busy":"2023-08-26T16:56:19.785082Z","iopub.execute_input":"2023-08-26T16:56:19.785474Z","iopub.status.idle":"2023-08-26T16:56:24.582362Z","shell.execute_reply.started":"2023-08-26T16:56:19.785444Z","shell.execute_reply":"2023-08-26T16:56:24.581378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# (3) MULTINOMIAL NAIVE BAYES\n","metadata":{"id":"ozLeBo9qjdNR"}},{"cell_type":"code","source":"%%time\n# pipeline creation \n# 1. CountVectorizer\n# 2. TfidTransformer\n# 3. MultinomialNB\n\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# Create a pipeline with CountVectorizer, TfidfTransformer, and Multinomial Naive Bayes\npipeline_nb = Pipeline([\n    ('count_vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('model', MultinomialNB())\n])\n\n# Fit the pipeline to the training data\npipeline_nb.fit(X_train, y_train)\n\n# Predict on the test dataset\ny_pred_nb = pipeline_nb.predict(X_test)\n\n# Calculate accuracy\naccuracy_nb = accuracy_score(y_test, y_pred_nb)\nprint(\"Accuracy:\", accuracy_nb)\n\n# Calculate confusion matrix\nconf_matrix_nb = confusion_matrix(y_test, y_pred_nb)\nprint(\"Confusion Matrix:\\n\", conf_matrix_nb)\n\n# Print classification report\nclass_report_nb = classification_report(y_test, y_pred_nb)\nprint(\"Classification Report:\\n\", class_report_nb)\n","metadata":{"id":"kxTsmokz2sVw","outputId":"87aedc65-0edf-4775-a543-29617044ca95","execution":{"iopub.status.busy":"2023-08-26T17:00:09.570019Z","iopub.execute_input":"2023-08-26T17:00:09.570410Z","iopub.status.idle":"2023-08-26T17:00:10.690724Z","shell.execute_reply.started":"2023-08-26T17:00:09.570378Z","shell.execute_reply":"2023-08-26T17:00:10.689160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# (4) BERNOULLI NAIVE BAYES\n","metadata":{"id":"91Ms-94_jaKm"}},{"cell_type":"code","source":"%%time\n# pipeline creation \n# 1. CountVectorizer\n# 2. TfidTransformer\n# 3. BernoulliNB\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# Create a pipeline with CountVectorizer, TfidfTransformer, and Bernoulli Naive Bayes\npipeline_bnb = Pipeline([\n    ('count_vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('model', BernoulliNB())\n])\n\n# Fit the pipeline to the training data\npipeline_bnb.fit(X_train, y_train)\n\n# Predict on the test dataset\ny_pred_bnb = pipeline_bnb.predict(X_test)\n\n# Calculate accuracy\naccuracy_bnb = accuracy_score(y_test, y_pred_bnb)\nprint(\"Accuracy:\", accuracy_bnb)\n\n# Calculate confusion matrix\nconf_matrix_bnb = confusion_matrix(y_test, y_pred_bnb)\nprint(\"Confusion Matrix:\\n\", conf_matrix_bnb)\n\n# Print classification report\nclass_report_bnb = classification_report(y_test, y_pred_bnb)\nprint(\"Classification Report:\\n\", class_report_bnb)\n","metadata":{"id":"Tx_-8y_x2sSO","outputId":"131fa1a0-1fdc-46e0-8b22-9d6f77a01758","execution":{"iopub.status.busy":"2023-08-26T17:03:38.227044Z","iopub.execute_input":"2023-08-26T17:03:38.227408Z","iopub.status.idle":"2023-08-26T17:03:39.357283Z","shell.execute_reply.started":"2023-08-26T17:03:38.227381Z","shell.execute_reply":"2023-08-26T17:03:39.355623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# (5) GRADIENT BOOSTING CLASSIFICATION MODEL\n","metadata":{"id":"N1OOQeVmjWjx"}},{"cell_type":"code","source":"%%time\n# pipeline creation \n# 1. CountVectorizer\n# 2. TfidTransformer\n# 3. GradientBoostingClassifier\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# Create a pipeline with CountVectorizer, TfidfTransformer, and Gradient Boosting Classifier\npipeline_gb = Pipeline([\n    ('count_vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('model', GradientBoostingClassifier())\n])\n\n# Fit the pipeline to the training data\npipeline_gb.fit(X_train, y_train)\n\n# Predict on the test dataset\ny_pred_gb = pipeline_gb.predict(X_test)\n\n# Calculate accuracy\naccuracy_gb = accuracy_score(y_test, y_pred_gb)\nprint(\"Accuracy:\", accuracy_gb)\n\n# Calculate confusion matrix\nconf_matrix_gb = confusion_matrix(y_test, y_pred_gb)\nprint(\"Confusion Matrix:\\n\", conf_matrix_gb)\n\n# Print classification report\nclass_report_gb = classification_report(y_test, y_pred_gb)\nprint(\"Classification Report:\\n\", class_report_gb)\n","metadata":{"id":"K_5dgcgS2sQj","outputId":"962b1d1d-6623-4ba7-aa74-4efb47f9bac1","execution":{"iopub.status.busy":"2023-08-26T17:17:39.807098Z","iopub.execute_input":"2023-08-26T17:17:39.807432Z","iopub.status.idle":"2023-08-26T17:19:29.994314Z","shell.execute_reply.started":"2023-08-26T17:17:39.807405Z","shell.execute_reply":"2023-08-26T17:19:29.992845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# (6) XGBOOST CLASSIFICATION MODEL\n","metadata":{"id":"z7l-VmXKjTJP"}},{"cell_type":"code","source":"%%time\n# pipeline creation \n# 1. CountVectorizer\n# 2. TfidTransformer\n# 3. XGBClassifier\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# Create a pipeline with CountVectorizer, TfidfTransformer, and Gradient Boosting Classifier\npipeline_xgb = Pipeline([\n    ('count_vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('model', GradientBoostingClassifier())\n])\n\n# Fit the pipeline to the training data\npipeline_xgb.fit(X_train, y_train)\n\n# Predict on the test dataset\ny_pred_xgb = pipeline_xgb.predict(X_test)\n\n# Calculate accuracy\naccuracy_xgb = accuracy_score(y_test, y_pred_gb)\nprint(\"Accuracy:\", accuracy_xgb)\n\n# Calculate confusion matrix\nconf_matrix_xgb = confusion_matrix(y_test, y_pred_xgb)\nprint(\"Confusion Matrix:\\n\", conf_matrix_gb)\n\n# Print classification report\nclass_report_xgb = classification_report(y_test, y_pred_gb)\nprint(\"Classification Report:\\n\", class_report_xgb)\n","metadata":{"id":"6koZzsSv2sM7","outputId":"cb7b1e22-5edd-4dc2-a7df-ddb511ef749c","execution":{"iopub.status.busy":"2023-08-26T17:43:56.976099Z","iopub.execute_input":"2023-08-26T17:43:56.976443Z","iopub.status.idle":"2023-08-26T17:45:45.794918Z","shell.execute_reply.started":"2023-08-26T17:43:56.976418Z","shell.execute_reply":"2023-08-26T17:45:45.793565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# (7) DECISION TREE CLASSIFICATION MODEL\n","metadata":{"id":"2SBHJMuyjPmm"}},{"cell_type":"code","source":"%%time\n# pipeline creation \n# 1. CountVectorizer\n# 2. TfidTransformer\n# 3. Decision tree classifier\n\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# Create a pipeline with CountVectorizer, TfidfTransformer, and Decision Tree Classifier\npipeline_dt = Pipeline([\n    ('count_vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('model', DecisionTreeClassifier())\n])\n\n# Fit the pipeline to the training data\npipeline_dt.fit(X_train, y_train)\n\n# Predict on the test dataset\ny_pred_dt = pipeline_dt.predict(X_test)\n\n# Calculate accuracy\naccuracy_dt = accuracy_score(y_test, y_pred_dt)\nprint(\"Accuracy:\", accuracy_dt)\n\n# Calculate confusion matrix\nconf_matrix_dt = confusion_matrix(y_test, y_pred_dt)\nprint(\"Confusion Matrix:\\n\", conf_matrix_dt)\n\n# Print classification report\nclass_report_dt = classification_report(y_test, y_pred_dt)\nprint(\"Classification Report:\\n\", class_report_dt)\n","metadata":{"id":"EwiF9Pwj2sLZ","outputId":"5663ea05-9a2b-4caf-fc9b-8d84c90d8d4d","execution":{"iopub.status.busy":"2023-08-26T17:27:19.997808Z","iopub.execute_input":"2023-08-26T17:27:19.998197Z","iopub.status.idle":"2023-08-26T17:27:42.307958Z","shell.execute_reply.started":"2023-08-26T17:27:19.998167Z","shell.execute_reply":"2023-08-26T17:27:42.306639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# (8) K- NEAREST NEIGHBOUR CLASSIFIER MODEL\n","metadata":{"id":"IPUcodK0jLVr"}},{"cell_type":"code","source":"%%time\n# pipeline creation \n# 1. CountVectorizer\n# 2. TfidTransformer\n# 3. KNN classifier\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# Create a pipeline with CountVectorizer, TfidfTransformer, and K-Nearest Neighbors Classifier\npipeline_knn = Pipeline([\n    ('count_vect', CountVectorizer()),\n    ('tfidf', TfidfTransformer()),\n    ('model', KNeighborsClassifier())\n])\n\n# Fit the pipeline to the training data\npipeline_knn.fit(X_train, y_train)\n\n# Predict on the test dataset\ny_pred_knn = pipeline_knn.predict(X_test)\n\n# Calculate accuracy\naccuracy_knn = accuracy_score(y_test, y_pred_knn)\nprint(\"Accuracy:\", accuracy_knn)\n\n# Calculate confusion matrix\nconf_matrix_knn = confusion_matrix(y_test, y_pred_knn)\nprint(\"Confusion Matrix:\\n\", conf_matrix_knn)\n\n# Print classification report\nclass_report_knn = classification_report(y_test, y_pred_knn)\nprint(\"Classification Report:\\n\", class_report_knn)\n","metadata":{"id":"_8XjVbty2sIL","outputId":"0f047183-29a5-4fcc-ca9c-6e5322ac49fc","execution":{"iopub.status.busy":"2023-08-26T17:37:03.109650Z","iopub.execute_input":"2023-08-26T17:37:03.110049Z","iopub.status.idle":"2023-08-26T17:37:35.618082Z","shell.execute_reply.started":"2023-08-26T17:37:03.110014Z","shell.execute_reply":"2023-08-26T17:37:35.617037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Helper function for comparing models matric\n\ndef compare_models(models, model_names, X_test, y_test):\n    metrics = []\n\n    for model, name in zip(models, model_names):\n        y_pred = model.predict(X_test)\n        \n        accuracy = accuracy_score(y_test, y_pred)\n        conf_matrix = confusion_matrix(y_test, y_pred)\n        class_report = classification_report(y_test, y_pred, output_dict=True)\n        \n        metrics.append({\n            'Model': name,\n            'Accuracy': accuracy,\n            'Confusion Matrix': conf_matrix,\n            'Classification Report': class_report\n        })\n\n    metrics_df = pd.DataFrame(metrics)\n    return metrics_df","metadata":{"id":"yCooDdQ7yFdC","execution":{"iopub.status.busy":"2023-08-26T17:41:40.946602Z","iopub.execute_input":"2023-08-26T17:41:40.947252Z","iopub.status.idle":"2023-08-26T17:41:40.954151Z","shell.execute_reply.started":"2023-08-26T17:41:40.947219Z","shell.execute_reply":"2023-08-26T17:41:40.952794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of model objects\nmodels = [pipeline_lr, pipeline_nb, pipeline_bnb, pipeline_gb, pipeline_xgb, pipeline_dt, pipeline_knn]\n\n# List of model names\nmodel_names = ['Logistic Regression', 'Multinomial Naive Bayes', 'Bernoulli Naive Bayes',\n               'Gradient Boosting Classifier', 'XGBoost Classifier', 'Decision Tree Classifier',\n               'K-Nearest Neighbors']\n\n# Compare models and get metrics dataframe\nmetrics_dataframe = compare_models(models, model_names, X_test, y_test)\n\n# Print the comparison of models\nmetrics_dataframe","metadata":{"id":"CQyOqutpyFYS","outputId":"058cbc3e-15de-491b-ba9a-85009051eae3","execution":{"iopub.status.busy":"2023-08-26T17:46:24.610589Z","iopub.execute_input":"2023-08-26T17:46:24.610921Z","iopub.status.idle":"2023-08-26T17:46:57.816269Z","shell.execute_reply.started":"2023-08-26T17:46:24.610896Z","shell.execute_reply":"2023-08-26T17:46:57.814961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Hence our best model is Logistic Regression with an Accuracy of 0.807714**","metadata":{}},{"cell_type":"markdown","source":"# **Now we will make predictions on our Test Data**","metadata":{"id":"urk4DVzslAXB"}},{"cell_type":"code","source":"# Perforn the prediction on the test dataset\n# Predict on the test dataset using the Logistic Regression model\ny_pred_lr = pipeline_lr.predict(X_test)\n\n# Print the predicted labels\ny_pred_lr\n","metadata":{"id":"T7HvvBOW2sGj","outputId":"44b79c1b-84ea-4b00-9200-d75f8d514603","execution":{"iopub.status.busy":"2023-08-26T17:53:01.538184Z","iopub.execute_input":"2023-08-26T17:53:01.538603Z","iopub.status.idle":"2023-08-26T17:53:01.641966Z","shell.execute_reply.started":"2023-08-26T17:53:01.538525Z","shell.execute_reply":"2023-08-26T17:53:01.640382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a dataframe of predicted results \nimport pandas as pd\n\n# Create a DataFrame of predicted results\npredicted_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_lr})\n\n# Display the DataFrame\npredicted_df","metadata":{"id":"pOKTBCnPlD5J","execution":{"iopub.status.busy":"2023-08-26T17:55:38.339298Z","iopub.execute_input":"2023-08-26T17:55:38.339660Z","iopub.status.idle":"2023-08-26T17:55:38.352864Z","shell.execute_reply.started":"2023-08-26T17:55:38.339631Z","shell.execute_reply":"2023-08-26T17:55:38.351522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# Calculate accuracy\naccuracy_lr = accuracy_score(y_test, y_pred_lr)\nprint(\"Accuracy:\", accuracy_lr)\n\n# Calculate confusion matrix\nconf_matrix_lr = confusion_matrix(y_test, y_pred_lr)\nprint(\"Confusion Matrix:\\n\", conf_matrix_lr)\n\n# Print classification report\nclass_report_lr = classification_report(y_test, y_pred_lr)\nprint(\"Classification Report:\\n\", class_report_lr)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T17:56:37.101871Z","iopub.execute_input":"2023-08-26T17:56:37.102298Z","iopub.status.idle":"2023-08-26T17:56:37.204188Z","shell.execute_reply.started":"2023-08-26T17:56:37.102266Z","shell.execute_reply":"2023-08-26T17:56:37.202613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now we will be working on headlines","metadata":{"id":"VOS21GT-gOzH"}},{"cell_type":"code","source":"combined_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-26T18:00:13.567480Z","iopub.execute_input":"2023-08-26T18:00:13.567834Z","iopub.status.idle":"2023-08-26T18:00:13.578517Z","shell.execute_reply.started":"2023-08-26T18:00:13.567807Z","shell.execute_reply":"2023-08-26T18:00:13.577340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a new dataframe by dropping the 'Description' column\nnew_dataframe = combined_df.drop(columns=['Description'])\n\n# Display the new dataframe\nnew_dataframe.head()","metadata":{"id":"wFmAITs64xzF","outputId":"1ef5c066-55a3-413b-e5a6-936f6ce06146","execution":{"iopub.status.busy":"2023-08-26T18:05:38.396165Z","iopub.execute_input":"2023-08-26T18:05:38.396502Z","iopub.status.idle":"2023-08-26T18:05:38.409147Z","shell.execute_reply.started":"2023-08-26T18:05:38.396474Z","shell.execute_reply":"2023-08-26T18:05:38.407435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rename the \"date\" column to \"time\" in the Guardian headlines dataset\nguardian_df.rename(columns={'date': 'time'}, inplace=True)\n\n# Display the updated Guardian headlines dataset\nguardian_df.head()","metadata":{"id":"isurNknP7iib","outputId":"6df7401d-7ac2-48b1-e391-d9fc65f14305","execution":{"iopub.status.busy":"2023-08-26T18:06:37.522221Z","iopub.execute_input":"2023-08-26T18:06:37.522560Z","iopub.status.idle":"2023-08-26T18:06:37.533786Z","shell.execute_reply.started":"2023-08-26T18:06:37.522530Z","shell.execute_reply":"2023-08-26T18:06:37.532822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Concatenate the guardian_df and  new_dataframe to get all headlines together\n\nimport pandas as pd\n\n# Concatenate the guardian_df and new_dataframe\nall_headlines = pd.concat([guardian_df, new_dataframe])\n\n# Display the concatenated dataframe\nall_headlines.head()","metadata":{"id":"7PmKhFHl4xs-","execution":{"iopub.status.busy":"2023-08-26T18:11:18.575315Z","iopub.execute_input":"2023-08-26T18:11:18.576031Z","iopub.status.idle":"2023-08-26T18:11:18.590732Z","shell.execute_reply.started":"2023-08-26T18:11:18.575938Z","shell.execute_reply":"2023-08-26T18:11:18.589395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check the shape of all headlines dataset\nall_headlines.shape","metadata":{"id":"4b_DReQJ4xnw","outputId":"4ba05177-4e07-45a8-8a32-b58c1173760d","execution":{"iopub.status.busy":"2023-08-26T18:11:49.933735Z","iopub.execute_input":"2023-08-26T18:11:49.934123Z","iopub.status.idle":"2023-08-26T18:11:49.941822Z","shell.execute_reply.started":"2023-08-26T18:11:49.934092Z","shell.execute_reply":"2023-08-26T18:11:49.940682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply Preprocessing Function (previously made by us) to the headlines column in the new dataset\nall_headlines['Headlines'] = all_headlines['Headlines'].apply(preprocess_text)\n\n# Display the updated dataframe\nall_headlines.head()","metadata":{"id":"Xn2AN-6MAgQE","outputId":"59c8dcbb-e719-4579-f872-aa8768f4a2e1","execution":{"iopub.status.busy":"2023-08-26T18:15:31.558058Z","iopub.execute_input":"2023-08-26T18:15:31.558493Z","iopub.status.idle":"2023-08-26T18:15:38.034848Z","shell.execute_reply.started":"2023-08-26T18:15:31.558460Z","shell.execute_reply":"2023-08-26T18:15:38.033738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Analyze polarity score of values in headlines and  add new column 'hl_score' of it in dataset\n\nfrom nltk.sentiment import SentimentIntensityAnalyzer\n\n# Create a SentimentIntensityAnalyzer object\nsia = SentimentIntensityAnalyzer()\n\n# Function to get the polarity score\ndef get_polarity_score(text):\n    sentiment = sia.polarity_scores(text)\n    return sentiment['compound']\n\n# Apply the polarity score function to the \"Headlines\" column\nall_headlines['hl_score'] = all_headlines['Headlines'].apply(get_polarity_score)\n\n# Display the updated dataframe\nall_headlines.head()\n","metadata":{"id":"EBdenfoGAgOL","outputId":"b1730b84-9c09-4f26-fe59-171c490b958c","execution":{"iopub.status.busy":"2023-08-26T18:22:18.972604Z","iopub.execute_input":"2023-08-26T18:22:18.973490Z","iopub.status.idle":"2023-08-26T18:22:25.657683Z","shell.execute_reply.started":"2023-08-26T18:22:18.973423Z","shell.execute_reply":"2023-08-26T18:22:25.656334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply the function  which decides sentiment to  polarity score column\n\ndef get_sentiment_label(score):\n    if score > 0.05:\n        return 'Positive'\n    elif score < -0.05:\n        return 'Negative'\n    else:\n        return 'Neutral'\n\n# Apply the sentiment function to the \"hl_score\" column\nall_headlines['hl_sentiment'] = all_headlines['hl_score'].apply(get_sentiment_label)\n\n# Display the updated dataframe\nall_headlines.head()","metadata":{"id":"OexQKGBxAgKb","outputId":"63a014a7-f17c-43ed-ceee-45f68546f2c2","execution":{"iopub.status.busy":"2023-08-26T18:26:32.270722Z","iopub.execute_input":"2023-08-26T18:26:32.271162Z","iopub.status.idle":"2023-08-26T18:26:32.304190Z","shell.execute_reply.started":"2023-08-26T18:26:32.271131Z","shell.execute_reply":"2023-08-26T18:26:32.302473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform countplot on headline score column\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Create a countplot for the \"hl_sentiment\" column\nsns.countplot(data=all_headlines, x='hl_sentiment')\n\n# Set labels and title\nplt.xlabel('Sentiment')\nplt.ylabel('Count')\nplt.title('Distribution of Headline Sentiments')\n\n# Show the plot\nplt.show()","metadata":{"id":"NiIoQpS1AgIg","outputId":"63d38ec2-8500-425a-f99b-3d6c60c88e08","execution":{"iopub.status.busy":"2023-08-26T18:29:41.130508Z","iopub.execute_input":"2023-08-26T18:29:41.131412Z","iopub.status.idle":"2023-08-26T18:29:41.371294Z","shell.execute_reply.started":"2023-08-26T18:29:41.131002Z","shell.execute_reply":"2023-08-26T18:29:41.369791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a pie chart on hl_sentiment\n\n# Create a pie chart\nplt.figure(figsize=(4, 4))\nplt.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=140, colors=['#66b3ff','#99ff99','#ff9999'])\n\n# Set title\nplt.title('Distribution of Headline Sentiments')\n\n# Show the pie chart\nplt.show()","metadata":{"id":"0do52B-enPVe","outputId":"6b88ed3f-c5a5-4c5c-d56a-d3ab60d61043","execution":{"iopub.status.busy":"2023-08-26T18:31:18.104806Z","iopub.execute_input":"2023-08-26T18:31:18.105182Z","iopub.status.idle":"2023-08-26T18:31:18.210761Z","shell.execute_reply.started":"2023-08-26T18:31:18.105153Z","shell.execute_reply":"2023-08-26T18:31:18.209784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling on Headlines dataframe all_headlines","metadata":{"id":"xldbLpNQgfG-"}},{"cell_type":"code","source":"all_headlines.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-26T18:32:30.754033Z","iopub.execute_input":"2023-08-26T18:32:30.754479Z","iopub.status.idle":"2023-08-26T18:32:30.767311Z","shell.execute_reply.started":"2023-08-26T18:32:30.754445Z","shell.execute_reply":"2023-08-26T18:32:30.765480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove the \"hl_score\" column from the dataframe\nall_headlines = all_headlines.drop(columns=['hl_score'])","metadata":{"execution":{"iopub.status.busy":"2023-08-26T18:34:27.277589Z","iopub.execute_input":"2023-08-26T18:34:27.277945Z","iopub.status.idle":"2023-08-26T18:34:27.286654Z","shell.execute_reply.started":"2023-08-26T18:34:27.277917Z","shell.execute_reply":"2023-08-26T18:34:27.285534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the dataset  into test and train \n# 90% train , 10% test and random state 212\n\nfrom sklearn.model_selection import train_test_split\n\n# Split the dataset into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(\n    all_headlines['Headlines'],    # Features (Headlines column)\n    all_headlines['hl_sentiment'],  # Target (hl_sentiment column)\n    test_size=0.1,                  # 10% test size\n    random_state=212\n)\n\n# Print the shapes of the train and test sets\nprint(\"Train set shape:\", X_train.shape)\nprint(\"Test set shape:\", X_test.shape)","metadata":{"id":"T1v5tZHj4xk7","execution":{"iopub.status.busy":"2023-08-26T18:35:06.672458Z","iopub.execute_input":"2023-08-26T18:35:06.672834Z","iopub.status.idle":"2023-08-26T18:35:06.690875Z","shell.execute_reply.started":"2023-08-26T18:35:06.672804Z","shell.execute_reply":"2023-08-26T18:35:06.689002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# (1) LINEAR SUPPORT VECTOR MACHINE","metadata":{"id":"x4bzS8ZiiZ5I"}},{"cell_type":"code","source":"%%time\n# pipeline creation\n# 1. tfidVectorization\n# 2. linearSVC model\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# Create a pipeline\npipeline_svc = Pipeline([\n    ('tfidf', TfidfVectorizer()),  # TF-IDF vectorization\n    ('svc', LinearSVC())           # LinearSVC model\n])\n\n# Fit the pipeline to the training data\npipeline_svc.fit(X_train, y_train)\n\n# Predict on the test dataset\ny_pred_svc = pipeline_svc.predict(X_test)\n\n# Calculate accuracy\naccuracy_svc = accuracy_score(y_test, y_pred_svc)\nprint(\"Accuracy:\", accuracy_svc)\n\n# Calculate confusion matrix\nconf_matrix_svc = confusion_matrix(y_test, y_pred_svc)\nprint(\"Confusion Matrix:\\n\", conf_matrix_svc)\n\n# Print classification report\nclass_report_svc = classification_report(y_test, y_pred_svc)\nprint(\"Classification Report:\\n\", class_report_svc)\n","metadata":{"id":"ajb1LxXxhsKS","outputId":"cb27a48f-370d-4172-8656-588fdaafd59c","execution":{"iopub.status.busy":"2023-08-26T18:40:49.515375Z","iopub.execute_input":"2023-08-26T18:40:49.515797Z","iopub.status.idle":"2023-08-26T18:40:50.892853Z","shell.execute_reply.started":"2023-08-26T18:40:49.515768Z","shell.execute_reply":"2023-08-26T18:40:50.891425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# (2) LOGISTIC REGRESSION","metadata":{"id":"MSeXO8a1iePB"}},{"cell_type":"code","source":"%%time\n# pipeline creation \n# 1. CountVectorization\n# 2. TfidTransformer\n# 3. Logistic Regression\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# Create a pipeline\npipeline_lr = Pipeline([\n    ('count_vect', CountVectorizer()),   # CountVectorization\n    ('tfidf', TfidfTransformer()),        # TF-IDF transformation\n    ('lr', LogisticRegression())         # Logistic Regression model\n])\n\n# Fit the pipeline to the training data\npipeline_lr.fit(X_train, y_train)\n\n# Predict on the test dataset\ny_pred_lr = pipeline_lr.predict(X_test)\n\n# Calculate accuracy\naccuracy_lr = accuracy_score(y_test, y_pred_lr)\nprint(\"Accuracy:\", accuracy_lr)\n\n# Calculate confusion matrix\nconf_matrix_lr = confusion_matrix(y_test, y_pred_lr)\nprint(\"Confusion Matrix:\\n\", conf_matrix_lr)\n\n# Print classification report\nclass_report_lr = classification_report(y_test, y_pred_lr)\nprint(\"Classification Report:\\n\", class_report_lr)\n","metadata":{"id":"nU4V-w3vhsHi","outputId":"c0dd3cf0-96c0-457e-8621-1d83ef92d7c6","execution":{"iopub.status.busy":"2023-08-26T18:42:44.041055Z","iopub.execute_input":"2023-08-26T18:42:44.041405Z","iopub.status.idle":"2023-08-26T18:42:47.803341Z","shell.execute_reply.started":"2023-08-26T18:42:44.041376Z","shell.execute_reply":"2023-08-26T18:42:47.801964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# (3) MULTINOMIAL NAIVE BAYES\n","metadata":{"id":"uX2i2JIwiiAk"}},{"cell_type":"code","source":"%%time\n# pipeline creation \n# 1. CountVectorizer\n# 2. TfidTransformer\n# 3. MultinomialNB\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# Create a pipeline\npipeline_mnb = Pipeline([\n    ('count_vect', CountVectorizer()),   # CountVectorization\n    ('tfidf', TfidfTransformer()),        # TF-IDF transformation\n    ('nb', MultinomialNB())              # Multinomial Naive Bayes model\n])\n\n# Fit the pipeline to the training data\npipeline_mnb.fit(X_train, y_train)\n\n# Predict on the test dataset\ny_pred_mnb = pipeline_mnb.predict(X_test)\n\n# Calculate accuracy\naccuracy_mnb = accuracy_score(y_test, y_pred_mnb)\nprint(\"Accuracy:\", accuracy_mnb)\n\n# Calculate confusion matrix\nconf_matrix_mnb = confusion_matrix(y_test, y_pred_mnb)\nprint(\"Confusion Matrix:\\n\", conf_matrix_mnb)\n\n# Print classification report\nclass_report_mnb = classification_report(y_test, y_pred_mnb)\nprint(\"Classification Report:\\n\", class_report_mnb)\n","metadata":{"id":"yaq-D8-qhsFH","outputId":"bba6992b-7119-406e-bf64-357b8fec4466","execution":{"iopub.status.busy":"2023-08-26T19:06:10.500181Z","iopub.execute_input":"2023-08-26T19:06:10.500664Z","iopub.status.idle":"2023-08-26T19:06:11.297942Z","shell.execute_reply.started":"2023-08-26T19:06:10.500611Z","shell.execute_reply":"2023-08-26T19:06:11.296165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# (4) BERNOULLI NAIVE BAYES\n","metadata":{"id":"67D7-TNXil6t"}},{"cell_type":"code","source":"%%time\n# pipeline creation \n# 1. CountVectorizer\n# 2. TfidTransformer\n# 3. BernoulliNB\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# Create a pipeline\npipeline_bnb = Pipeline([\n    ('count_vect', CountVectorizer()),   # CountVectorization\n    ('tfidf', TfidfTransformer()),        # TF-IDF transformation\n    ('bnb', BernoulliNB())               # Bernoulli Naive Bayes model\n])\n\n# Fit the pipeline to the training data\npipeline_bnb.fit(X_train, y_train)\n\n# Predict on the test dataset\ny_pred_bnb = pipeline_bnb.predict(X_test)\n\n# Calculate accuracy\naccuracy_bnb = accuracy_score(y_test, y_pred_bnb)\nprint(\"Accuracy:\", accuracy_bnb)\n\n# Calculate confusion matrix\nconf_matrix_bnb = confusion_matrix(y_test, y_pred_bnb)\nprint(\"Confusion Matrix:\\n\", conf_matrix_bnb)\n\n# Print classification report\nclass_report_bnb = classification_report(y_test, y_pred_bnb)\nprint(\"Classification Report:\\n\", class_report_bnb)\n","metadata":{"id":"I-RnJCDxhsB6","outputId":"cf6d532c-f119-4fa8-e8e9-ced33b3129e6","execution":{"iopub.status.busy":"2023-08-26T18:44:54.726025Z","iopub.execute_input":"2023-08-26T18:44:54.726386Z","iopub.status.idle":"2023-08-26T18:44:55.522287Z","shell.execute_reply.started":"2023-08-26T18:44:54.726357Z","shell.execute_reply":"2023-08-26T18:44:55.520811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# (5) GRADIENT BOOSTING CLASSIFICATION MODEL\n","metadata":{"id":"8GUtphU3i5fP"}},{"cell_type":"code","source":"%%time\n# pipeline creation \n# 1. CountVectorizer\n# 2. TfidTransformer\n# 3. GradientBoostingClassifier\n\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# Create a pipeline\npipeline_gb = Pipeline([\n    ('count_vect', CountVectorizer()),        # CountVectorization\n    ('tfidf', TfidfTransformer()),             # TF-IDF transformation\n    ('gb', GradientBoostingClassifier())      # Gradient Boosting Classifier model\n])\n\n# Fit the pipeline to the training data\npipeline_gb.fit(X_train, y_train)\n\n# Predict on the test dataset\ny_pred_gb = pipeline_gb.predict(X_test)\n\n# Calculate accuracy\naccuracy_gb = accuracy_score(y_test, y_pred_gb)\nprint(\"Accuracy:\", accuracy_gb)\n\n# Calculate confusion matrix\nconf_matrix_gb = confusion_matrix(y_test, y_pred_gb)\nprint(\"Confusion Matrix:\\n\", conf_matrix_gb)\n\n# Print classification report\nclass_report_gb = classification_report(y_test, y_pred_gb)\nprint(\"Classification Report:\\n\", class_report_gb)\n","metadata":{"id":"KSfng2DphsAG","outputId":"d3f96a64-515c-4996-cb98-8723ec613ad5","execution":{"iopub.status.busy":"2023-08-26T18:46:50.457397Z","iopub.execute_input":"2023-08-26T18:46:50.457839Z","iopub.status.idle":"2023-08-26T18:47:48.346399Z","shell.execute_reply.started":"2023-08-26T18:46:50.457805Z","shell.execute_reply":"2023-08-26T18:47:48.344663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# (5) XGBOOST CLASSIFICATION MODEL\nNeeded label encoding","metadata":{"id":"N-ucxwSqixk7"}},{"cell_type":"code","source":"%%time\n# pipeline creation \n# 1. CountVectorizer\n# 2. TfidTransformer\n# 3. XGBClassifier\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.preprocessing import LabelEncoder\n\n# Create a label encoder\nlabel_encoder = LabelEncoder()\n\n# Fit the encoder on the target variable\nlabel_encoder.fit(y_train)\n\n# Encode the target variable\ny_train_encoded = label_encoder.transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\n# Create a pipeline\npipeline_xgb = Pipeline([\n    ('count_vect', CountVectorizer()),   # CountVectorization\n    ('tfidf', TfidfTransformer()),        # TF-IDF transformation\n    ('xgb', XGBClassifier())             # XGBoost Classifier model\n])\n\n# Fit the pipeline to the training data\npipeline_xgb.fit(X_train, y_train_encoded)\n\n# Predict on the test dataset\ny_pred_xgb_encoded = pipeline_xgb.predict(X_test)\n\n# Inverse transform the predictions to get original labels\ny_pred_xgb = label_encoder.inverse_transform(y_pred_xgb_encoded)\n\n# Calculate accuracy\naccuracy_xgb = accuracy_score(y_test, y_pred_xgb)\nprint(\"Accuracy:\", accuracy_xgb)\n\n# Calculate confusion matrix\nconf_matrix_xgb = confusion_matrix(y_test, y_pred_xgb)\nprint(\"Confusion Matrix:\\n\", conf_matrix_xgb)\n\n# Print classification report\nclass_report_xgb = classification_report(y_test, y_pred_xgb)\nprint(\"Classification Report:\\n\", class_report_xgb)\n","metadata":{"id":"nQg5zgOi4xid","outputId":"b210a603-815c-458c-c82f-f026bd4d254e","execution":{"iopub.status.busy":"2023-08-26T18:52:16.486644Z","iopub.execute_input":"2023-08-26T18:52:16.487053Z","iopub.status.idle":"2023-08-26T18:52:38.434346Z","shell.execute_reply.started":"2023-08-26T18:52:16.487019Z","shell.execute_reply":"2023-08-26T18:52:38.432913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# (6) DECISION TREE CLASSIFICATION MODEL\n","metadata":{"id":"u_N_BrWyjABA"}},{"cell_type":"code","source":"%%time\n# pipeline creation \n# 1. CountVectorizer\n# 2. TfidTransformer\n# 3. Decision tree classifier\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# Create a pipeline\npipeline_dt = Pipeline([\n    ('count_vect', CountVectorizer()),       # CountVectorization\n    ('tfidf', TfidfTransformer()),            # TF-IDF transformation\n    ('dt', DecisionTreeClassifier())         # Decision Tree Classifier model\n])\n\n# Fit the pipeline to the training data\npipeline_dt.fit(X_train, y_train)\n\n# Predict on the test dataset\ny_pred_dt = pipeline_dt.predict(X_test)\n\n# Calculate accuracy\naccuracy_dt = accuracy_score(y_test, y_pred_dt)\nprint(\"Accuracy:\", accuracy_dt)\n\n# Calculate confusion matrix\nconf_matrix_dt = confusion_matrix(y_test, y_pred_dt)\nprint(\"Confusion Matrix:\\n\", conf_matrix_dt)\n\n# Print classification report\nclass_report_dt = classification_report(y_test, y_pred_dt)\nprint(\"Classification Report:\\n\", class_report_dt)","metadata":{"id":"IvA6LRen4xeh","outputId":"4e614ba8-83e6-4360-d87b-9d8b63ac3659","execution":{"iopub.status.busy":"2023-08-26T18:55:06.005688Z","iopub.execute_input":"2023-08-26T18:55:06.006076Z","iopub.status.idle":"2023-08-26T18:55:55.675203Z","shell.execute_reply.started":"2023-08-26T18:55:06.006046Z","shell.execute_reply":"2023-08-26T18:55:55.673835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# (7) K- NEAREST NEIGHBOUR CLASSIFIER MODEL\n","metadata":{"id":"ez0xd3SmjDAU"}},{"cell_type":"code","source":"%%time\n# pipeline creation \n# 1. CountVectorizer\n# 2. TfidTransformer\n# 3. KNN classifier\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# Create a pipeline\npipeline_knn = Pipeline([\n    ('count_vect', CountVectorizer()),       # CountVectorization\n    ('tfidf', TfidfTransformer()),            # TF-IDF transformation\n    ('knn', KNeighborsClassifier())          # K-Nearest Neighbors Classifier model\n])\n\n# Fit the pipeline to the training data\npipeline_knn.fit(X_train, y_train)\n\n# Predict on the test dataset\ny_pred_knn = pipeline_knn.predict(X_test)\n\n# Calculate accuracy\naccuracy_knn = accuracy_score(y_test, y_pred_knn)\nprint(\"Accuracy:\", accuracy_knn)\n\n# Calculate confusion matrix\nconf_matrix_knn = confusion_matrix(y_test, y_pred_knn)\nprint(\"Confusion Matrix:\\n\", conf_matrix_knn)\n\n# Print classification report\nclass_report_knn = classification_report(y_test, y_pred_knn)\nprint(\"Classification Report:\\n\", class_report_knn)\n","metadata":{"id":"G7Y6zavB4xcc","outputId":"f2bee906-2302-4905-8554-2e9f13b98f85","execution":{"iopub.status.busy":"2023-08-26T18:57:45.408718Z","iopub.execute_input":"2023-08-26T18:57:45.409070Z","iopub.status.idle":"2023-08-26T18:57:53.921588Z","shell.execute_reply.started":"2023-08-26T18:57:45.409042Z","shell.execute_reply":"2023-08-26T18:57:53.920037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Making a df of all models metrics.\n\nbeforehand, lets make label encoding so that no model will throw any error","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Create a label encoder\nlabel_encoder = LabelEncoder()\n\n# Fit the encoder on the target variable in training data\ny_train_encoded = label_encoder.fit_transform(y_train)\n\n# Transform the target variable in test data using the same encoder\ny_test_encoded = label_encoder.transform(y_test)\n\n# Now you can use y_train_encoded and y_test_encoded in your pipelines and models","metadata":{"execution":{"iopub.status.busy":"2023-08-26T19:08:16.311238Z","iopub.execute_input":"2023-08-26T19:08:16.311619Z","iopub.status.idle":"2023-08-26T19:08:16.330337Z","shell.execute_reply.started":"2023-08-26T19:08:16.311590Z","shell.execute_reply":"2023-08-26T19:08:16.328631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Helper function for comparing models metrics\n\ndef compare_models(models, model_names, X_train, y_train, X_test, y_test):\n    label_encoder = LabelEncoder()\n    y_train_encoded = label_encoder.fit_transform(y_train)\n    y_test_encoded = label_encoder.transform(y_test)\n    \n    metrics = []\n    \n    for model, name in zip(models, model_names):\n        model.fit(X_train, y_train_encoded)\n        y_pred_encoded = model.predict(X_test)\n        y_pred = label_encoder.inverse_transform(y_pred_encoded)\n        \n        accuracy = accuracy_score(y_test, y_pred)\n        conf_matrix = confusion_matrix(y_test, y_pred)\n        class_report = classification_report(y_test, y_pred, output_dict=True)\n        \n        metrics.append({\n            'Model': name,\n            'Accuracy': accuracy,\n            'Confusion Matrix': conf_matrix,\n            'Classification Report': class_report\n        })\n    \n    metrics_df = pd.DataFrame(metrics)\n    return metrics_df","metadata":{"id":"ncLiLHw6rNFP","execution":{"iopub.status.busy":"2023-08-26T19:09:59.469521Z","iopub.execute_input":"2023-08-26T19:09:59.469880Z","iopub.status.idle":"2023-08-26T19:09:59.478482Z","shell.execute_reply.started":"2023-08-26T19:09:59.469852Z","shell.execute_reply":"2023-08-26T19:09:59.476491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of model objects\nmodels = [pipeline_svc, pipeline_lr, pipeline_mnb, pipeline_bnb, pipeline_gb, pipeline_xgb, pipeline_dt, pipeline_knn]\n\n# List of model names\nmodel_names = ['LinearSVC', 'Logistic Regression', 'Multinomial Naive Bayes', \n               'Bernoulli Naive Bayes', 'Gradient Boosting Classifier', 'XGBoost Classifier', \n               'Decision Tree Classifier', 'K-Nearest Neighbors']\n\n# Create a dataframe with metrics\nmodel_metrics_df = compare_models(models, model_names, X_train, y_train, X_test, y_test)\n","metadata":{"id":"FspHXt4ZrdWV","outputId":"5809c57d-b69f-42fa-be05-3a8f4ebba491","execution":{"iopub.status.busy":"2023-08-26T19:10:20.248858Z","iopub.execute_input":"2023-08-26T19:10:20.249302Z","iopub.status.idle":"2023-08-26T19:12:49.197372Z","shell.execute_reply.started":"2023-08-26T19:10:20.249266Z","shell.execute_reply":"2023-08-26T19:12:49.196071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_metrics_df","metadata":{"execution":{"iopub.status.busy":"2023-08-26T19:16:03.464944Z","iopub.execute_input":"2023-08-26T19:16:03.465320Z","iopub.status.idle":"2023-08-26T19:16:03.499611Z","shell.execute_reply.started":"2023-08-26T19:16:03.465294Z","shell.execute_reply":"2023-08-26T19:16:03.498516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now working with test data\n#### We found Linear SVC is the best model with an accuracy of **0.919917** .","metadata":{"id":"gsQKs2r_lSaz"}},{"cell_type":"code","source":"# Perforn the prediction on the test dataset\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# Fit the Linear SVC model on the full training data\npipeline_svc.fit(X_train, y_train)\n\n# Predict on the test dataset\ny_pred_svc = pipeline_svc.predict(X_test)\ny_pred_svc\n","metadata":{"id":"VSSPcY-VjFyc","outputId":"5a164a05-ba61-41b0-dd45-c049948dc9be","execution":{"iopub.status.busy":"2023-08-26T19:19:42.087858Z","iopub.execute_input":"2023-08-26T19:19:42.088218Z","iopub.status.idle":"2023-08-26T19:19:44.020889Z","shell.execute_reply.started":"2023-08-26T19:19:42.088190Z","shell.execute_reply":"2023-08-26T19:19:44.019122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate accuracy\naccuracy_svc = accuracy_score(y_test, y_pred_svc)\nprint(\"Accuracy:\", accuracy_svc)\n\n# Calculate confusion matrix\nconf_matrix_svc = confusion_matrix(y_test, y_pred_svc)\nprint(\"Confusion Matrix:\\n\", conf_matrix_svc)\n\n# Print classification report\nclass_report_svc = classification_report(y_test, y_pred_svc)\nprint(\"Classification Report:\\n\", class_report_svc)","metadata":{"execution":{"iopub.status.busy":"2023-08-26T19:19:50.394467Z","iopub.execute_input":"2023-08-26T19:19:50.394852Z","iopub.status.idle":"2023-08-26T19:19:50.538912Z","shell.execute_reply.started":"2023-08-26T19:19:50.394823Z","shell.execute_reply":"2023-08-26T19:19:50.538150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a dataframe of predicted results \n# Create a dataframe of predicted results\npredicted_df = pd.DataFrame({\n    'Actual': y_test,\n    'Predicted': y_pred_svc\n})\n\n# Display the predicted dataframe\npredicted_df.head()","metadata":{"id":"HZH2_2KZjFwO","execution":{"iopub.status.busy":"2023-08-26T19:20:59.195019Z","iopub.execute_input":"2023-08-26T19:20:59.195438Z","iopub.status.idle":"2023-08-26T19:20:59.207877Z","shell.execute_reply.started":"2023-08-26T19:20:59.195407Z","shell.execute_reply":"2023-08-26T19:20:59.205953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Making predictions on realtime news data .........**","metadata":{"id":"6ffMQY_00ufo"}},{"cell_type":"markdown","source":"We can check the result on real time news headlines!","metadata":{"id":"BrQATukn0x2u"}},{"cell_type":"code","source":"sent1 = ['Chandrayaan 3 makes successful soft landing on Lunar South Pole']\ny_predict = pipeline_svc.predict(sent1)\nprint(y_predict)","metadata":{"id":"uRUtaAhZ0wwU","outputId":"946e8f9c-6fdc-4d7f-b2a4-72ed559a470c","execution":{"iopub.status.busy":"2023-08-26T19:24:33.445899Z","iopub.execute_input":"2023-08-26T19:24:33.446267Z","iopub.status.idle":"2023-08-26T19:24:33.454736Z","shell.execute_reply.started":"2023-08-26T19:24:33.446231Z","shell.execute_reply":"2023-08-26T19:24:33.453487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sent2 = [\"Rape survivors sustains fatal injuries in Kolkata\"]\ny_predict = pipeline_svc.predict(sent2)\nprint(y_predict)","metadata":{"id":"_YJqDGt71DGn","outputId":"8265f9b2-4c84-4ada-876e-4b2f3eb1989a","execution":{"iopub.status.busy":"2023-08-26T19:25:57.231694Z","iopub.execute_input":"2023-08-26T19:25:57.232079Z","iopub.status.idle":"2023-08-26T19:25:57.241295Z","shell.execute_reply.started":"2023-08-26T19:25:57.232051Z","shell.execute_reply":"2023-08-26T19:25:57.240204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion","metadata":{"id":"No7lHSthFvmj"}},{"cell_type":"markdown","source":"We learn about NLTK, sentiment analysis in this Project.\n\nWe conclude that using nltk it is easy to classify financial news and more we improve the traning data more we can get accurate\n","metadata":{"id":"4FRWlgXRFywD"}}]}