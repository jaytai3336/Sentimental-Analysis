{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Comparing between different Sentimental Analaysis Models\n",
    "\n",
    "Goal: To determine the best model on hand\n",
    "\n",
    "Description:  I have a csv of headliners, and fed it to GrokAI to generate a list of sentimental Scores. This will be used as the benchmark in the comparison.\n",
    "\n",
    "Steps outlined:\n",
    "1. Setup the file \"with_sentiment_100.csv\" for comparison and briefly screen through the list for outliers\n",
    "2. Run through the different models and run the data through them (We are interested to know if its positive or negative)\n",
    "3. Compare with true values\n",
    "\n",
    "Models:\n",
    "- vader\n",
    "- textblob\n",
    "- flair\n",
    "- roberta\n",
    "- distilbert\n",
    "- bertweet\n",
    "- finbert\n",
    "- deberta\n",
    "- qwen llm"
   ],
   "id": "bbeb033608f08ddd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Setup testing file",
   "id": "974369bbd4b8facb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T01:08:45.138275Z",
     "start_time": "2025-06-18T01:08:45.128469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/headlines_with_sentiment.csv\")\n",
    "df.head()"
   ],
   "id": "a848f71571d52b07",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Index                                           Headline Sentiment\n",
       "0      0   Johnson is asking Santa for a Christmas recovery       POS\n",
       "1      1  ‘I now fear the worst’: four grim tales of wor...       NEG\n",
       "2      2  Five key areas Sunak must tackle to serve up e...       NEU\n",
       "3      3  Covid-19 leaves firms ‘fatally ill-prepared’ f...       NEG\n",
       "4      4  The Week in Patriarchy Bacardi's 'lady vodka':...       NEG"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Johnson is asking Santa for a Christmas recovery</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>‘I now fear the worst’: four grim tales of wor...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Five key areas Sunak must tackle to serve up e...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Covid-19 leaves firms ‘fatally ill-prepared’ f...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The Week in Patriarchy Bacardi's 'lady vodka':...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.shape",
   "id": "b46b169d6a7299ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.info()",
   "id": "4169c2a32d507ae3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.describe()",
   "id": "ac756655313fe851",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T01:08:48.694637Z",
     "start_time": "2025-06-18T01:08:48.661106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "headline = list(df['Headline'])[:10]\n",
    "headline"
   ],
   "id": "4b5c64b58a3649c7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Johnson is asking Santa for a Christmas recovery',\n",
       " '‘I now fear the worst’: four grim tales of working life upended by Covid-19',\n",
       " 'Five key areas Sunak must tackle to serve up economic recovery',\n",
       " 'Covid-19 leaves firms ‘fatally ill-prepared’ for no-deal Brexit',\n",
       " \"The Week in Patriarchy Bacardi's 'lady vodka': the latest in a long line of depressing gendered products\",\n",
       " 'English councils call for smoking ban outside pubs and cafes',\n",
       " 'Can Tesla justify a $300bn valuation?',\n",
       " \"Empty city centres: 'I’m not sure it will ever be the same again'\",\n",
       " \"Democratising finance for all? An investment app for amateurs and a student trader's death\",\n",
       " 'Homebuyer loses £300,000 to fraudsters – but gets it back after we step in']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Run the list through different models",
   "id": "b7999155b16b3afc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T01:09:23.396895Z",
     "start_time": "2025-06-18T01:09:20.718026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set up\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    if not isinstance(text, str) or text is None:\n",
    "        return \"\"\n",
    "    tokens = word_tokenize(text.lower())  # Tokenize and lowercase\n",
    "    cleaned_tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalpha() and token not in stop_words]\n",
    "    test_sentence = \" \".join(cleaned_tokens)\n",
    "    return test_sentence\n",
    "\n",
    "processed_headine = list(map(preprocess, headline))"
   ],
   "id": "548065da08211f47",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/jaytai/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jaytai/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/jaytai/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T16:52:32.006511Z",
     "start_time": "2025-06-17T16:52:31.986547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Prebuilt Vader sentiment package (NaiveBayes model) - Done\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "result_vader = []\n",
    "threshold_upper = .05\n",
    "threshold_lower = -.05\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "for sentence in processed_headine:\n",
    "    score = analyzer.polarity_scores(sentence)\n",
    "    result_vader.append(score['compound'])\n",
    "result_vader = ['POS' if s >= threshold_upper else 'NEG' if s <= threshold_lower else 'NEU' for s in result_vader]\n",
    "print(result_vader[:10])\n",
    "pd.DataFrame(result_vader).to_csv(\"data/result_vader.csv\")\n",
    "\n",
    "# to determine the threshold"
   ],
   "id": "e45f5d28bbc253e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NEU', 'NEG', 'NEU', 'NEG', 'NEG', 'NEG', 'NEU', 'POS', 'NEG', 'NEG']\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 2. Prebuilt Textblob sentiment package - Done\n",
    "\n",
    "from textblob import TextBlob\n",
    "result_tb = []\n",
    "threshold_upper = .05\n",
    "threshold_lower = -.05\n",
    "for sentence in processed_headine:\n",
    "    result_tb.append(TextBlob(sentence).sentiment.polarity)\n",
    "result_tb = ['POS' if s >= threshold_upper else 'NEG' if s <= threshold_lower else 'NEU' for s in result_tb]\n",
    "print(result_tb[:10])\n",
    "pd.DataFrame(result_tb).to_csv(\"data/result_tb.csv\")\n",
    "\n",
    "# to determine the threshold"
   ],
   "id": "dabb924578b70adc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 3. Prebuilt Flair sentiment package/Model - Done\n",
    "\n",
    "from flair.data import Sentence\n",
    "from flair.nn import Classifier\n",
    "result_flair = []\n",
    "tagger = Classifier.load('sentiment')\n",
    "\n",
    "for sentence in processed_headine:\n",
    "    sentence = Sentence(sentence)\n",
    "    tagger.predict(sentence)\n",
    "    value = sentence.labels[0].value\n",
    "    result_flair.append(value)\n",
    "result_flair = ['POS' if s == 'POSITIVE' else 'NEG' if s == 'NEGATIVE' else 'NEU' for s in result_flair]\n",
    "print(result_flair[:10])\n",
    "pd.DataFrame(result_flair).to_csv(\"data/result_flair.csv\")"
   ],
   "id": "b2947c9fcd7945dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T01:09:48.924451Z",
     "start_time": "2025-06-18T01:09:43.567819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# setup for HuggingFace Transformers\n",
    "\n",
    "from transformers import pipeline, set_seed\n",
    "set_seed(999)"
   ],
   "id": "9a198a7537747514",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# RoBERTa - Done\n",
    "\n",
    "classifier = pipeline('sentiment-analysis', model='cardiffnlp/twitter-roberta-base-sentiment-latest')\n",
    "\n",
    "result_roberta = []\n",
    "for sentence in processed_headine:\n",
    "    temp = classifier(sentence)\n",
    "    result_roberta.append(temp[0]['label'])\n",
    "result_roberta = ['POS' if s == 'positive' else 'NEG' if s == 'negative' else 'NEU' for s in result_roberta]\n",
    "print(result_roberta[:10])\n",
    "pd.DataFrame(result_roberta).to_csv(\"data/result_roberta.csv\")"
   ],
   "id": "81ee78c078282156",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# distilBERT - Done\n",
    "\n",
    "classifier = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')\n",
    "\n",
    "result_dis = []\n",
    "for sentence in processed_headine:\n",
    "    temp = classifier(sentence)\n",
    "    result_dis.append(temp[0]['label'])\n",
    "result_dis = ['POS' if s == 'POSITIVE' else 'NEG' if s == 'NEGATIVE' else 'NEU' for s in result_dis]\n",
    "print(result_dis[:10])\n",
    "pd.DataFrame(result_dis).to_csv(\"data/result_distilbert.csv\")"
   ],
   "id": "1529a63db0d77e0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Bertweet - Done\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "\n",
    "result_bertweet = []\n",
    "for sentence in processed_headine:\n",
    "    result_bertweet.append(classifier(sentence)[0]['label'])\n",
    "print(result_bertweet[:10])\n",
    "pd.DataFrame(result_bertweet).to_csv(\"data/result_bertweet.csv\")"
   ],
   "id": "682c686030bb5642",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-18T01:20:39.056351Z",
     "start_time": "2025-06-18T01:20:31.861192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# finBERT - Done\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"ProsusAI/finbert\")\n",
    "\n",
    "result_finbert = []\n",
    "for sentence in processed_headine:\n",
    "    temp = classifier(sentence)\n",
    "    result_finbert.append(temp[0]['label'])\n",
    "result_finbert = ['POS' if s == 'positive' else 'NEG' if s == 'negative' else 'NEU' for s in result_finbert]\n",
    "print(result_finbert[:10])\n",
    "pd.DataFrame(result_finbert).to_csv(\"data/result_finbert.csv\")"
   ],
   "id": "6dad42ce7ea0e585",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NEU', 'NEU', 'POS', 'NEU', 'NEG', 'NEU', 'NEU', 'NEU', 'NEU', 'NEG']\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# LLM QWEN 8gb\n",
    "# \n",
    "# from openai import OpenAI\n",
    "# \n",
    "# client = OpenAI(\n",
    "#   base_url=\"https://openrouter.ai/api/v1\",\n",
    "#   api_key=\"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\",\n",
    "# )\n",
    "# \n",
    "# result_ai = []\n",
    "# \n",
    "# for sentence in processed_headine:\n",
    "#     completion = client.chat.completions.create(\n",
    "#       extra_body={}, model=\"deepseek/deepseek-r1-0528-qwen3-8b:free\",\n",
    "#       messages=[{ \"role\": \"user\",\n",
    "#           \"content\": f\"Only give me a sentimental analysis from -1(negative) to 1(positive) for the following sentence {sentence}\"\n",
    "#     }])\n",
    "#     result_ai.append(completion.choices[0].message.content)\n",
    "# result_ai[:10]\n",
    "# pd.DataFrame(result_ai).to_csv(\"data/ai.csv\")"
   ],
   "id": "95e325bb2df4b9e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=\"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\",\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "      extra_body={}, model=\"deepseek/deepseek-r1-0528-qwen3-8b:free\",\n",
    "      messages=[{ \"role\": \"user\",\n",
    "          \"content\": f\"Only give me a sentimental analysis value of NEG (negative) or POS (positive) or NEU (neutral) for the following sentence {\"Hi Hi\"}\"\n",
    "    }])\n",
    "print(completion.choices[0].message.content)"
   ],
   "id": "a86f44bee2350198"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
