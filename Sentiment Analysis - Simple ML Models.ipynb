{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model training\n",
    "\n",
    "trained using the same 2000 entries. train-test split 8-2"
   ],
   "id": "abf03c66dcfb800b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-23T05:47:44.076611Z",
     "start_time": "2025-06-23T05:47:33.478950Z"
    }
   },
   "source": [
    "# labelling all the data using the best model: distilbert\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/Training Data/headlines_with_sentiment.csv\")\n",
    "print(df.head())\n",
    "print(df.describe())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Index                                           Headline Sentiment_label\n",
      "0      0   Johnson is asking Santa for a Christmas recovery             POS\n",
      "1      1  ‘I now fear the worst’: four grim tales of wor...             NEG\n",
      "2      2  Five key areas Sunak must tackle to serve up e...             NEU\n",
      "3      3  Covid-19 leaves firms ‘fatally ill-prepared’ f...             NEG\n",
      "4      4  The Week in Patriarchy Bacardi's 'lady vodka':...             NEG\n",
      "             Index\n",
      "count  1984.000000\n",
      "mean    993.127520\n",
      "std     575.397447\n",
      "min       0.000000\n",
      "25%     495.750000\n",
      "50%     991.500000\n",
      "75%    1487.250000\n",
      "max    1999.000000\n",
      "   Index                                           Headline Sentiment_label\n",
      "0      0   Johnson is asking Santa for a Christmas recovery             POS\n",
      "1      1  ‘I now fear the worst’: four grim tales of wor...             NEG\n",
      "2      2  Five key areas Sunak must tackle to serve up e...             NEU\n",
      "3      3  Covid-19 leaves firms ‘fatally ill-prepared’ f...             NEG\n",
      "4      4  The Week in Patriarchy Bacardi's 'lady vodka':...             NEG\n",
      "             Index\n",
      "count  1984.000000\n",
      "mean    993.127520\n",
      "std     575.397447\n",
      "min       0.000000\n",
      "25%     495.750000\n",
      "50%     991.500000\n",
      "75%    1487.250000\n",
      "max    1999.000000\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T05:47:54.430717Z",
     "start_time": "2025-06-23T05:47:46.103592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set up\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    if not isinstance(text, str) or text is None:\n",
    "        return \"\"\n",
    "    tokens = word_tokenize(text.lower())  # Tokenize and lowercase\n",
    "    cleaned_tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalpha() and token not in stop_words]\n",
    "    test_sentence = \" \".join(cleaned_tokens)\n",
    "    return test_sentence\n",
    "\n",
    "headline = list(df['Headline'])\n",
    "processed_headline = list(map(preprocess, headline))\n",
    "\n",
    "data = pd.DataFrame({'Headline': processed_headline, 'Sentiment': df['Sentiment_label'] })\n",
    "data.head()"
   ],
   "id": "e1698d4c183718dc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Jay\n",
      "[nltk_data]     Tai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Jay\n",
      "[nltk_data]     Tai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Jay\n",
      "[nltk_data]     Tai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                            Headline Sentiment\n",
       "0            johnson asking santa christmas recovery       POS\n",
       "1     fear worst four grim tale working life upended       NEG\n",
       "2  five key area sunak must tackle serve economic...       NEU\n",
       "3                           leaf firm fatally brexit       NEG\n",
       "4  week patriarchy bacardi vodka latest long line...       NEG"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>johnson asking santa christmas recovery</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear worst four grim tale working life upended</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>five key area sunak must tackle serve economic...</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>leaf firm fatally brexit</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>week patriarchy bacardi vodka latest long line...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T05:48:24.046700Z",
     "start_time": "2025-06-23T05:48:24.028737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the dataset  into test and train\n",
    "# 90% train , 10% test and random state 999\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "np.random.seed(999)\n",
    "\n",
    "# Define the features and target variable\n",
    "X = data['Headline']  # Features\n",
    "y = data['Sentiment']  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=999)\n",
    "\n",
    "# Print the shape of the training and testing sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ],
   "id": "cc313f4641288f05",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1785,)\n",
      "X_test shape: (199,)\n",
      "y_train shape: (1785,)\n",
      "y_test shape: (199,)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Testing using different models",
   "id": "6d17846b2998f40c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T07:18:16.302283Z",
     "start_time": "2025-06-19T07:18:16.268543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SVM\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('model', LinearSVC())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"LinearSVC\")\n",
    "\n",
    "print(\"accuracy score: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ],
   "id": "685a6f12dea3b7b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n",
      "accuracy score: 90.45%\n",
      "Confusion Matrix:\n",
      " [[171   1   1]\n",
      " [  4   2   3]\n",
      " [ 10   0   7]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.92      0.99      0.96       173\n",
      "         NEU       0.67      0.22      0.33         9\n",
      "         POS       0.64      0.41      0.50        17\n",
      "\n",
      "    accuracy                           0.90       199\n",
      "   macro avg       0.74      0.54      0.60       199\n",
      "weighted avg       0.89      0.90      0.89       199\n",
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T07:18:39.784510Z",
     "start_time": "2025-06-19T07:18:39.722775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LR\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# Create a pipeline with CountVectorizer, TfidfTransformer, and Logistic Regression\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test dataset\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression\")\n",
    "print(\"accuracy score: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ],
   "id": "fe83609c0247d1a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "accuracy score: 86.93%\n",
      "Confusion Matrix:\n",
      " [[173   0   0]\n",
      " [  9   0   0]\n",
      " [ 17   0   0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.87      1.00      0.93       173\n",
      "         NEU       0.00      0.00      0.00         9\n",
      "         POS       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.87       199\n",
      "   macro avg       0.29      0.33      0.31       199\n",
      "weighted avg       0.76      0.87      0.81       199\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay Tai\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Jay Tai\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Jay Tai\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T07:18:58.806858Z",
     "start_time": "2025-06-19T07:18:58.771596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Multinomial NB\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# Create a pipeline with CountVectorizer, TfidfTransformer, and Multinomial Naive Bayes\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('model', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test dataset\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"MultinomialNB\")\n",
    "print(\"accuracy score: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ],
   "id": "268c32e2cf319d2d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\n",
      "accuracy score: 86.93%\n",
      "Confusion Matrix:\n",
      " [[173   0   0]\n",
      " [  9   0   0]\n",
      " [ 17   0   0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.87      1.00      0.93       173\n",
      "         NEU       0.00      0.00      0.00         9\n",
      "         POS       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.87       199\n",
      "   macro avg       0.29      0.33      0.31       199\n",
      "weighted avg       0.76      0.87      0.81       199\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay Tai\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Jay Tai\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Jay Tai\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T07:21:26.206819Z",
     "start_time": "2025-06-19T07:21:26.175328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Binomial NB\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# Create a pipeline with CountVectorizer, TfidfTransformer, and Bernoulli Naive Bayes\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('model', BernoulliNB())\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test dataset\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"BernoulliNB\")\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy score: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ],
   "id": "647cda317b364388",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB\n",
      "accuracy score: 86.43%\n",
      "Confusion Matrix:\n",
      " [[172   0   1]\n",
      " [  9   0   0]\n",
      " [ 17   0   0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.87      0.99      0.93       173\n",
      "         NEU       0.00      0.00      0.00         9\n",
      "         POS       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.86       199\n",
      "   macro avg       0.29      0.33      0.31       199\n",
      "weighted avg       0.76      0.86      0.81       199\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay Tai\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Jay Tai\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Jay Tai\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T07:22:00.323952Z",
     "start_time": "2025-06-19T07:21:59.369529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Grad Boost\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# Create a pipeline with CountVectorizer, TfidfTransformer, and Gradient Boosting Classifier\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('model', GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test dataset\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"GradientBoostingClassifier\")\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy score: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ],
   "id": "3e321fde09194fb8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier\n",
      "accuracy score: 87.94%\n",
      "Confusion Matrix:\n",
      " [[172   1   0]\n",
      " [  7   0   2]\n",
      " [ 12   2   3]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.90      0.99      0.95       173\n",
      "         NEU       0.00      0.00      0.00         9\n",
      "         POS       0.60      0.18      0.27        17\n",
      "\n",
      "    accuracy                           0.88       199\n",
      "   macro avg       0.50      0.39      0.41       199\n",
      "weighted avg       0.83      0.88      0.84       199\n",
      "\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T07:22:14.389387Z",
     "start_time": "2025-06-19T07:22:14.154339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# XG Boost\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Create a label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the label encoder on the sentiment labels and transform them to numerical values\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Create a pipeline with CountVectorizer, TfidfTransformer, and XGBoost Classifier\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('model', XGBClassifier())\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Predict on the test dataset\n",
    "y_pred_encoded = pipeline.predict(X_test)\n",
    "print(\"XGBoostClassifier\")\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred_encoded)\n",
    "print(\"accuracy score: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_encoded, y_pred_encoded))\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_encoded, y_pred_encoded, target_names=label_encoder.classes_))"
   ],
   "id": "a69f9c48110df1af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoostClassifier\n",
      "accuracy score: 86.43%\n",
      "Confusion Matrix:\n",
      " [[168   1   4]\n",
      " [  8   1   0]\n",
      " [ 13   1   3]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.89      0.97      0.93       173\n",
      "         NEU       0.33      0.11      0.17         9\n",
      "         POS       0.43      0.18      0.25        17\n",
      "\n",
      "    accuracy                           0.86       199\n",
      "   macro avg       0.55      0.42      0.45       199\n",
      "weighted avg       0.82      0.86      0.84       199\n",
      "\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T06:17:05.947455Z",
     "start_time": "2025-06-23T06:17:05.873826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# DT\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Assuming you have already split the data into X_train, X_test, y_train, y_test\n",
    "# If not, please refer to the previous code snippets\n",
    "\n",
    "# Create a pipeline with CountVectorizer, TfidfTransformer, and Decision Tree Classifier\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('model', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test dataset\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"DecisionTreeClassifier\")\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy score: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "print(pipeline.named_steps['model'].feature_importances_)"
   ],
   "id": "f1aaf5077f50ddf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "accuracy score: 83.42%\n",
      "Confusion Matrix:\n",
      " [[161   4   8]\n",
      " [  5   1   3]\n",
      " [ 11   2   4]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.91      0.93      0.92       173\n",
      "         NEU       0.14      0.11      0.12         9\n",
      "         POS       0.27      0.24      0.25        17\n",
      "\n",
      "    accuracy                           0.83       199\n",
      "   macro avg       0.44      0.43      0.43       199\n",
      "weighted avg       0.82      0.83      0.83       199\n",
      "\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T06:14:08.532767900Z",
     "start_time": "2025-06-19T07:22:47.723243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# RF\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Assuming you have already split the data into X_train, X_test, y_train, y_test\n",
    "# If not, please refer to the previous code snippets\n",
    "\n",
    "# Create a pipeline with CountVectorizer, TfidfTransformer, and Decision Tree Classifier\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('model', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test dataset\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"RandomForestClassifier\")\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy score: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ],
   "id": "6e0c3265eae1591d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "accuracy score: 87.44%\n",
      "Confusion Matrix:\n",
      " [[172   0   1]\n",
      " [  8   1   0]\n",
      " [ 15   1   1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.88      0.99      0.93       173\n",
      "         NEU       0.50      0.11      0.18         9\n",
      "         POS       0.50      0.06      0.11        17\n",
      "\n",
      "    accuracy                           0.87       199\n",
      "   macro avg       0.63      0.39      0.41       199\n",
      "weighted avg       0.83      0.87      0.83       199\n",
      "\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T07:23:15.302446Z",
     "start_time": "2025-06-19T07:23:15.269621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# KNN\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# Create a pipeline with CountVectorizer, TfidfTransformer, and K-Nearest Neighbors Classifier\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('model', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test dataset\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"KNeighborsClassifier\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "# Calculate accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy score: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ],
   "id": "af3479e2a81c1251",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier\n",
      "accuracy score: 87.94%\n",
      "Confusion Matrix:\n",
      " [[171   1   1]\n",
      " [  7   1   1]\n",
      " [ 14   0   3]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.89      0.99      0.94       173\n",
      "         NEU       0.50      0.11      0.18         9\n",
      "         POS       0.60      0.18      0.27        17\n",
      "\n",
      "    accuracy                           0.88       199\n",
      "   macro avg       0.66      0.43      0.46       199\n",
      "weighted avg       0.85      0.88      0.85       199\n",
      "\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Compare the best ML model with available Libraries",
   "id": "6df6b8cfedb46da4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T05:59:13.845575Z",
     "start_time": "2025-06-23T05:59:13.706445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SVM\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('model', LinearSVC())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(pipeline.named_steps['model'].decision_function(X_test))"
   ],
   "id": "11f05bbf02543cfe",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'behind job returned key takeaway june u job report'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 15\u001B[39m\n\u001B[32m     13\u001B[39m pipeline.fit(X_train, y_train)\n\u001B[32m     14\u001B[39m y_pred = pipeline.predict(X_test)\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[43mpipeline\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnamed_steps\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mmodel\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecision_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\linear_model\\_base.py:352\u001B[39m, in \u001B[36mLinearClassifierMixin.decision_function\u001B[39m\u001B[34m(self, X)\u001B[39m\n\u001B[32m    349\u001B[39m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[32m    350\u001B[39m xp, _ = get_namespace(X)\n\u001B[32m--> \u001B[39m\u001B[32m352\u001B[39m X = \u001B[43mvalidate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcsr\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m    353\u001B[39m scores = safe_sparse_dot(X, \u001B[38;5;28mself\u001B[39m.coef_.T, dense_output=\u001B[38;5;28;01mTrue\u001B[39;00m) + \u001B[38;5;28mself\u001B[39m.intercept_\n\u001B[32m    354\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[32m    355\u001B[39m     xp.reshape(scores, (-\u001B[32m1\u001B[39m,))\n\u001B[32m    356\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m (scores.ndim > \u001B[32m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m scores.shape[\u001B[32m1\u001B[39m] == \u001B[32m1\u001B[39m)\n\u001B[32m    357\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m scores\n\u001B[32m    358\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\utils\\validation.py:2954\u001B[39m, in \u001B[36mvalidate_data\u001B[39m\u001B[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001B[39m\n\u001B[32m   2952\u001B[39m         out = X, y\n\u001B[32m   2953\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m no_val_y:\n\u001B[32m-> \u001B[39m\u001B[32m2954\u001B[39m     out = \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mX\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2955\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_y:\n\u001B[32m   2956\u001B[39m     out = _check_y(y, **check_params)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\utils\\validation.py:1053\u001B[39m, in \u001B[36mcheck_array\u001B[39m\u001B[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[39m\n\u001B[32m   1051\u001B[39m         array = xp.astype(array, dtype, copy=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m   1052\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1053\u001B[39m         array = \u001B[43m_asarray_with_order\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[43m=\u001B[49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxp\u001B[49m\u001B[43m=\u001B[49m\u001B[43mxp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1054\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m ComplexWarning \u001B[38;5;28;01mas\u001B[39;00m complex_warning:\n\u001B[32m   1055\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   1056\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mComplex data not supported\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m\"\u001B[39m.format(array)\n\u001B[32m   1057\u001B[39m     ) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mcomplex_warning\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\utils\\_array_api.py:757\u001B[39m, in \u001B[36m_asarray_with_order\u001B[39m\u001B[34m(array, dtype, order, copy, xp, device)\u001B[39m\n\u001B[32m    755\u001B[39m     array = numpy.array(array, order=order, dtype=dtype)\n\u001B[32m    756\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m757\u001B[39m     array = \u001B[43mnumpy\u001B[49m\u001B[43m.\u001B[49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[43m=\u001B[49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    759\u001B[39m \u001B[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001B[39;00m\n\u001B[32m    760\u001B[39m \u001B[38;5;66;03m# container that is consistent with the input's namespace.\u001B[39;00m\n\u001B[32m    761\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m xp.asarray(array)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\core\\series.py:1033\u001B[39m, in \u001B[36mSeries.__array__\u001B[39m\u001B[34m(self, dtype, copy)\u001B[39m\n\u001B[32m   1030\u001B[39m values = \u001B[38;5;28mself\u001B[39m._values\n\u001B[32m   1031\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m copy \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   1032\u001B[39m     \u001B[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1033\u001B[39m     arr = \u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1034\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1035\u001B[39m     arr = np.array(values, dtype=dtype, copy=copy)\n",
      "\u001B[31mValueError\u001B[39m: could not convert string to float: 'behind job returned key takeaway june u job report'"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T09:40:01.548551Z",
     "start_time": "2025-06-20T09:39:24.637673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline, set_seed\n",
    "set_seed(999)\n",
    "\n",
    "# Initialize DistilBERT pipeline\n",
    "classifier = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')\n",
    "\n",
    "# Apply DistilBERT to test set\n",
    "y_pred_distilbert = [classifier(headline)[0]['label'] for headline in X_test]\n",
    "y_pred_distilbert = ['POS' if s == 'POSITIVE' else 'NEG' if s == 'NEGATIVE' else 'NEU' for s in y_pred_distilbert]\n",
    "\n",
    "# Compute and print metrics\n",
    "accuracy_distilbert = accuracy_score(y_test, y_pred_distilbert)\n",
    "print(\"DistilBERT\")\n",
    "print(\"Accuracy score: {:.2f}%\".format(accuracy_distilbert * 100))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_distilbert))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_distilbert))"
   ],
   "id": "1bca520d3a181ae4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBERT\n",
      "Accuracy score: 80.40%\n",
      "Confusion Matrix:\n",
      " [[157   0  16]\n",
      " [  6   0   3]\n",
      " [ 14   0   3]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.89      0.91      0.90       173\n",
      "         NEU       0.00      0.00      0.00         9\n",
      "         POS       0.14      0.18      0.15        17\n",
      "\n",
      "    accuracy                           0.80       199\n",
      "   macro avg       0.34      0.36      0.35       199\n",
      "weighted avg       0.78      0.80      0.79       199\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jay Tai\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Jay Tai\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Jay Tai\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6d3fbcd4d60ca6a4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
