{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e8c02b57eb0abd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:43:09.575188Z",
     "start_time": "2025-06-26T01:42:50.734121Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.11.9)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Jay Tai/Documents/Sentimental-Analysis/Sentimental-Analysis/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "df = pd.read_csv('data/News Articles/Bloomberg/BloombergNews100.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76a4f2b0c9cd62f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:57:24.185016Z",
     "start_time": "2025-06-26T01:54:33.615781Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [ivory, coast, keeps, cocoa, export, tax, docu...\n",
       "1    [usda, boxed, beef, cutout, closing, prices, o...\n",
       "2          [september, small, business, jobs, summary]\n",
       "3    [greece, gsee, says, meet, talks, troika, athens]\n",
       "4           [companies, get, tax, breaks, hundt, says]\n",
       "Name: processed_content, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset=['Headline'])\n",
    "\n",
    "# Define a function to preprocess the text\n",
    "def preprocess_text(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text.lower())  # Tokenize and convert to lowercase\n",
    "    tokens = [word for word in tokens if word.isalpha()]  # Remove non-alphabetic characters\n",
    "    tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords\n",
    "    return tokens\n",
    "\n",
    "# Apply the function to preprocess the 'data' column\n",
    "df['processed_content'] = df['Headline'].apply(preprocess_text)\n",
    "\n",
    "# Preview the preprocessed text\n",
    "df['processed_content'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82cd4d39eb4c18e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:57:36.946991Z",
     "start_time": "2025-06-26T01:57:30.168230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)], [(8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary and corpus for LDA\n",
    "dictionary = corpora.Dictionary(df['processed_content'])\n",
    "corpus = [dictionary.doc2bow(text) for text in df['processed_content']]\n",
    "\n",
    "# Preview the corpus\n",
    "print(corpus[:2])  # List of tuples (term_id, term_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f08af02e0f5b1b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T02:07:41.911003Z",
     "start_time": "2025-06-26T01:58:34.689693Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: 0.027*\"says\" + 0.012*\"eu\" + 0.012*\"world\" + 0.012*\"gas\" + 0.010*\"obama\" + 0.010*\"companies\" + 0.009*\"power\" + 0.008*\"deal\" + 0.007*\"budget\" + 0.007*\"plan\"\n",
      "Topic 1: 0.061*\"says\" + 0.033*\"bank\" + 0.016*\"february\" + 0.014*\"may\" + 0.013*\"credit\" + 0.012*\"rate\" + 0.012*\"central\" + 0.011*\"japan\" + 0.010*\"debt\" + 0.008*\"fed\"\n",
      "Topic 2: 0.027*\"says\" + 0.016*\"euro\" + 0.014*\"crude\" + 0.011*\"april\" + 0.007*\"egypt\" + 0.007*\"probe\" + 0.007*\"said\" + 0.007*\"versus\" + 0.006*\"move\" + 0.006*\"little\"\n",
      "Topic 3: 0.032*\"profit\" + 0.029*\"rises\" + 0.023*\"growth\" + 0.015*\"estimates\" + 0.014*\"china\" + 0.013*\"forecast\" + 0.012*\"stocks\" + 0.012*\"first\" + 0.011*\"months\" + 0.010*\"years\"\n",
      "Topic 4: 0.028*\"prices\" + 0.024*\"million\" + 0.021*\"says\" + 0.017*\"india\" + 0.013*\"new\" + 0.011*\"markets\" + 0.009*\"china\" + 0.009*\"may\" + 0.009*\"higher\" + 0.009*\"copper\"\n",
      "Topic 5: 0.035*\"says\" + 0.022*\"billion\" + 0.015*\"million\" + 0.014*\"may\" + 0.013*\"said\" + 0.012*\"equity\" + 0.011*\"south\" + 0.010*\"reports\" + 0.010*\"plans\" + 0.010*\"preview\"\n",
      "Topic 6: 0.031*\"stocks\" + 0.017*\"oil\" + 0.015*\"drop\" + 0.014*\"dollar\" + 0.014*\"rise\" + 0.013*\"decline\" + 0.013*\"day\" + 0.013*\"falls\" + 0.013*\"gains\" + 0.013*\"high\"\n",
      "Topic 7: 0.094*\"sales\" + 0.062*\"table\" + 0.062*\"tt\" + 0.042*\"rise\" + 0.038*\"fall\" + 0.038*\"june\" + 0.009*\"may\" + 0.007*\"increases\" + 0.007*\"home\" + 0.006*\"august\"\n",
      "Coherence Score: 0.3019987325605488\n"
     ]
    }
   ],
   "source": [
    "# Train the LDA model\n",
    "lda_model = LdaModel(corpus=corpus, num_topics=8, id2word=dictionary, passes=10)\n",
    "\n",
    "# Print the topics with top words\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(f\"Topic {idx}: {topic}\")\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "# Calculate Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=df['processed_content'], dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print(f'Coherence Score: {coherence_lda}')\n",
    "\n",
    "# Visualize the topics using pyLDAvis\n",
    "vis = gensimvis.prepare(lda_model, corpus, dictionary)\n",
    "pyLDAvis.save_html(vis, 'data/LDA html charts/LDA bloomberg.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dde2ed3c0a3916a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
