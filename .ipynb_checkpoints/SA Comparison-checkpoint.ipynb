{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Comparing between different Sentimental Analaysis Models\n",
    "\n",
    "Goal: To determine the best model on hand\n",
    "\n",
    "Description:  I have a csv of headliners, and fed it to GrokAI to generate a list of sentimental Scores. This will be used as the benchmark in the comparison.\n",
    "\n",
    "Steps outlined:\n",
    "1. Setup the file \"with_sentiment_100.csv\" for comparison and briefly screen through the list for outliers\n",
    "2. Run through the different models and run the data through them (We are interested to know if its positive or negative)\n",
    "3. Compare with true values"
   ],
   "id": "bbeb033608f08ddd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Setup testing file",
   "id": "974369bbd4b8facb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/with_sentiment_100.csv\")\n",
    "df.head()"
   ],
   "id": "a848f71571d52b07"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.shape",
   "id": "b46b169d6a7299ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.info()",
   "id": "4169c2a32d507ae3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.describe()",
   "id": "ac756655313fe851",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "headline = list(df['Headline'])\n",
    "headline[:10]"
   ],
   "id": "4b5c64b58a3649c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Run the list through different models",
   "id": "b7999155b16b3afc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# set up\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    if not isinstance(text, str) or text is None:\n",
    "        return \"\"\n",
    "    tokens = word_tokenize(text.lower())  # Tokenize and lowercase\n",
    "    cleaned_tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalpha() and token not in stop_words]\n",
    "    test_sentence = \" \".join(cleaned_tokens)\n",
    "    return test_sentence\n",
    "\n",
    "processed_headine = list(map(preprocess, headline))"
   ],
   "id": "548065da08211f47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1. Prebuilt Vader sentiment package (NaiveBayes model)\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "result_vader = []\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "for sentence in processed_headine:\n",
    "    temp = analyzer.polarity_scores(sentence)\n",
    "    result_vader.append(temp['pos']-temp['neg'])\n",
    "print(result_vader[:10])\n",
    "pd.DataFrame(result_vader).to_csv(\"data/result_vader.csv\")"
   ],
   "id": "e45f5d28bbc253e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 2. Prebuilt Textblob sentiment package\n",
    "\n",
    "from textblob import TextBlob\n",
    "result_tb = []\n",
    "for sentence in processed_headine:\n",
    "    result_tb.append(TextBlob(sentence).sentiment.polarity)\n",
    "print(result_tb[:10])\n",
    "pd.DataFrame(result_tb).to_csv(\"data/result_tb.csv\")"
   ],
   "id": "dabb924578b70adc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 3. Prebuilt Flair sentiment package/Model\n",
    "\n",
    "from flair.data import Sentence\n",
    "from flair.nn import Classifier\n",
    "result_flair = []\n",
    "tagger = Classifier.load('sentiment')\n",
    "for sentence in processed_headine:\n",
    "    sentence = Sentence(sentence)\n",
    "    tagger.predict(sentence)\n",
    "    score = sentence.labels[0].score\n",
    "    result_flair.append(score)\n",
    "print(result_flair[:10])\n",
    "pd.DataFrame(result_flair).to_csv(\"data/result_flair.csv\")"
   ],
   "id": "b2947c9fcd7945dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# setup for HuggingFace Transformers\n",
    "\n",
    "from transformers import pipeline, set_seed\n",
    "set_seed(999)"
   ],
   "id": "9a198a7537747514",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T15:04:12.268555Z",
     "start_time": "2025-06-17T15:03:53.768094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# RoBERTa\n",
    "\n",
    "classifier = pipeline('sentiment-analysis', model='cardiffnlp/twitter-roberta-base-sentiment-latest')\n",
    "\n",
    "result_roberta = []\n",
    "for sentence in processed_headine:\n",
    "    score = 0\n",
    "    temp = classifier(sentence)\n",
    "    if temp[0]['label'] == 'positive': score = temp[0]['score']\n",
    "    elif temp[0]['label'] == 'negative': score = -temp[0]['score']\n",
    "    result_roberta.append(score)\n",
    "print(result_roberta[:10])\n",
    "pd.DataFrame(result_roberta).to_csv(\"data/result_roberta.csv\")"
   ],
   "id": "81ee78c078282156",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, -0.8230181932449341, 0, 0, -0.927061140537262, 0, 0, -0.7382956147193909, -0.6555284261703491, -0.8183677792549133]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T15:05:29.064151Z",
     "start_time": "2025-06-17T15:05:23.915489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# distilBERT\n",
    "\n",
    "classifier = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')\n",
    "\n",
    "result_dis = []\n",
    "for sentence in processed_headine:\n",
    "    score = 0\n",
    "    temp = classifier(sentence)\n",
    "    if temp[0]['label'] == 'POSITIVE': score = temp[0]['score']\n",
    "    elif temp[0]['label'] == 'NEGATIVE': score = -temp[0]['score']\n",
    "    result_dis.append(score)\n",
    "print(result_dis[:10])\n",
    "pd.DataFrame(result_dis).to_csv(\"data/result_distilbert.csv\")"
   ],
   "id": "1529a63db0d77e0d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7830798029899597, -0.9975211024284363, 0.9916312098503113, -0.9994638562202454, -0.9995527863502502, -0.9851893186569214, 0.898344874382019, -0.9996541738510132, -0.9996930360794067, -0.9973596930503845]\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T15:34:55.283345Z",
     "start_time": "2025-06-17T15:33:44.967882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Google Flan t5\n",
    "\n",
    "sentiment_regressor = pipeline(\"text-classification\", model=\"finiteautomata/bertweet-base-sentiment-analysis\")\n"
   ],
   "id": "682c686030bb5642",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/949 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b826090205f5454394135930e861b36f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/540M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c57efad4eab4bb2be09350306ff3c1f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/338 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0bbbeaa83a8417182d5fe7efb14b1a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/540M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a3fd8d58b2ef4a969cead6b97c7a83df"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/843k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2f2cf231708f463ba7fcfa936375e138"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "bpe.codes:   0%|          | 0.00/1.08M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8a3173a2406474386c5f4fe13a8468d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/22.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05bb55838bca40f9907b0a37b938d6eb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2e4465044914eb9bc91024777e8cfcc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T15:35:19.642922Z",
     "start_time": "2025-06-17T15:34:59.901131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sentence = \"The market is slightly bullish.\"\n",
    "result = sentiment_regressor(sentence)[0]\n",
    "score = result[\"score\"] if result[\"label\"] == \"POS\" else -result[\"score\"]\n",
    "print(score)  # e.g., 0.65 (positive sentiment)"
   ],
   "id": "92bf7c3f91b6d423",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8173216581344604\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T15:42:42.255112Z",
     "start_time": "2025-06-17T15:42:29.333365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result_bertweet = []\n",
    "for sentence in processed_headine:\n",
    "    result = sentiment_regressor(sentence)[0]\n",
    "    if result['label'] == \"NEU\": score = -result[\"score\"]\n",
    "    elif result['label'] == \"NEG\": score = -result[\"score\"]\n",
    "    result_bertweet.append(result)\n",
    "print(result_bertweet[:10])\n",
    "pd.DataFrame(result_bertweet).to_csv(\"data/result_bertweet.csv\")"
   ],
   "id": "d3fa904a54945194",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEU', 'score': 0.9402851462364197}, {'label': 'NEG', 'score': 0.971281111240387}, {'label': 'NEU', 'score': 0.9430890083312988}, {'label': 'NEU', 'score': 0.9454593658447266}, {'label': 'NEG', 'score': 0.9511646032333374}, {'label': 'NEU', 'score': 0.9328596591949463}, {'label': 'NEU', 'score': 0.7165356874465942}, {'label': 'NEG', 'score': 0.8400986790657043}, {'label': 'NEG', 'score': 0.9036521315574646}, {'label': 'NEG', 'score': 0.9230291247367859}]\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T15:41:50.271671Z",
     "start_time": "2025-06-17T15:41:41.295722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for sentence in processed_headine[:0]:\n",
    "    score = 0\n",
    "    result = sentiment_regressor(sentence)[0]\n",
    "    print(result)\n",
    "    if result['label'] == \"NEU\": score = -result[\"score\"]\n",
    "    elif result['label'] == \"NEG\": score = -result[\"score\"]\n",
    "    print(score)"
   ],
   "id": "4e89a40a91a7a8c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'NEU', 'score': 0.9402851462364197}\n",
      "0\n",
      "{'label': 'NEG', 'score': 0.971281111240387}\n",
      "-0.971281111240387\n",
      "{'label': 'NEU', 'score': 0.9430890083312988}\n",
      "0\n",
      "{'label': 'NEU', 'score': 0.9454593658447266}\n",
      "0\n",
      "{'label': 'NEG', 'score': 0.9511646032333374}\n",
      "-0.9511646032333374\n",
      "{'label': 'NEU', 'score': 0.9328596591949463}\n",
      "0\n",
      "{'label': 'NEU', 'score': 0.7165356874465942}\n",
      "0\n",
      "{'label': 'NEG', 'score': 0.8400986790657043}\n",
      "-0.8400986790657043\n",
      "{'label': 'NEG', 'score': 0.9036521315574646}\n",
      "-0.9036521315574646\n",
      "{'label': 'NEG', 'score': 0.9230291247367859}\n",
      "-0.9230291247367859\n",
      "{'label': 'NEU', 'score': 0.6469767093658447}\n",
      "0\n",
      "{'label': 'NEG', 'score': 0.6269466876983643}\n",
      "-0.6269466876983643\n",
      "{'label': 'NEU', 'score': 0.9495458602905273}\n",
      "0\n",
      "{'label': 'NEU', 'score': 0.8629282116889954}\n",
      "0\n",
      "{'label': 'NEU', 'score': 0.9752309322357178}\n",
      "0\n",
      "{'label': 'NEG', 'score': 0.8271180987358093}\n",
      "-0.8271180987358093\n",
      "{'label': 'NEU', 'score': 0.8855149745941162}\n",
      "0\n",
      "{'label': 'NEU', 'score': 0.9280298948287964}\n",
      "0\n",
      "{'label': 'NEU', 'score': 0.9443793296813965}\n",
      "0\n",
      "{'label': 'NEU', 'score': 0.617679238319397}\n",
      "0\n",
      "{'label': 'NEU', 'score': 0.9357874393463135}\n",
      "0\n",
      "{'label': 'NEU', 'score': 0.5279436111450195}\n",
      "0\n",
      "{'label': 'NEG', 'score': 0.7240381836891174}\n",
      "-0.7240381836891174\n",
      "{'label': 'NEU', 'score': 0.8431287407875061}\n",
      "0\n",
      "{'label': 'NEG', 'score': 0.7639641165733337}\n",
      "-0.7639641165733337\n",
      "{'label': 'NEU', 'score': 0.8595221042633057}\n",
      "0\n",
      "{'label': 'NEU', 'score': 0.9532785415649414}\n",
      "0\n",
      "{'label': 'NEU', 'score': 0.9519932866096497}\n",
      "0\n",
      "{'label': 'NEU', 'score': 0.9713897109031677}\n",
      "0\n",
      "{'label': 'NEU', 'score': 0.9487465023994446}\n",
      "0\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# LLM QWEN 8gb\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=\"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\",\n",
    ")\n",
    "\n",
    "result_ai = []\n",
    "\n",
    "for sentence in processed_headine:\n",
    "    completion = client.chat.completions.create(\n",
    "      extra_body={}, model=\"deepseek/deepseek-r1-0528-qwen3-8b:free\",\n",
    "      messages=[{ \"role\": \"user\",\n",
    "          \"content\": f\"Only give me a float sentimental analysis score from -1(negative) to 1(positive) for the following sentence {sentence}\"\n",
    "    }])\n",
    "    result_ai.append(completion.choices[0].message.content)\n",
    "result_ai[:10]\n",
    "pd.DataFrame(result_ai).to_csv(\"data/ai.csv\")"
   ],
   "id": "95e325bb2df4b9e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "df8301159eece3e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "410d95e5537866cd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
