{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Headline Tagging and Sentiment Analysis with DistilBERT\n",
    "\n",
    "This notebook processes news headlines to:\n",
    "- Perform sentiment analysis (positive/negative) using DistilBERT.\n",
    "- Tag headlines with categories (Positive Sentiment, Negative Sentiment, New Products, Layoffs, Analyst Comments, Stocks, Dividends, Corporate Earnings, Mergers & Acquisitions, Store Openings, Product Recalls, Adverse Events, Personnel Changes, Stock Rumors) using DistilBERT embeddings.\n",
    "- Map headlines to S&P 500 stocks.\n",
    "- Output results as a CSV for Excel integration.\n",
    "\n",
    "**Prerequisites**:\n",
    "- Install dependencies: `!pip install transformers pandas torch scikit-learn`\n",
    "- Run in a Jupyter Notebook environment.\n",
    "- Headlines are provided as a list; replace with your own if needed.\n",
    "\n",
    "**Note**: Category tagging simulates a fine-tuned multi-label DistilBERT model using embeddings. For better accuracy, fine-tune with labeled data (see instructions at the end).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T09:13:57.473406Z",
     "start_time": "2025-06-20T09:13:50.363561Z"
    }
   },
   "source": "pip install transformers pandas torch scikit-learn",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (4.52.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (2.3.0)\n",
      "Requirement already satisfied: torch in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (1.7.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers) (0.33.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jay tai\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests->transformers) (2025.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-20T09:48:19.633465Z"
    }
   },
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline, DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize DistilBERT sentiment analysis pipeline\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Initialize DistilBERT tokenizer and model for embeddings\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# S&P 500 tickers and company names (partial list, extend as needed)\n",
    "sp500_tickers = {\n",
    "    'NVDA': 'Nvidia', 'TSLA': 'Tesla', 'ULTA': 'Ulta Beauty', 'GPS': 'The Gap',\n",
    "    'FDS': 'FactSet', 'COST': 'Costco', 'OKTA': 'Okta', 'M': 'Macy’s',\n",
    "    'AWK': 'American Water Works'\n",
    "}\n",
    "\n",
    "# User-provided headlines\n",
    "headlines = [\n",
    "    {'date': '2025-06-15', 'text': 'FactSet’s ASV growth slows, raising analyst concerns.', 'source': 'Investing.com'},\n",
    "    {'date': '2025-05-30', 'text': 'Nvidia shares pop after lower-cost chip for China announced.', 'source': 'Yahoo Finance'},\n",
    "    {'date': '2025-05-31', 'text': 'Ulta Beauty jumps 8.3% after beating Q1 earnings.', 'source': 'Yahoo Finance'},\n",
    "    {'date': '2025-05-30', 'text': 'The Gap stock falls 14.8% due to tariff fears.', 'source': 'Yahoo Finance'},\n",
    "    {'date': '2025-06-10', 'text': 'Tesla stock rises on positive sentiment for EV vision.', 'source': 'AInvest'},\n",
    "    {'date': '2025-06-15', 'text': 'FactSet acquires new firm, but EPS guidance may drop.', 'source': 'Investing.com'},\n",
    "    {'date': '2025-06-12', 'text': 'Costco to open new stores in Q3.', 'source': 'Yahoo Finance'},\n",
    "    {'date': '2025-06-13', 'text': 'American Water Works faces regulatory scrutiny after Thames Water news.', 'source': 'Simulated'},\n",
    "    {'date': '2025-06-16', 'text': 'Okta announces layoffs to streamline operations.', 'source': 'Yahoo Finance'},\n",
    "    {'date': '2025-06-20', 'text': 'Rumors swirl about Macy’s potential merger.', 'source': 'Simulated'}\n",
    "]\n",
    "\n",
    "df1 = pd.read_csv('data/Kraggle Datasets/Financial News Dataset/guardian_headlines.csv')\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'date': df1['Time'],\n",
    "    'text': df1['Headlines'],\n",
    "})\n",
    "\n",
    "# Define categories\n",
    "categories = [\n",
    "    'News - Positive Sentiment', 'News - Negative Sentiment', 'News - New Products',\n",
    "    'News - Layoffs', 'News - Analyst Comments', 'News - Stocks', 'News - Dividends',\n",
    "    'News - Corporate Earnings', 'News - Mergers & Acquisitions', 'News - Store Openings',\n",
    "    'News - Product Recalls', 'News - Adverse Events', 'News - Personnel Changes',\n",
    "    'News - Stock Rumors'\n",
    "]\n",
    "\n",
    "# Category descriptions for embedding-based tagging (simulating fine-tuned model)\n",
    "category_descriptions = {\n",
    "    'News - Positive Sentiment': 'Stock price increases, optimistic outlook, strong performance',\n",
    "    'News - Negative Sentiment': 'Stock price declines, negative outlook, poor performance',\n",
    "    'News - New Products': 'Launch or announcement of new products or services',\n",
    "    'News - Layoffs': 'Company announces job cuts or downsizing',\n",
    "    'News - Analyst Comments': 'Analyst reports, forecasts, or concerns about the company',\n",
    "    'News - Stocks': 'General news about stock price or equity movements',\n",
    "    'News - Dividends': 'Announcements about dividend payouts or changes',\n",
    "    'News - Corporate Earnings': 'Reports on company earnings, revenue, or EPS',\n",
    "    'News - Mergers & Acquisitions': 'Mergers, acquisitions, or buyouts involving the company',\n",
    "    'News - Store Openings': 'New store openings or business expansion',\n",
    "    'News - Product Recalls': 'Product defects, recalls, or safety issues',\n",
    "    'News - Adverse Events': 'Lawsuits, regulatory scrutiny, or negative events',\n",
    "    'News - Personnel Changes': 'Changes in executives, CEO, or key personnel',\n",
    "    'News - Stock Rumors': 'Speculation or rumors about stock or company actions'\n",
    "}\n",
    "\n",
    "# Function to get DistilBERT embeddings\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].numpy()  # CLS token embedding\n",
    "\n",
    "# Function to map headlines to tickers\n",
    "def map_to_ticker(text):\n",
    "    text_lower = text.lower()\n",
    "    for ticker, name in sp500_tickers.items():\n",
    "        if ticker.lower() in text_lower or name.lower() in text_lower:\n",
    "            return ticker\n",
    "    return 'Unknown'\n",
    "\n",
    "# Function for multi-label tagging using embeddings\n",
    "def tag_categories(text):\n",
    "    text_embedding = get_embeddings(text)\n",
    "    tags = []\n",
    "    for category, desc in category_descriptions.items():\n",
    "        desc_embedding = get_embeddings(desc)\n",
    "        similarity = cosine_similarity(text_embedding, desc_embedding)[0][0]\n",
    "        if similarity > 0.85:  # Threshold (adjust based on testing)\n",
    "            tags.append(category)\n",
    "    return tags if tags else ['None']\n",
    "\n",
    "# Apply sentiment analysis\n",
    "def get_sentiment(text):\n",
    "    result = sentiment_analyzer(text)[0]\n",
    "    label = result['label']\n",
    "    score = result['score']\n",
    "    return label, score\n",
    "\n",
    "# Process headlines\n",
    "df['Ticker'] = df['text'].apply(map_to_ticker)\n",
    "df['Categories'] = df['text'].apply(tag_categories)\n",
    "df[['Sentiment', 'Sentiment_Score']] = df['text'].apply(get_sentiment).apply(pd.Series)\n",
    "\n",
    "# Expand categories into binary columns\n",
    "for category in categories:\n",
    "    df[category] = df['Categories'].apply(lambda x: 1 if category in x else 0)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('news_tags_distilbert.csv', index=False)\n",
    "print('Output saved to news_tags_distilbert.csv')\n",
    "df\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "The output DataFrame (`news_tags_distilbert.csv`) contains:\n",
    "- **date**: Date of the headline.\n",
    "- **text**: Headline text.\n",
    "- **source**: Source of the headline.\n",
    "- **Ticker**: S&P 500 ticker (e.g., NVDA, AWK) or 'Unknown'.\n",
    "- **Categories**: List of assigned categories (from DistilBERT embeddings).\n",
    "- **Sentiment**: POSITIVE or NEGATIVE (from DistilBERT).\n",
    "- **Sentiment_Score**: Confidence score from DistilBERT.\n",
    "- Binary columns for each category (1 if present, 0 otherwise).\n",
    "\n",
    "Import `news_tags_distilbert.csv` into Excel to join with your S&P 500 dataset (e.g., match on Date and Ticker).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning DistilBERT for Multi-Label Tagging\n",
    "\n",
    "The above script uses embeddings and cosine similarity as a placeholder for a fine-tuned model. For better accuracy, fine-tune DistilBERT on labeled data. Steps:\n",
    "\n",
    "1. **Prepare Labeled Data**:\n",
    "   - Create a CSV with columns: `text` (headline), and binary columns for each category (1 if present, 0 otherwise).\n",
    "   - Example:\n",
    "     ```csv\n",
    "     text,News - Positive Sentiment,News - Negative Sentiment,...,News - Stock Rumors\n",
    "     Nvidia shares pop after lower-cost chip,1,0,...,0\n",
    "     FactSet’s ASV growth slows,0,1,...,0\n",
    "     ```\n",
    "   - Label at least 500-1000 headlines for robust training.\n",
    "\n",
    "2. **Fine-Tune DistilBERT**:\n",
    "   - Use Hugging Face’s `transformers` library.\n",
    "   - Example code (add to a new cell):\n",
    "     ```python\n",
    "     from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "     from datasets import load_dataset\n",
    "\n",
    "     # Load labeled data\n",
    "     dataset = load_dataset('csv', data_files='labeled_headlines.csv')\n",
    "\n",
    "     # Tokenize\n",
    "     def tokenize_function(examples):\n",
    "         return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "     tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "     # Define model for multi-label classification\n",
    "     model = DistilBertForSequenceClassification.from_pretrained(\n",
    "         'distilbert-base-uncased',\n",
    "         num_labels=len(categories),\n",
    "         problem_type='multi_label_classification'\n",
    "     )\n",
    "\n",
    "     # Training arguments\n",
    "     training_args = TrainingArguments(\n",
    "         output_dir='./results',\n",
    "         num_train_epochs=3,\n",
    "         per_device_train_batch_size=8,\n",
    "         per_device_eval_batch_size=8,\n",
    "         warmup_steps=500,\n",
    "         weight_decay=0.01,\n",
    "         logging_dir='./logs',\n",
    "         logging_steps=10,\n",
    "         evaluation_strategy='epoch'\n",
    "     )\n",
    "\n",
    "     # Trainer\n",
    "     trainer = Trainer(\n",
    "         model=model,\n",
    "         args=training_args,\n",
    "         train_dataset=tokenized_dataset['train'],\n",
    "         eval_dataset=tokenized_dataset['validation']\n",
    "     )\n",
    "\n",
    "     # Train\n",
    "     trainer.train()\n",
    "\n",
    "     # Save model\n",
    "     model.save_pretrained('fine_tuned_distilbert_multi_label')\n",
    "     tokenizer.save_pretrained('fine_tuned_distilbert_multi_label')\n",
    "     ```\n",
    "\n",
    "3. **Use Fine-Tuned Model**:\n",
    "   - Replace the `tag_categories` function with:\n",
    "     ```python\n",
    "     fine_tuned_model = DistilBertForSequenceClassification.from_pretrained('fine_tuned_distilbert_multi_label')\n",
    "     def tag_categories(text):\n",
    "         inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
    "         with torch.no_grad():\n",
    "             outputs = fine_tuned_model(**inputs)\n",
    "         probs = torch.sigmoid(outputs.logits).numpy()[0]\n",
    "         tags = [categories[i] for i in range(len(probs)) if probs[i] > 0.5]\n",
    "         return tags if tags else ['None']\n",
    "     ```\n",
    "\n",
    "4. **Resources**:\n",
    "   - Need labeled data? I can help create a small dataset or suggest labeling tools (e.g., Prodigy).\n",
    "   - Fine-tuning requires a GPU for efficiency (e.g., Google Colab).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
