{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c44a31e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "datetime",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "isRetweet",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "a37aed72-06ef-4651-8ace-9768a5ca18e4",
       "rows": [
        [
         "July 9, 2025 @ 8:29 PM ET",
         "I am pleased to announce that I am directing our GREAT Secretary of Transportation, Sean Duffy, to be Interim Administrator of NASA. Sean is doing a TREMENDOUS job in handling our Country’s Transportation Affairs, including creating a state-of-the-art Air Traffic Control systems, while at the same time rebuilding our roads and bridges, making them efficient, and beautiful, again. He will be a fantastic leader of the ever more important Space Agency, even if only for a short period of time. Congratulations, and thank you, Sean!",
         "False"
        ],
        [
         "July 9, 2025 @ 8:29 PM ET",
         "I am announcing a 50% TARIFF on Copper, effective August 1, 2025, after receiving a robust NATIONAL SECURITY ASSESSMENT. Copper is necessary for Semiconductors, Aircraft, Ships, Ammunition, Data Centers, Lithium-ion Batteries, Radar Systems, Missile Defense Systems, and even, Hypersonic Weapons, of which we are building many. Copper is the second most used material by the Department of Defense! Why did our foolish (and SLEEPY!) “Leaders” decimate this important Industry? This 50% TARIFF will reverse the Biden Administration’s thoughtless behavior, and stupidity. America will, once again, build a DOMINANT Copper Industry. THIS IS, AFTER ALL, OUR GOLDEN AGE!",
         "False"
        ],
        [
         "July 9, 2025 @ 8:13 PM ET",
         "HAPPY BIRTHDAY TO SENATOR LINDSEY GRAHAM! He is always there when I need him, and I hope everyone in the Great State of South Carolina will help Lindsey have a BIG WIN in his Re-Election bid next year. MAKE AMERICA GREAT AGAIN!",
         "False"
        ],
        [
         "July 9, 2025 @ 8:12 PM ET",
         "Senator Tom Cotton is working incredibly hard for the Great State of Arkansas, which I love and WON BIG in 2016, 2020, and 2024. He loves the U.S.A., and is truly an American Patriot! A former U.S. Army Ranger, Tom bravely served our Nation in combat, and brings that same Fighting Spirit to the U.S. Senate. He is working tirelessly to Strengthen our Military, Provide the BEST Care for our Veterans, Help Secure our now VERY Secure (Record Setting!) Southern Border, Cut Taxes and Regulations, Ensure American Energy DOMINANCE, and Protect our always under siege Second Amendment. Tom Cotton has my Complete and Total Endorsement for Re-Election – HE WILL NEVER LET YOU DOWN!",
         "False"
        ],
        [
         "July 9, 2025 @ 8:11 PM ET",
         "Senator Roger Marshall is an incredibly strong advocate for the wonderful people of Kansas, a State I love, and WON BIG, in 2016, 2020, and 2024! A distinguished Medical Doctor and U.S. Army Veteran, Roger knows how to Defend our Country, Support our Brave Military/Veterans, and Ensure PEACE THROUGH STRENGTH. In the U.S. Senate, Roger is working hard to Champion our Great Farmers and American Agriculture, Grow our Economy, Cut Taxes and Regulations, Help Secure our now VERY Secure (Record Setting!) Southern Border, Champion American Energy DOMINANCE, and Defend our always under siege Second Amendment. KANSAS, Roger Marshall has my Complete and Total Endorsement for Re-Election – HE WILL NEVER LET YOU DOWN!",
         "False"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>isRetweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>July 9, 2025 @ 8:29 PM ET</th>\n",
       "      <td>I am pleased to announce that I am directing o...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>July 9, 2025 @ 8:29 PM ET</th>\n",
       "      <td>I am announcing a 50% TARIFF on Copper, effect...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>July 9, 2025 @ 8:13 PM ET</th>\n",
       "      <td>HAPPY BIRTHDAY TO SENATOR LINDSEY GRAHAM! He i...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>July 9, 2025 @ 8:12 PM ET</th>\n",
       "      <td>Senator Tom Cotton is working incredibly hard ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>July 9, 2025 @ 8:11 PM ET</th>\n",
       "      <td>Senator Roger Marshall is an incredibly strong...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        text  \\\n",
       "datetime                                                                       \n",
       "July 9, 2025 @ 8:29 PM ET  I am pleased to announce that I am directing o...   \n",
       "July 9, 2025 @ 8:29 PM ET  I am announcing a 50% TARIFF on Copper, effect...   \n",
       "July 9, 2025 @ 8:13 PM ET  HAPPY BIRTHDAY TO SENATOR LINDSEY GRAHAM! He i...   \n",
       "July 9, 2025 @ 8:12 PM ET  Senator Tom Cotton is working incredibly hard ...   \n",
       "July 9, 2025 @ 8:11 PM ET  Senator Roger Marshall is an incredibly strong...   \n",
       "\n",
       "                           isRetweet  \n",
       "datetime                              \n",
       "July 9, 2025 @ 8:29 PM ET      False  \n",
       "July 9, 2025 @ 8:29 PM ET      False  \n",
       "July 9, 2025 @ 8:13 PM ET      False  \n",
       "July 9, 2025 @ 8:12 PM ET      False  \n",
       "July 9, 2025 @ 8:11 PM ET      False  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/News Articles/raw/trump_social_results2.csv', index_col='datetime')[:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "958003e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Jay\n",
      "[nltk_data]     Tai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Jay Tai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker_tab to C:\\Users\\Jay\n",
      "[nltk_data]     Tai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
      "[nltk_data] Downloading package words to C:\\Users\\Jay\n",
      "[nltk_data]     Tai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Jay\n",
      "[nltk_data]     Tai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Jay\n",
      "[nltk_data]     Tai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "datetime",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "processed_text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "ab283964-d54f-4ef4-ae94-492b15b0a247",
       "rows": [
        [
         "July 9, 2025 @ 8:29 PM ET",
         "great transportation sean duffy interim nasa sean tremendous country transportation affairs air traffic control space agency pleased announce directing secretary administrator job handling including creating system time rebuilding road bridge making efficient beautiful fantastic leader ever important even short period time congratulation thank"
        ],
        [
         "July 9, 2025 @ 8:29 PM ET",
         "tariff copper national security copper aircraft ships ammunition data centers radar systems missile defense systems hypersonic weapons copper department defense sleepy leaders tariff biden administration america dominant copper industry after our announcing effective august receiving robust assessment necessary semiconductor battery even building many second used material foolish decimate important reverse thoughtless behavior stupidity build golden age"
        ],
        [
         "July 9, 2025 @ 8:13 PM ET",
         "lindsey great south carolina lindsey big make america happy birthday senator graham always need hope everyone state help win bid next year"
        ],
        [
         "July 9, 2025 @ 8:12 PM ET",
         "tom cotton great arkansas won u.s.a. american patriot u.s. army ranger tom u.s. senate strengthen best care help secure very record setting southern border cut taxes regulations ensure american energy dominance tom cotton complete total senator working incredibly hard state love big love truly former bravely served nation combat brings fighting spirit working tirelessly military provide veteran protect always siege second amendment endorsement never"
        ],
        [
         "July 9, 2025 @ 8:11 PM ET",
         "roger marshall kansas won medical doctor u.s. army veteran roger support brave ensure peace u.s. senate roger great farmers american agriculture grow cut taxes regulations help secure very record setting southern border champion american energy dominance kansas roger marshall complete total senator incredibly strong advocate wonderful people state love big distinguished know defend country strength working hard economy defend always siege second amendment endorsement never"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/plain": [
       "datetime\n",
       "July 9, 2025 @ 8:29 PM ET    great transportation sean duffy interim nasa s...\n",
       "July 9, 2025 @ 8:29 PM ET    tariff copper national security copper aircraf...\n",
       "July 9, 2025 @ 8:13 PM ET    lindsey great south carolina lindsey big make ...\n",
       "July 9, 2025 @ 8:12 PM ET    tom cotton great arkansas won u.s.a. american ...\n",
       "July 9, 2025 @ 8:11 PM ET    roger marshall kansas won medical doctor u.s. ...\n",
       "Name: processed_text, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk.tree import Tree\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"averaged_perceptron_tagger_eng\")\n",
    "nltk.download(\"maxent_ne_chunker_tab\")\n",
    "nltk.download(\"words\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "stop_words = set(stopwords.words('english')).union({\n",
    "    \"said\", \"mr\", \"u\", \"s\", \"today\", \"report\", \"according\"\n",
    "})\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "financial_phrases = [\n",
    "    \"beats expectations\", \"misses expectations\", \"strong guidance\",\n",
    "    \"weak guidance\", \"downgraded rating\", \"upgraded rating\",\n",
    "    \"raises outlook\", \"cuts outlook\", \"missed earnings\", \n",
    "    \"beat earnings\", \"profit warning\", \"record profits\",\n",
    "    \"trading halt\", \"surprise loss\", \"share buyback\", \"stock split\",\n",
    "    \"positive forecast\", \"negative forecast\", \"unexpected loss\"\n",
    "]\n",
    "\n",
    "def extract_named_entities(text):\n",
    "    chunked = ne_chunk(pos_tag(word_tokenize(text)))\n",
    "    named_entities = []\n",
    "    for subtree in chunked:\n",
    "        if isinstance(subtree, Tree):\n",
    "            entity = \" \".join(token for token, pos in subtree.leaves())\n",
    "            named_entities.append(entity.lower())\n",
    "    return named_entities\n",
    "\n",
    "def extract_financial_phrases(text):\n",
    "    phrases_found = []\n",
    "    for phrase in financial_phrases:\n",
    "        # Allow variable whitespace, case-insensitive\n",
    "        pattern = r\"\\b\" + r\"\\s+\".join(re.escape(word) for word in phrase.split()) + r\"\\b\"\n",
    "        match = re.search(pattern, text, flags=re.IGNORECASE)\n",
    "        if match:\n",
    "            phrases_found.append(match.group(0).lower())\n",
    "    return phrases_found\n",
    "\n",
    "def preprocess(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return \"\"\n",
    "\n",
    "    text = text.strip()\n",
    "    text_lower = text.lower()\n",
    "\n",
    "    named_entities = extract_named_entities(text)\n",
    "    fin_phrases = extract_financial_phrases(text)\n",
    "\n",
    "    all_preserved = set(named_entities + fin_phrases)\n",
    "\n",
    "    tokens = word_tokenize(text_lower)\n",
    "    other_tokens = [\n",
    "        lemmatizer.lemmatize(token)\n",
    "        for token in tokens\n",
    "        if token.isalpha() and token not in stop_words and token not in \" \".join(all_preserved)\n",
    "    ]\n",
    "\n",
    "    return \" \".join(fin_phrases + named_entities + other_tokens)\n",
    "\n",
    "\n",
    "df['processed_text'] = df['text'].apply(preprocess)\n",
    "df['processed_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "01c607e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUPS = {\n",
    "    \"Financial Markets\": [\n",
    "        \"stocks\", \"equities\", \"shares\", \"indices\", \"dow\", \"nasdaq\", \"s&p\",\n",
    "        \"bonds\", \"treasuries\", \"yield\", \"spread\", \"options\", \"futures\",\n",
    "        \"margin\", \"leverage\", \"short\", \"dividends\", \"etf\", \"volatility\", \n",
    "        \"vix\", \"hedge\", \"trading\", \"liquidity\", \"volume\", \"order book\", \n",
    "        \"forecast\", \"price action\", \"open interest\", \"technicals\"\n",
    "    ],\n",
    "    \"Corporate Sector\": [\n",
    "        \"earnings\", \"revenue\", \"guidance\", \"layoffs\", \"acquisition\", \"merger\", \n",
    "        \"ipo\", \"startup\", \"valuation\", \"unicorn\", \"restructuring\", \"subsidiary\",\n",
    "        \"brand\", \"expansion\", \"subsidiary\", \"joint venture\", \"conglomerate\",\n",
    "        \"company\", \"profits\", \"CEO\", \"management\", \"shareholder\", \"stake\"\n",
    "    ],\n",
    "    \"Macro Finance\": [\n",
    "        \"inflation\", \"interest\", \"rate hike\", \"fed\", \"ecb\", \"central bank\", \n",
    "        \"monetary\", \"liquidity\", \"policy\", \"credit\", \"debt\", \"balance sheet\", \n",
    "        \"yields\", \"bond buying\", \"qe\", \"qt\", \"macro\", \"gdp\", \"growth\", \"cpi\", \n",
    "        \"ppi\", \"unemployment\", \"deficit\", \"surplus\", \"sovereign\", \"treasury\"\n",
    "    ],\n",
    "    \"Energy & Commodities\": [\n",
    "        \"oil\", \"brent\", \"wti\", \"crude\", \"natural gas\", \"coal\", \"uranium\", \n",
    "        \"gold\", \"silver\", \"copper\", \"commodity\", \"minerals\", \"barrel\", \"supply\",\n",
    "        \"demand\", \"refinery\", \"pipeline\", \"opec\", \"inventory\", \"mining\", \n",
    "        \"extraction\", \"energy\", \"power\", \"grid\", \"electricity\"\n",
    "    ],\n",
    "    \"Geopolitics & Policy\": [\n",
    "        \"war\", \"conflict\", \"military\", \"sanctions\", \"elections\", \"diplomacy\", \n",
    "        \"tariffs\", \"regime\", \"treaty\", \"un\", \"nato\", \"geopolitics\", \"alliance\", \n",
    "        \"border\", \"summit\", \"foreign policy\", \"cyberwar\", \"espionage\", \"blockade\"\n",
    "    ],\n",
    "    \"Tech & Innovation\": [\n",
    "        \"ai\", \"machine learning\", \"deep learning\", \"chatbot\", \"quantum\", \n",
    "        \"robotics\", \"semiconductors\", \"chips\", \"hardware\", \"software\", \"cloud\", \n",
    "        \"infrastructure\", \"cybersecurity\", \"5g\", \"6g\", \"platform\", \"saas\", \n",
    "        \"startup\", \"innovation\", \"automation\", \"big data\", \"iot\", \"virtual reality\"\n",
    "    ],\n",
    "    \"Crypto & Digital Assets\": [\n",
    "        \"crypto\", \"bitcoin\", \"ethereum\", \"nft\", \"token\", \"defi\", \"stablecoin\", \n",
    "        \"blockchain\", \"mining\", \"wallet\", \"exchange\", \"smart contract\", \n",
    "        \"airdrops\", \"gas fees\", \"halving\", \"web3\", \"metaverse\", \"yield farming\"\n",
    "    ],\n",
    "    \"Climate & Environment\": [\n",
    "        \"climate\", \"global warming\", \"carbon\", \"emissions\", \"green\", \n",
    "        \"net zero\", \"biodiversity\", \"deforestation\", \"renewables\", \"solar\", \n",
    "        \"wind\", \"sustainability\", \"eco\", \"climate risk\", \"co2\", \"enviro\", \n",
    "        \"recycling\", \"pollution\", \"weather\", \"drought\", \"wildfire\", \"hurricane\"\n",
    "    ],\n",
    "    \"Health & Biotech\": [\n",
    "        \"healthcare\", \"pharma\", \"vaccine\", \"covid\", \"pandemic\", \"epidemic\", \n",
    "        \"hospital\", \"insurance\", \"fda\", \"biotech\", \"drug\", \"therapy\", \n",
    "        \"clinical trials\", \"approval\", \"genomics\", \"mrna\", \"public health\"\n",
    "    ],\n",
    "    \"Consumer & Retail\": [\n",
    "        \"retail\", \"e-commerce\", \"spending\", \"shopping\", \"consumer\", \"foot traffic\", \n",
    "        \"brand\", \"loyalty\", \"promotion\", \"fashion\", \"luxury\", \"discount\", \n",
    "        \"travel\", \"leisure\", \"supermarket\", \"apparel\", \"inventory\", \"mall\", \n",
    "        \"tourism\", \"holiday sales\", \"storefront\", \"lifestyle\"\n",
    "    ],\n",
    "    \"Society & Labor\": [\n",
    "        \"labor\", \"employment\", \"wages\", \"strike\", \"union\", \"pension\", \n",
    "        \"migration\", \"education\", \"healthcare\", \"inequality\", \"crime\", \n",
    "        \"working class\", \"jobless\", \"benefits\", \"minimum wage\", \"social unrest\"\n",
    "    ],\n",
    "    \"Legal & Regulation\": [\n",
    "        \"regulation\", \"compliance\", \"litigation\", \"lawsuit\", \"ban\", \n",
    "        \"fine\", \"sec\", \"doj\", \"fca\", \"privacy\", \"antitrust\", \"audit\", \n",
    "        \"whistleblower\", \"ethics\", \"governance\", \"oversight\"\n",
    "    ],\n",
    "    \"Real Estate & Housing\": [\n",
    "        \"housing\", \"mortgage\", \"real estate\", \"rent\", \"home sales\", \n",
    "        \"construction\", \"property\", \"housing market\", \"zoning\", \"commercial real estate\", \n",
    "        \"land\", \"housing prices\", \"tenant\", \"eviction\", \"housing bubble\"\n",
    "    ],\n",
    "    \"Transport & Logistics\": [\n",
    "        \"shipping\", \"freight\", \"logistics\", \"supply chain\", \"port\", \n",
    "        \"airline\", \"aviation\", \"rail\", \"infrastructure\", \"trucking\", \n",
    "        \"transportation\", \"container\", \"cargo\", \"disruption\", \"delivery\"\n",
    "    ],\n",
    "    \"Education & Knowledge\": [\n",
    "        \"school\", \"university\", \"student\", \"curriculum\", \"exam\", \"scholarship\", \n",
    "        \"tuition\", \"degree\", \"research\", \"academic\", \"professor\", \n",
    "        \"online learning\", \"edtech\", \"education policy\"\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bda0c24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Analyzing tweets:   0%|          | 0/2 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Analyzing tweets: 100%|██████████| 2/2 [00:36<00:00, 18.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data saved successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extended Tweet Classification Pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline, set_seed, AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.cluster import KMeans\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Load NLP models\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/deberta-v3-base-zeroshot-v1.1-all-33\", device=0 if torch.cuda.is_available() else -1)\n",
    "sentiment = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\", device=0 if torch.cuda.is_available() else -1)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "embed_model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\").to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Helper to extract contextual embeddings\n",
    "def get_embedding(text):\n",
    "    encoded_input = tokenizer(text, padding=True, truncation=True, return_tensors='pt').to(embed_model.device)\n",
    "    with torch.no_grad():\n",
    "        model_output = embed_model(**encoded_input)\n",
    "    return model_output.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "# Multi-label classifier setup\n",
    "def multi_label_classification(text, candidate_labels, threshold=0.5):\n",
    "    result = classifier(text, candidate_labels=candidate_labels, multi_label=True)\n",
    "    labels = [label for label, score in zip(result['labels'], result['scores']) if score >= threshold]\n",
    "    return labels, result\n",
    "\n",
    "# Data processing\n",
    "results = []\n",
    "embeddings = []\n",
    "try:\n",
    "    for sentence in tqdm(df['processed_text'], desc=\"Analyzing tweets\"):\n",
    "        try:\n",
    "            # Topic classification\n",
    "            topics, full_result = multi_label_classification(sentence, list(GROUPS.keys()), threshold=0.5)\n",
    "\n",
    "            # Named entity recognition\n",
    "            doc = nlp(sentence)\n",
    "            named_entities = list(set(ent.text for ent in doc.ents))\n",
    "\n",
    "            # Sentiment\n",
    "            sent_result = sentiment(sentence)[0]\n",
    "\n",
    "            # Keyword matching\n",
    "            matched_keywords = []\n",
    "            for label in topics:\n",
    "                matched_keywords.extend([kw for kw in GROUPS[label] if re.search(rf\"\\\\b{re.escape(kw)}\\\\b\", sentence.lower())])\n",
    "\n",
    "            # Embedding\n",
    "            emb = get_embedding(sentence)\n",
    "            embeddings.append(emb)\n",
    "\n",
    "            results.append({\n",
    "                \"text\": sentence,\n",
    "                \"topics\": topics if topics else [\"Uncertain\"],\n",
    "                \"top_3_topics\": \", \".join(full_result['labels'][:3]),\n",
    "                \"topic_confidences\": [round(score, 3) for score in full_result['scores'][:3]],\n",
    "                \"matched_keywords\": \", \".join(matched_keywords[:3]) if matched_keywords else \"None\",\n",
    "                \"sentiment\": sent_result['label'].upper(),\n",
    "                \"sentiment_score\": round(sent_result['score'], 4),\n",
    "                \"named_entities\": named_entities\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {sentence[:50]}... -> {str(e)}\")\n",
    "            continue\n",
    "finally:\n",
    "    if results:\n",
    "        # Convert to DataFrame\n",
    "        results_df = pd.DataFrame(results)\n",
    "\n",
    "        # Embedding clustering\n",
    "        # X = np.stack(embeddings)\n",
    "        # kmeans = KMeans(n_clusters=6, random_state=42).fit(X)\n",
    "        # results_df['cluster'] = kmeans.labels_\n",
    "\n",
    "        # Binarize multi-label topics\n",
    "        mlb = MultiLabelBinarizer()\n",
    "        topic_binarized = pd.DataFrame(mlb.fit_transform(results_df['topics']), columns=mlb.classes_)\n",
    "        results_df = pd.concat([results_df, topic_binarized], axis=1)\n",
    "        results_df_merged = df.merge(results_df, left_on='processed_text', right_on='text', how='left')\n",
    "\n",
    "        # Save results\n",
    "        results_df_merged.to_csv(\"../data/News Articles/processed/tweet_analysis_extended.csv\", index=True)\n",
    "        print(\"✅ Data saved successfully.\")\n",
    "    else:\n",
    "        print(\"⚠️ No results to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e655b1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
